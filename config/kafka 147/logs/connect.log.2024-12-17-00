[2024-12-17 00:09:19,624] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2510)
[2024-12-17 00:09:19,637] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2510)
[2024-12-17 00:10:34,767] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:10:34,772] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 00:10:34,773] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:10:34,773] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:10:34,779] INFO 172.30.2.207 - - [16/Dec/2024:17:10:34 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 66 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 00:10:34,782] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=408, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:10:34,795] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=408, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:10:34,796] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 00:10:34,796] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 00:10:34,798] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-17 00:10:34,800] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-17 00:10:34,813] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 00:10:34,818] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 00:10:34,826] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 00:10:34,827] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 408 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=656, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:10:34,830] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 656 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:10:34,830] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:10:34,831] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:10:34,832] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:10:34,840] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=409, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:10:34,847] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=409, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:10:34,848] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 409 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=656, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:10:34,849] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 656 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:10:34,850] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:10:52,234] INFO [Producer clientId=mongo-source-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,240] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,240] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,240] INFO [mongodb-source-connector|task-0] [Producer clientId=connector-producer-mongodb-source-connector-0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,234] INFO [Producer clientId=mongo-source-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,238] INFO [AdminClient clientId=mongo-source-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,236] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Node 2147483647 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,242] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,252] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Cancelled in-flight FETCH request with correlation id 14647 due to node 0 being disconnected (elapsed time since creation: 27ms, elapsed time since send: 27ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient:364)
[2024-12-17 00:10:52,241] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Cancelled in-flight FETCH request with correlation id 14792 due to node 0 being disconnected (elapsed time since creation: 331ms, elapsed time since send: 331ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient:364)
[2024-12-17 00:10:52,257] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Error sending fetch request (sessionId=335368808, epoch=14733) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:52,261] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:10:52,264] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Error sending fetch request (sessionId=107030391, epoch=14590) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:52,273] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Cancelled in-flight FETCH request with correlation id 14728 due to node 0 being disconnected (elapsed time since creation: 401ms, elapsed time since send: 401ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient:364)
[2024-12-17 00:10:52,273] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Error sending fetch request (sessionId=615764381, epoch=14671) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:52,321] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,323] WARN [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:52,324] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Error sending fetch request (sessionId=107030391, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:52,331] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,335] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:10:52,349] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Node 2147483647 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,359] WARN [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connection to node 2147483647 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:52,360] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:10:52,363] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:10:52,364] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:10:52,365] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Requesting disconnect from last known coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1013)
[2024-12-17 00:10:52,365] WARN [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:52,373] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Error sending fetch request (sessionId=335368808, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:52,376] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,381] WARN [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:52,382] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Error sending fetch request (sessionId=615764381, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:52,439] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,439] WARN [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:52,439] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Error sending fetch request (sessionId=107030391, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:52,484] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:10:52,485] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Node 2147483647 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,486] WARN [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connection to node 2147483647 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:52,487] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:10:52,488] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:10:52,489] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:10:52,489] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Requesting disconnect from last known coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1013)
[2024-12-17 00:10:52,492] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,492] WARN [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:52,492] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Error sending fetch request (sessionId=335368808, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:52,556] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,559] WARN [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:52,560] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Error sending fetch request (sessionId=615764381, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:52,605] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,606] WARN [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:52,607] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:10:52,607] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:10:52,607] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Requesting disconnect from last known coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1013)
[2024-12-17 00:10:52,644] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,645] WARN [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:52,646] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Error sending fetch request (sessionId=107030391, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:52,790] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,791] WARN [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:52,792] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Error sending fetch request (sessionId=615764381, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:52,795] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,796] WARN [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:52,796] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Error sending fetch request (sessionId=335368808, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:52,850] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:10:52,853] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Node 2147483647 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:52,853] WARN [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connection to node 2147483647 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:52,854] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: null. isDisconnected: true. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:10:52,856] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:10:52,857] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:10:52,857] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Requesting disconnect from last known coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1013)
[2024-12-17 00:10:52,964] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:10:52,965] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:10:52,966] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Requesting disconnect from last known coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1013)
[2024-12-17 00:10:53,146] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:53,148] WARN [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:53,150] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Error sending fetch request (sessionId=335368808, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:53,167] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:53,168] WARN [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:53,169] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Error sending fetch request (sessionId=107030391, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:53,178] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:10:53,178] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:10:53,178] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Requesting disconnect from last known coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1013)
[2024-12-17 00:10:53,304] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:53,305] WARN [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:53,305] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Error sending fetch request (sessionId=615764381, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:53,959] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:53,959] WARN [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:53,960] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Error sending fetch request (sessionId=107030391, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:54,134] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:54,134] WARN [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:54,135] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Error sending fetch request (sessionId=335368808, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:54,223] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:54,223] WARN [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:54,224] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Error sending fetch request (sessionId=615764381, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:54,968] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:54,969] WARN [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:54,969] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Error sending fetch request (sessionId=107030391, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:55,042] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:55,042] WARN [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:55,042] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Error sending fetch request (sessionId=335368808, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:55,229] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:55,229] WARN [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:55,230] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Error sending fetch request (sessionId=615764381, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:55,856] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Broker coordinator was unreachable for 3000ms. Revoking previous assignment Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=656, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} to avoid running tasks while not being a member the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:147)
[2024-12-17 00:10:55,858] INFO [mongodb-source-connector|worker] Stopping connector mongodb-source-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 00:10:55,859] INFO [mongodb-source-connector|task-0] Stopping task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.Worker:1048)
[2024-12-17 00:10:55,859] INFO [mongodb-source-connector|worker] Scheduled shutdown for WorkerConnector{id=mongodb-source-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 00:10:55,860] INFO [mongodb-source-connector|worker] Stopping MongoDB connector (io.debezium.connector.mongodb.MongoDbConnector:82)
[2024-12-17 00:10:55,861] INFO [mongodb-source-connector|worker] Stopped MongoDB connector (io.debezium.connector.mongodb.MongoDbConnector:86)
[2024-12-17 00:10:55,864] INFO [mongodb-source-connector|worker] Completed shutdown for WorkerConnector{id=mongodb-source-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 00:10:55,866] INFO [Producer clientId=mongo-source-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:55,866] WARN [Producer clientId=mongo-source-cluster-statuses] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:56,012] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:56,015] WARN [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:56,016] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Error sending fetch request (sessionId=107030391, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:56,040] INFO [mongodb-source-connector|task-0] Stopping down connector (io.debezium.connector.common.BaseSourceTask:432)
[2024-12-17 00:10:56,117] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:56,118] WARN [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:56,118] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Error sending fetch request (sessionId=335368808, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:56,252] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:56,253] WARN [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:56,253] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Error sending fetch request (sessionId=615764381, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:56,483] INFO [mongodb-source-connector|task-0] Awaiting fetcher thread termination (io.debezium.connector.mongodb.events.BufferingChangeStreamCursor:457)
[2024-12-17 00:10:57,026] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:57,026] WARN [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:57,026] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Error sending fetch request (sessionId=107030391, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:57,105] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:57,106] WARN [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:57,106] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Error sending fetch request (sessionId=335368808, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:57,288] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:57,289] WARN [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:57,290] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Error sending fetch request (sessionId=615764381, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:57,778] INFO [mongodb-source-connector|task-0] Finished streaming (io.debezium.pipeline.ChangeEventSourceCoordinator:325)
[2024-12-17 00:10:57,780] INFO [mongodb-source-connector|task-0] Connected metrics set to 'false' (io.debezium.pipeline.ChangeEventSourceCoordinator:477)
[2024-12-17 00:10:57,783] INFO [mongodb-source-connector|task-0] SignalProcessor stopped (io.debezium.pipeline.signal.SignalProcessor:127)
[2024-12-17 00:10:57,784] INFO [mongodb-source-connector|task-0] Debezium ServiceRegistry stopped. (io.debezium.service.DefaultServiceRegistry:105)
[2024-12-17 00:10:57,785] INFO [mongodb-source-connector|task-0] [Producer clientId=connector-producer-mongodb-source-connector-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2024-12-17 00:10:57,816] INFO [mongodb-source-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 00:10:57,817] INFO [mongodb-source-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:10:57,818] INFO [mongodb-source-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:10:57,819] INFO [mongodb-source-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 00:10:57,821] INFO [mongodb-source-connector|task-0] App info kafka.producer for connector-producer-mongodb-source-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 00:10:57,827] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 00:10:57,982] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:57,983] WARN [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:57,984] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Error sending fetch request (sessionId=107030391, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:58,109] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:58,112] WARN [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:58,113] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Error sending fetch request (sessionId=335368808, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:58,302] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:58,303] WARN [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:58,303] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Error sending fetch request (sessionId=615764381, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:58,922] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:58,922] WARN [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:58,923] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Error sending fetch request (sessionId=107030391, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:59,118] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:59,120] WARN [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:59,120] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Error sending fetch request (sessionId=335368808, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:59,248] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:59,248] WARN [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:59,248] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Error sending fetch request (sessionId=615764381, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:59,894] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:10:59,927] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:59,928] WARN [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Connection to node 0 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:59,928] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Error sending fetch request (sessionId=107030391, epoch=INITIAL) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2024-12-17 00:10:59,996] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Node 2147483647 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:10:59,997] WARN [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connection to node 2147483647 (/172.30.2.207:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2024-12-17 00:10:59,997] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: null. isDisconnected: true. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:11:00,300] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:11:00,304] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:11:00,508] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:11:00,508] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:11:00,609] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:11:00,609] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:11:00,655] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-2 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,657] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,658] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 00:11:00,660] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:11:00,661] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:11:00,661] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Requesting disconnect from last known coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1013)
[2024-12-17 00:11:00,668] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-2 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,669] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,675] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-2 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,676] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,755] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:11:00,755] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:11:00,755] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Requesting disconnect from last known coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1013)
[2024-12-17 00:11:00,782] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,789] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,795] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,809] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,816] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,822] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,829] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,833] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,839] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,846] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,852] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,863] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,867] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,880] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,893] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,897] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,904] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,910] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,915] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,924] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,929] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,936] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,938] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:11:00,940] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:11:00,940] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:11:00,946] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:00,954] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:11:00,955] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Requesting disconnect from last known coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1013)
[2024-12-17 00:11:00,956] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=409, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:695)
[2024-12-17 00:11:00,957] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1103)
[2024-12-17 00:11:00,958] WARN [Producer clientId=mongo-source-cluster-statuses] Received invalid metadata error in produce request on partition connect-status-3 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition. Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender:711)
[2024-12-17 00:11:01,060] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Client requested disconnect from node 2147483647 (org.apache.kafka.clients.NetworkClient:344)
[2024-12-17 00:11:01,063] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:11:01,063] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:11:01,063] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Requesting disconnect from last known coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1013)
[2024-12-17 00:11:01,169] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:11:01,171] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:11:01,177] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:11:01,178] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Requesting disconnect from last known coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1013)
[2024-12-17 00:11:01,179] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=409, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:695)
[2024-12-17 00:11:01,179] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1103)
[2024-12-17 00:11:01,280] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Client requested disconnect from node 2147483647 (org.apache.kafka.clients.NetworkClient:344)
[2024-12-17 00:11:01,283] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:11:01,284] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2024-12-17 00:11:01,284] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Requesting disconnect from last known coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1013)
[2024-12-17 00:11:01,396] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:11:01,397] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:11:01,404] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] JoinGroup failed: Coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is loading the group. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:679)
[2024-12-17 00:11:01,404] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Request joining group due to: rebalance failed due to 'The coordinator is loading and hence can't process requests.' (CoordinatorLoadInProgressException) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1103)
[2024-12-17 00:11:01,504] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:11:01,507] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] JoinGroup failed: Coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) is loading the group. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:679)
[2024-12-17 00:11:01,508] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Request joining group due to: rebalance failed due to 'The coordinator is loading and hence can't process requests.' (CoordinatorLoadInProgressException) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1103)
[2024-12-17 00:11:01,609] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:11:01,637] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=410, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:11:01,678] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=410, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:11:01,679] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 410 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=656, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:11:01,680] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 656 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:11:01,680] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mongodb-source-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 00:11:01,681] INFO [mongodb-source-connector|worker] Creating connector mongodb-source-connector of type io.debezium.connector.mongodb.MongoDbConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 00:11:01,681] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 00:11:01,683] INFO [mongodb-source-connector|task-0] Creating task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 00:11:01,684] INFO [mongodb-source-connector|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-17 00:11:01,687] INFO [mongodb-source-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:11:01,688] INFO [mongodb-source-connector|worker] Instantiated connector mongodb-source-connector with version 3.0.4.Final of type class io.debezium.connector.mongodb.MongoDbConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 00:11:01,688] INFO [mongodb-source-connector|worker] Finished creating connector mongodb-source-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 00:11:01,690] INFO [mongodb-source-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 00:11:01,691] INFO [mongodb-source-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:11:01,692] INFO [mongodb-source-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.MongoDbConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:371)
[2024-12-17 00:11:01,694] INFO [mongodb-source-connector|worker] Successfully started MongoDB connector (io.debezium.connector.mongodb.MongoDbConnector:67)
[2024-12-17 00:11:01,704] INFO [mongodb-source-connector|task-0] Instantiated task mongodb-source-connector-0 with version 3.0.4.Final of type io.debezium.connector.mongodb.MongoDbConnectorTask (org.apache.kafka.connect.runtime.Worker:665)
[2024-12-17 00:11:01,704] INFO [mongodb-source-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 00:11:01,705] INFO [mongodb-source-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 00:11:01,705] INFO [mongodb-source-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-source-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:680)
[2024-12-17 00:11:01,705] INFO [mongodb-source-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-source-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:686)
[2024-12-17 00:11:01,715] INFO [mongodb-source-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mongodb-source-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:691)
[2024-12-17 00:11:01,717] WARN [mongodb-source-connector|task-0] The deleted record handling configs "drop.tombstones" and "delete.handling.mode" have been deprecated, please use "delete.tombstone.handling.mode" instead. (io.debezium.transforms.AbstractExtractNewRecordState:110)
[2024-12-17 00:11:01,718] WARN [mongodb-source-connector|task-0] Configuration key whitelist is deprecated and may be removed in the future.  Please update your configuration to use include instead. (org.apache.kafka.common.utils.ConfigUtils:114)
[2024-12-17 00:11:01,720] INFO [mongodb-source-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{io.debezium.connector.mongodb.transforms.ExtractNewDocumentState, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.TimestampConverter$Value} (org.apache.kafka.connect.runtime.Worker:1795)
[2024-12-17 00:11:01,721] INFO [mongodb-source-connector|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-17 00:11:01,723] INFO [mongodb-source-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:11:01,724] INFO [mongodb-source-connector|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-mongodb-source-connector-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-17 00:11:01,728] INFO [mongodb-source-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 00:11:01,756] INFO [mongodb-source-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-17 00:11:01,756] INFO [mongodb-source-connector|task-0] Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 00:11:01,756] INFO [mongodb-source-connector|task-0] Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 00:11:01,756] INFO [mongodb-source-connector|task-0] Kafka startTimeMs: 1734369061756 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 00:11:01,768] INFO [mongodb-source-connector|task-0] Starting MongoDbConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:245)
[2024-12-17 00:11:01,769] INFO [mongodb-source-connector|task-0]    connector.class = io.debezium.connector.mongodb.MongoDbConnector (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,769] INFO [mongodb-source-connector|task-0]    collection.include.list = test.customers (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,769] INFO [mongodb-source-connector|task-0]    transforms.unwrap.delete.handling.mode = drop (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,770] INFO [mongodb-source-connector|task-0]    transforms.unwrap.array.encoding = array (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,770] INFO [mongodb-source-connector|task-0]    mongodb.connection.string = ******** (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,770] INFO [mongodb-source-connector|task-0]    tasks.max = 1 (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,770] INFO [mongodb-source-connector|task-0]    transforms = unwrap,extractNew,convertDate (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,770] INFO [mongodb-source-connector|task-0]    transforms.unwrap.add.source.fields = db,collection (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,770] INFO [mongodb-source-connector|task-0]    topic.prefix = fullfillment (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,770] INFO [mongodb-source-connector|task-0]    transforms.convertDate.format = yyyy-MM-dd HH:mm:ss (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,771] INFO [mongodb-source-connector|task-0]    mongodb.server.selection.timeout.ms = 10000 (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,771] INFO [mongodb-source-connector|task-0]    transforms.unwrap.drop.tombstones = false (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,771] INFO [mongodb-source-connector|task-0]    transforms.unwrap.type = io.debezium.connector.mongodb.transforms.ExtractNewDocumentState (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,771] INFO [mongodb-source-connector|task-0]    value.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,771] INFO [mongodb-source-connector|task-0]    mongodb.connect.timeout.ms = 10000 (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,771] INFO [mongodb-source-connector|task-0]    mongodb.auth.source = admin (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,771] INFO [mongodb-source-connector|task-0]    key.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,772] INFO [mongodb-source-connector|task-0]    transforms.convertDate.type = org.apache.kafka.connect.transforms.TimestampConverter$Value (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,772] INFO [mongodb-source-connector|task-0]    transforms.extractNew.type = org.apache.kafka.connect.transforms.ReplaceField$Value (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,772] INFO [mongodb-source-connector|task-0]    key.converter.schemas.enable = true (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,772] INFO [mongodb-source-connector|task-0]    transforms.extractNew.whitelist = _id,name,email,age,createdAt (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,772] INFO [mongodb-source-connector|task-0]    task.class = io.debezium.connector.mongodb.MongoDbConnectorTask (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,772] INFO [mongodb-source-connector|task-0]    transforms.convertDate.field = createdAt (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,773] INFO [mongodb-source-connector|task-0]    value.converter.schemas.enable = true (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,773] INFO [mongodb-source-connector|task-0]    name = mongodb-source-connector (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,773] INFO [mongodb-source-connector|task-0]    transforms.convertDate.target.type = string (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,773] INFO [mongodb-source-connector|task-0]    database.include.list = test (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,773] INFO [mongodb-source-connector|task-0]    snapshot.mode = initial (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,773] INFO [mongodb-source-connector|task-0]    transforms.unwrap.operation.header = true (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:01,774] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,775] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,778] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:11:01,780] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-17 00:11:01,782] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:11:01,794] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,795] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,796] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,800] INFO [mongodb-source-connector|task-0] [Producer clientId=connector-producer-mongodb-source-connector-0] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 00:11:01,803] INFO [mongodb-source-connector|task-0] Loading the custom topic naming strategy plugin: io.debezium.schema.DefaultTopicNamingStrategy (io.debezium.config.CommonConnectorConfig:1401)
[2024-12-17 00:11:01,804] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,804] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,808] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,850] INFO [mongodb-source-connector|task-0] Found previous partition offset MongoDbPartition [sourcePartition={server_id=fullfillment}]: {sec=1734365014, ord=1, resume_token=zQAAAAJfZGF0YQC9AAAAODI2NzYwNEY1NjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNEY1NjQ5NkY2QjQ1OTk5NjQwMzcwMDAwMDQAAA==} (io.debezium.connector.common.BaseSourceTask:527)
[2024-12-17 00:11:01,852] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = fullfillment named = SignalProcessor (io.debezium.util.Threads:270)
[2024-12-17 00:11:01,855] WARN [mongodb-source-connector|task-0] Found a not connector specific implementation io.debezium.snapshot.lock.NoLockingSupport for lock mode no_locking_support (io.debezium.snapshot.SnapshotLockProvider:82)
[2024-12-17 00:11:01,861] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,863] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,864] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,866] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,867] INFO [mongodb-source-connector|task-0] Found existing offset for at {sec=1734365014, ord=1, resume_token=zQAAAAJfZGF0YQC9AAAAODI2NzYwNEY1NjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNEY1NjQ5NkY2QjQ1OTk5NjQwMzcwMDAwMDQAAA==} (io.debezium.connector.mongodb.connection.MongoDbConnection:202)
[2024-12-17 00:11:01,868] INFO [mongodb-source-connector|task-0] Adding discovered server 172.30.2.147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:01,881] INFO [mongodb-source-connector|task-0] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.11.0"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-125-generic"}, "platform": "Java/Ubuntu/17.0.13+11-Ubuntu-2ubuntu122.04"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@5691a171, com.mongodb.Jep395RecordCodecProvider@415feae4, com.mongodb.KotlinCodecProvider@26839f41]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[172.30.2.147:27017], srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='rs0', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='10000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=javax.net.ssl.SSLContext@74facd12}, applicationName='null', compressorList=[], uuidRepresentation=STANDARD, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null} (org.mongodb.driver.client:71)
[2024-12-17 00:11:01,882] INFO [mongodb-source-connector|task-0] Effective change stream pipeline: [{"$replaceRoot": {"newRoot": {"namespace": {"$concat": ["$ns.db", ".", "$ns.coll"]}, "event": "$$ROOT"}}}, {"$match": {"$and": [{"$and": [{"event.ns.db": {"$regularExpression": {"pattern": "test", "options": "i"}}}, {"namespace": {"$regularExpression": {"pattern": "test.customers", "options": "i"}}}]}, {"event.operationType": {"$in": ["insert", "update", "replace", "delete"]}}]}}, {"$replaceRoot": {"newRoot": "$event"}}] (io.debezium.connector.mongodb.ChangeStreamPipelineFactory:56)
[2024-12-17 00:11:01,891] INFO [mongodb-source-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=172.30.2.147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=14206071, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Tue Dec 17 00:10:58 ICT 2024, lastUpdateTimeNanos=75878651585906} (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:01,893] INFO [mongodb-source-connector|task-0] No server chosen by ReadPreferenceServerSelector{readPreference=primary} from cluster description ClusterDescription{type=REPLICA_SET, connectionMode=MULTIPLE, serverDescriptions=[ServerDescription{address=172.30.2.147:27017, type=UNKNOWN, state=CONNECTING}]}. Waiting for 10000 ms before timing out (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:01,893] INFO [mongodb-source-connector|task-0] Adding discovered server linux-ip-147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:01,896] INFO [mongodb-source-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=linux-ip-147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=699046, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Tue Dec 17 00:10:58 ICT 2024, lastUpdateTimeNanos=75878657073483} (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:01,897] INFO [mongodb-source-connector|task-0] Server 172.30.2.147:27017 is no longer a member of the replica set.  Removing from client view of cluster. (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:01,898] INFO [mongodb-source-connector|task-0] Discovered replica set primary 172.30.2.147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:01,900] INFO [mongodb-source-connector|task-0] Discovered replica set primary linux-ip-147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:01,934] INFO [mongodb-source-connector|task-0] Valid resume token present, so no snapshot will be performed' (io.debezium.connector.mongodb.connection.MongoDbConnection:220)
[2024-12-17 00:11:01,937] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = fullfillment named = change-event-source-coordinator (io.debezium.util.Threads:270)
[2024-12-17 00:11:01,938] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = fullfillment named = blocking-snapshot (io.debezium.util.Threads:270)
[2024-12-17 00:11:01,938] INFO [mongodb-source-connector|task-0] Creating thread debezium-mongodbconnector-fullfillment-change-event-source-coordinator (io.debezium.util.Threads:287)
[2024-12-17 00:11:01,939] INFO [mongodb-source-connector|task-0] WorkerSourceTask{id=mongodb-source-connector-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:280)
[2024-12-17 00:11:01,940] INFO [mongodb-source-connector|task-0] Metrics registered (io.debezium.pipeline.ChangeEventSourceCoordinator:137)
[2024-12-17 00:11:01,940] INFO [mongodb-source-connector|task-0] Context created (io.debezium.pipeline.ChangeEventSourceCoordinator:140)
[2024-12-17 00:11:01,941] INFO [mongodb-source-connector|task-0] A previous offset indicating a completed snapshot has been found. (io.debezium.connector.mongodb.MongoDbSnapshotChangeEventSource:144)
[2024-12-17 00:11:01,941] INFO [mongodb-source-connector|task-0] According to the connector configuration, no snapshot will occur. (io.debezium.connector.mongodb.MongoDbSnapshotChangeEventSource:151)
[2024-12-17 00:11:01,941] INFO [mongodb-source-connector|task-0] Snapshot ended with SnapshotResult [status=SKIPPED, offset=MongoDbOffsetContext [sourceInfo=SourceInfo [initialSync=false, collectionId=null, position=Position [ts=Timestamp{value=7449041014456582145, seconds=1734365014, inc=1}, changeStreamSessionTxnId=null, resumeToken=zQAAAAJfZGF0YQC9AAAAODI2NzYwNEY1NjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNEY1NjQ5NkY2QjQ1OTk5NjQwMzcwMDAwMDQAAA==]]]] (io.debezium.pipeline.ChangeEventSourceCoordinator:298)
[2024-12-17 00:11:01,942] INFO [mongodb-source-connector|task-0] Connected metrics set to 'true' (io.debezium.pipeline.ChangeEventSourceCoordinator:477)
[2024-12-17 00:11:01,942] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = mongodb named = incremental-snapshot (io.debezium.util.Threads:270)
[2024-12-17 00:11:01,942] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,943] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,944] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,945] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,945] INFO [mongodb-source-connector|task-0] No incremental snapshot in progress, no action needed on start (io.debezium.connector.mongodb.snapshot.MongoDbIncrementalSnapshotChangeEventSource:262)
[2024-12-17 00:11:01,948] INFO [mongodb-source-connector|task-0] SignalProcessor started. Scheduling it every 5000ms (io.debezium.pipeline.signal.SignalProcessor:105)
[2024-12-17 00:11:01,949] INFO [mongodb-source-connector|task-0] Creating thread debezium-mongodbconnector-fullfillment-SignalProcessor (io.debezium.util.Threads:287)
[2024-12-17 00:11:01,957] INFO [mongodb-source-connector|task-0] Starting streaming (io.debezium.pipeline.ChangeEventSourceCoordinator:323)
[2024-12-17 00:11:01,957] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,958] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,959] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,960] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:01,961] INFO [mongodb-source-connector|task-0] Adding discovered server 172.30.2.147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:01,966] INFO [mongodb-source-connector|task-0] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.11.0"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-125-generic"}, "platform": "Java/Ubuntu/17.0.13+11-Ubuntu-2ubuntu122.04"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@5691a171, com.mongodb.Jep395RecordCodecProvider@415feae4, com.mongodb.KotlinCodecProvider@26839f41]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[172.30.2.147:27017], srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='rs0', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='10000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=javax.net.ssl.SSLContext@41db5703}, applicationName='null', compressorList=[], uuidRepresentation=STANDARD, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null} (org.mongodb.driver.client:71)
[2024-12-17 00:11:01,967] INFO [mongodb-source-connector|task-0] Reading change stream (io.debezium.connector.mongodb.MongoDbStreamingChangeEventSource:100)
[2024-12-17 00:11:01,967] INFO [mongodb-source-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=172.30.2.147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=1661367, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Tue Dec 17 00:10:58 ICT 2024, lastUpdateTimeNanos=75878727907159} (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:01,968] INFO [mongodb-source-connector|task-0] Adding discovered server linux-ip-147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:01,969] INFO [mongodb-source-connector|task-0] Effective change stream pipeline: [{"$replaceRoot": {"newRoot": {"namespace": {"$concat": ["$ns.db", ".", "$ns.coll"]}, "event": "$$ROOT"}}}, {"$match": {"$and": [{"$and": [{"event.ns.db": {"$regularExpression": {"pattern": "test", "options": "i"}}}, {"namespace": {"$regularExpression": {"pattern": "test.customers", "options": "i"}}}]}, {"event.operationType": {"$in": ["insert", "update", "replace", "delete"]}}]}}, {"$replaceRoot": {"newRoot": "$event"}}] (io.debezium.connector.mongodb.ChangeStreamPipelineFactory:56)
[2024-12-17 00:11:01,973] INFO [mongodb-source-connector|task-0] Resuming streaming from token 'zQAAAAJfZGF0YQC9AAAAODI2NzYwNEY1NjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNEY1NjQ5NkY2QjQ1OTk5NjQwMzcwMDAwMDQAAA==' (io.debezium.connector.mongodb.MongoDbStreamingChangeEventSource:207)
[2024-12-17 00:11:01,973] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = fullfillment named = replicator-fetcher (io.debezium.util.Threads:270)
[2024-12-17 00:11:01,973] INFO [mongodb-source-connector|task-0] Fetcher submitted for execution: io.debezium.connector.mongodb.events.BufferingChangeStreamCursor$EventFetcher@4c914ab7 @ java.util.concurrent.ThreadPoolExecutor@4ba26544[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] (io.debezium.connector.mongodb.events.BufferingChangeStreamCursor:367)
[2024-12-17 00:11:01,974] INFO [mongodb-source-connector|task-0] Creating thread debezium-mongodbconnector-fullfillment-replicator-fetcher-0 (io.debezium.util.Threads:287)
[2024-12-17 00:11:01,976] INFO [mongodb-source-connector|task-0] Server 172.30.2.147:27017 is no longer a member of the replica set.  Removing from client view of cluster. (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:01,977] INFO [mongodb-source-connector|task-0] Discovered replica set primary 172.30.2.147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:01,978] INFO [mongodb-source-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=linux-ip-147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=1296313, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Tue Dec 17 00:10:58 ICT 2024, lastUpdateTimeNanos=75878738393993} (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:01,979] INFO [mongodb-source-connector|task-0] No server chosen by ReadPreferenceServerSelector{readPreference=primary} from cluster description ClusterDescription{type=REPLICA_SET, connectionMode=MULTIPLE, serverDescriptions=[ServerDescription{address=172.30.2.147:27017, type=UNKNOWN, state=CONNECTING}]}. Waiting for 10000 ms before timing out (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:01,979] INFO [mongodb-source-connector|task-0] Discovered replica set primary linux-ip-147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:07,105] INFO [Producer clientId=mongo-source-cluster-offsets] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:11:07,110] INFO [mongodb-source-connector|task-0] [Producer clientId=connector-producer-mongodb-source-connector-0] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:11:07,110] INFO [Producer clientId=mongo-source-cluster-statuses] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:11:07,119] INFO [AdminClient clientId=mongo-source-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:11:07,120] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:11:07,122] INFO [Producer clientId=mongo-source-cluster-configs] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:11:07,124] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:11:07,130] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:11:07,131] INFO [mongodb-source-connector|task-0] [Producer clientId=connector-producer-mongodb-source-connector-0] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:11:07,132] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2024-12-17 00:11:11,243] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:87)
[2024-12-17 00:11:11,244] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:358)
[2024-12-17 00:11:11,267] INFO Stopped http_0.0.0.08083@68ff1d6e{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2024-12-17 00:11:11,270] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2024-12-17 00:11:11,305] INFO Stopped o.e.j.s.ServletContextHandler@62b056cb{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2024-12-17 00:11:11,306] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:387)
[2024-12-17 00:11:11,306] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:851)
[2024-12-17 00:11:11,307] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:808)
[2024-12-17 00:11:11,307] INFO [mongodb-source-connector|worker] Stopping connector mongodb-source-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 00:11:11,308] INFO [mongodb-source-connector|worker] Scheduled shutdown for WorkerConnector{id=mongodb-source-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 00:11:11,308] INFO [mongodb-source-connector|worker] Stopping MongoDB connector (io.debezium.connector.mongodb.MongoDbConnector:82)
[2024-12-17 00:11:11,309] INFO [mongodb-source-connector|worker] Stopped MongoDB connector (io.debezium.connector.mongodb.MongoDbConnector:86)
[2024-12-17 00:11:11,310] INFO [mongodb-source-connector|worker] Completed shutdown for WorkerConnector{id=mongodb-source-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 00:11:11,311] INFO [mongodb-source-connector|task-0] Stopping task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.Worker:1048)
[2024-12-17 00:11:11,459] INFO [mongodb-source-connector|task-0] Stopping down connector (io.debezium.connector.common.BaseSourceTask:432)
[2024-12-17 00:11:11,639] INFO [mongodb-source-connector|task-0] Awaiting fetcher thread termination (io.debezium.connector.mongodb.events.BufferingChangeStreamCursor:457)
[2024-12-17 00:11:13,054] INFO [mongodb-source-connector|task-0] Finished streaming (io.debezium.pipeline.ChangeEventSourceCoordinator:325)
[2024-12-17 00:11:13,055] INFO [mongodb-source-connector|task-0] Connected metrics set to 'false' (io.debezium.pipeline.ChangeEventSourceCoordinator:477)
[2024-12-17 00:11:13,063] INFO [mongodb-source-connector|task-0] SignalProcessor stopped (io.debezium.pipeline.signal.SignalProcessor:127)
[2024-12-17 00:11:13,064] INFO [mongodb-source-connector|task-0] Debezium ServiceRegistry stopped. (io.debezium.service.DefaultServiceRegistry:105)
[2024-12-17 00:11:13,065] INFO [mongodb-source-connector|task-0] [Producer clientId=connector-producer-mongodb-source-connector-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2024-12-17 00:11:13,090] INFO [mongodb-source-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 00:11:13,092] INFO [mongodb-source-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:11:13,092] INFO [mongodb-source-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:11:13,093] INFO [mongodb-source-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 00:11:13,094] INFO [mongodb-source-connector|task-0] App info kafka.producer for connector-producer-mongodb-source-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 00:11:13,114] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:317)
[2024-12-17 00:11:13,124] INFO [Producer clientId=mongo-source-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2024-12-17 00:11:13,133] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 00:11:13,134] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:11:13,134] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:11:13,134] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 00:11:13,136] INFO App info kafka.producer for mongo-source-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 00:11:13,142] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2024-12-17 00:11:13,143] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 00:11:13,624] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 00:11:13,624] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:11:13,625] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:11:13,625] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 00:11:13,634] INFO App info kafka.consumer for mongo-source-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 00:11:13,635] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:341)
[2024-12-17 00:11:13,636] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:407)
[2024-12-17 00:11:13,638] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:317)
[2024-12-17 00:11:13,639] INFO [Producer clientId=mongo-source-cluster-configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2024-12-17 00:11:13,651] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 00:11:13,652] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:11:13,653] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:11:13,653] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 00:11:13,655] INFO App info kafka.producer for mongo-source-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 00:11:13,656] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2024-12-17 00:11:13,657] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 00:11:13,920] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 00:11:13,920] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:11:13,921] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:11:13,921] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 00:11:13,929] INFO App info kafka.consumer for mongo-source-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 00:11:13,929] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:341)
[2024-12-17 00:11:13,929] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:412)
[2024-12-17 00:11:13,929] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:250)
[2024-12-17 00:11:13,932] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:261)
[2024-12-17 00:11:13,933] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:317)
[2024-12-17 00:11:13,934] INFO [Producer clientId=mongo-source-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2024-12-17 00:11:13,942] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 00:11:13,942] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:11:13,943] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:11:13,943] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 00:11:13,944] INFO App info kafka.producer for mongo-source-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 00:11:13,945] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2024-12-17 00:11:13,945] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 00:11:14,201] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 00:11:14,202] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:11:14,202] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:11:14,202] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 00:11:14,209] INFO App info kafka.consumer for mongo-source-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 00:11:14,209] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:341)
[2024-12-17 00:11:14,209] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:263)
[2024-12-17 00:11:14,209] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 00:11:14,210] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:11:14,210] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 00:11:14,211] INFO App info kafka.connect for 172.30.2.147:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 00:11:14,211] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:271)
[2024-12-17 00:11:14,215] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Member connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254 sending LeaveGroup request to coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1174)
[2024-12-17 00:11:14,217] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1056)
[2024-12-17 00:11:14,218] WARN [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1141)
[2024-12-17 00:11:14,218] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 00:11:14,218] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:11:14,219] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 00:11:14,222] INFO App info kafka.connect for connect-172.30.2.147:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 00:11:14,225] INFO App info kafka.admin.client for mongo-source-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 00:11:14,227] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 00:11:14,228] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:11:14,228] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 00:11:14,229] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:394)
[2024-12-17 00:11:14,235] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:858)
[2024-12-17 00:11:14,236] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:92)
[2024-12-17 00:11:16,405] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2024-12-17 00:11:16,418] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/opt/kafka/bin/../logs, -Dlog4j.configuration=file:/opt/kafka/bin/../config/connect-log4j.properties
	jvm.spec = Ubuntu, OpenJDK 64-Bit Server VM, 17.0.13, 17.0.13+11-Ubuntu-2ubuntu122.04
	jvm.classpath = /opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-sync-4.11.0.jar:/opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar:/opt/kafka/plugins/debezium-connector-mongodb/bson-record-codec-4.11.0.jar:/opt/kafka/plugins/debezium-connector-mongodb/bson-4.11.0.jar:/opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-core-4.11.0.jar:/opt/kafka/plugins/debezium-connector-mongodb/debezium-sink-3.0.4.Final.jar:/opt/kafka/plugins/debezium-connector-mongodb/debezium-api-3.0.4.Final.jar:/opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar:/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.12.0.jar:/opt/kafka/bin/../libs/caffeine-2.9.3.jar:/opt/kafka/bin/../libs/commons-beanutils-1.9.4.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-collections-3.2.2.jar:/opt/kafka/bin/../libs/commons-digester-2.1.jar:/opt/kafka/bin/../libs/commons-io-2.14.0.jar:/opt/kafka/bin/../libs/commons-lang3-3.12.0.jar:/opt/kafka/bin/../libs/commons-logging-1.2.jar:/opt/kafka/bin/../libs/commons-validator-1.7.jar:/opt/kafka/bin/../libs/connect-api-3.9.0.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-3.9.0.jar:/opt/kafka/bin/../libs/connect-json-3.9.0.jar:/opt/kafka/bin/../libs/connect-mirror-3.9.0.jar:/opt/kafka/bin/../libs/connect-mirror-client-3.9.0.jar:/opt/kafka/bin/../libs/connect-runtime-3.9.0.jar:/opt/kafka/bin/../libs/connect-transforms-3.9.0.jar:/opt/kafka/bin/../libs/error_prone_annotations-2.10.0.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.16.2.jar:/opt/kafka/bin/../libs/jackson-core-2.16.2.jar:/opt/kafka/bin/../libs/jackson-databind-2.16.2.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/opt/kafka/bin/../libs/jackson-module-afterburner-2.16.2.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.2.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/opt/kafka/bin/../libs/javassist-3.29.2-GA.jar:/opt/kafka/bin/../libs/javax.activation-api-1.2.0.jar:/opt/kafka/bin/../libs/javax.annotation-api-1.3.2.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.1.jar:/opt/kafka/bin/../libs/jersey-client-2.39.1.jar:/opt/kafka/bin/../libs/jersey-common-2.39.1.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.39.1.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/opt/kafka/bin/../libs/jersey-hk2-2.39.1.jar:/opt/kafka/bin/../libs/jersey-server-2.39.1.jar:/opt/kafka/bin/../libs/jetty-client-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-http-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-io-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-security-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-server-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-util-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jline-3.25.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/jose4j-0.9.4.jar:/opt/kafka/bin/../libs/jsr305-3.0.2.jar:/opt/kafka/bin/../libs/kafka-clients-3.9.0.jar:/opt/kafka/bin/../libs/kafka-group-coordinator-3.9.0.jar:/opt/kafka/bin/../libs/kafka-group-coordinator-api-3.9.0.jar:/opt/kafka/bin/../libs/kafka-metadata-3.9.0.jar:/opt/kafka/bin/../libs/kafka-raft-3.9.0.jar:/opt/kafka/bin/../libs/kafka-server-3.9.0.jar:/opt/kafka/bin/../libs/kafka-server-common-3.9.0.jar:/opt/kafka/bin/../libs/kafka-shell-3.9.0.jar:/opt/kafka/bin/../libs/kafka-storage-3.9.0.jar:/opt/kafka/bin/../libs/kafka-storage-api-3.9.0.jar:/opt/kafka/bin/../libs/kafka-streams-3.9.0.jar:/opt/kafka/bin/../libs/kafka-streams-examples-3.9.0.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-3.9.0.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-3.9.0.jar:/opt/kafka/bin/../libs/kafka-tools-3.9.0.jar:/opt/kafka/bin/../libs/kafka-tools-api-3.9.0.jar:/opt/kafka/bin/../libs/kafka-transaction-coordinator-3.9.0.jar:/opt/kafka/bin/../libs/kafka_2.13-3.9.0.jar:/opt/kafka/bin/../libs/lz4-java-1.8.0.jar:/opt/kafka/bin/../libs/maven-artifact-3.9.6.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-transport-classes-epoll-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.111.Final.jar:/opt/kafka/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/pcollections-4.0.1.jar:/opt/kafka/bin/../libs/plexus-utils-3.5.1.jar:/opt/kafka/bin/../libs/protobuf-java-3.25.5.jar:/opt/kafka/bin/../libs/reflections-0.10.2.jar:/opt/kafka/bin/../libs/reload4j-1.2.25.jar:/opt/kafka/bin/../libs/rocksdbjni-7.9.2.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/opt/kafka/bin/../libs/scala-library-2.13.14.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.5.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.14.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.36.jar:/opt/kafka/bin/../libs/slf4j-reload4j-1.7.36.jar:/opt/kafka/bin/../libs/snappy-java-1.1.10.5.jar:/opt/kafka/bin/../libs/swagger-annotations-2.2.8.jar:/opt/kafka/bin/../libs/trogdor-3.9.0.jar:/opt/kafka/bin/../libs/zookeeper-3.8.4.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.8.4.jar:/opt/kafka/bin/../libs/zstd-jni-1.5.6-4.jar
	os.spec = Linux, amd64, 5.15.0-125-generic
	os.vcpus = 2
 (org.apache.kafka.connect.runtime.WorkerInfo:72)
[2024-12-17 00:11:16,420] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2024-12-17 00:11:16,470] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:16,548] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 00:11:16,887] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:16,889] INFO Loading plugin from: /opt/kafka/plugins/hibernate-core-6.4.1.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:16,902] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 00:11:16,970] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/hibernate-core-6.4.1.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:16,971] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,009] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 00:11:17,027] ERROR Failed to discover Converter in /opt/kafka/plugins/debezium-connector-jdbc (org.apache.kafka.connect.runtime.isolation.PluginScanner:139)
java.util.ServiceConfigurationError: org.apache.kafka.connect.storage.Converter: Provider io.debezium.converters.CloudEventsConverter could not be instantiated
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:586)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:813)
	at java.base/java.util.ServiceLoader$ProviderImpl.get(ServiceLoader.java:729)
	at java.base/java.util.ServiceLoader$3.next(ServiceLoader.java:1403)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:177)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:61)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:84)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.util.ServiceConfigurationError: io.debezium.converters.spi.CloudEventsProvider: io.debezium.connector.mongodb.converters.MongoDbCloudEventsProvider not a subtype
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:593)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1244)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)
	at io.debezium.converters.CloudEventsConverter.<clinit>(CloudEventsConverter.java:135)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:789)
	... 13 more
[2024-12-17 00:11:17,111] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,381] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-sync-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,408] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-sync-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,408] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,443] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,444] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/bson-record-codec-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,464] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/bson-record-codec-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,465] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/bson-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,484] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/bson-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,485] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-core-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,516] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-core-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,517] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-sink-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,537] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-sink-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,537] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-api-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,557] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-api-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,558] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,570] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 00:11:17,573] ERROR Failed to discover Converter in /opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:139)
java.util.ServiceConfigurationError: org.apache.kafka.connect.storage.Converter: Provider io.debezium.converters.CloudEventsConverter could not be instantiated
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:586)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:813)
	at java.base/java.util.ServiceLoader$ProviderImpl.get(ServiceLoader.java:729)
	at java.base/java.util.ServiceLoader$3.next(ServiceLoader.java:1403)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:177)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:61)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:84)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.util.ServiceConfigurationError: io.debezium.converters.spi.CloudEventsProvider: io.debezium.connector.mongodb.converters.MongoDbCloudEventsProvider not a subtype
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:593)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1244)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)
	at io.debezium.converters.CloudEventsConverter.<clinit>(CloudEventsConverter.java:135)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:789)
	... 13 more
[2024-12-17 00:11:17,659] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,660] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/waffle-jna-3.2.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,683] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/waffle-jna-3.2.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,684] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jaxb-core-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,706] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-core-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,707] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/txw2-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,729] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/txw2-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,729] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/ojdbc11-21.15.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,749] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/ojdbc11-21.15.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,797] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/c3p0-0.9.5.5.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,824] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/c3p0-0.9.5.5.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,825] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/angus-activation-2.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,837] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/angus-activation-2.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,838] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jandex-3.1.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,855] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jandex-3.1.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,856] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-c3p0-6.4.8.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,870] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-c3p0-6.4.8.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,870] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mysql-connector-j-9.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,883] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mysql-connector-j-9.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,887] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/error_prone_annotations-2.10.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,895] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/error_prone_annotations-2.10.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,895] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.activation-api-2.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,903] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.activation-api-2.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,903] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/byte-buddy-1.14.11.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,910] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/byte-buddy-1.14.11.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,911] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/istack-commons-runtime-4.1.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,917] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/istack-commons-runtime-4.1.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,918] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mssql-jdbc-12.4.2.jre8.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,925] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mssql-jdbc-12.4.2.jre8.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,962] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mchange-commons-java-0.2.19.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,970] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mchange-commons-java-0.2.19.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,971] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/caffeine-2.9.3.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,977] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/caffeine-2.9.3.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,977] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jaxb-runtime-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,984] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-runtime-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,984] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jboss-logging-3.5.0.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:17,991] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jboss-logging-3.5.0.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:17,991] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.persistence-api-3.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:18,001] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.persistence-api-3.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:18,001] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.xml.bind-api-4.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:18,008] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.xml.bind-api-4.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:18,008] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.inject-api-2.0.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:18,015] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.inject-api-2.0.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:18,015] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mariadb-java-client-3.2.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:18,022] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mariadb-java-client-3.2.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:18,024] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jna-platform-5.12.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:18,030] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jna-platform-5.12.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:18,031] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/antlr4-runtime-4.10.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:18,037] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/antlr4-runtime-4.10.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:18,038] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jcl-over-slf4j-1.7.36.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:18,044] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jcl-over-slf4j-1.7.36.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:18,044] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-commons-annotations-6.0.6.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:18,051] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-commons-annotations-6.0.6.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:18,051] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/postgresql-42.6.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:18,058] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/postgresql-42.6.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:18,061] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.transaction-api-2.0.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:18,068] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.transaction-api-2.0.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:18,068] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-sink-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:18,075] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-sink-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:18,075] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-api-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:18,081] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-api-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:18,082] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/classmate-1.5.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:18,097] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/classmate-1.5.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:18,097] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-connector-jdbc-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:18,117] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-connector-jdbc-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:18,118] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:18,138] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 00:11:18,139] ERROR Failed to discover Converter in /opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:139)
java.util.ServiceConfigurationError: org.apache.kafka.connect.storage.Converter: Provider io.debezium.converters.CloudEventsConverter could not be instantiated
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:586)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:813)
	at java.base/java.util.ServiceLoader$ProviderImpl.get(ServiceLoader.java:729)
	at java.base/java.util.ServiceLoader$3.next(ServiceLoader.java:1403)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:177)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:61)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:84)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.util.ServiceConfigurationError: io.debezium.converters.spi.CloudEventsProvider: io.debezium.connector.mongodb.converters.MongoDbCloudEventsProvider not a subtype
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:593)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1244)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)
	at io.debezium.converters.CloudEventsConverter.<clinit>(CloudEventsConverter.java:135)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:789)
	... 13 more
[2024-12-17 00:11:18,194] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:18,195] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jna-5.12.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:18,204] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jna-5.12.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:18,204] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-core-6.4.8.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:18,214] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-core-6.4.8.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:18,214] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:18,226] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:18,227] INFO Scanning plugins with ServiceLoaderScanner took 1759 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:71)
[2024-12-17 00:11:18,230] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:19,049] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:19,050] INFO Loading plugin from: /opt/kafka/plugins/hibernate-core-6.4.1.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:20,243] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/hibernate-core-6.4.1.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:20,243] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:23,334] ERROR Failed to discover Converter in /opt/kafka/plugins/debezium-connector-jdbc: Unable to instantiate CloudEventsConverter: Plugin class has a dependency which is missing or invalid (org.apache.kafka.connect.runtime.isolation.ReflectionScanner:139)
java.lang.NoClassDefFoundError: Could not initialize class io.debezium.converters.CloudEventsConverter
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.versionFor(ReflectionScanner.java:74)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.getPluginDesc(ReflectionScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.scanPlugins(ReflectionScanner.java:90)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:92)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.lang.ExceptionInInitializerError: Exception java.util.ServiceConfigurationError: io.debezium.converters.spi.CloudEventsProvider: io.debezium.connector.mongodb.converters.MongoDbCloudEventsProvider not a subtype [in thread "main"]
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:593)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1244)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)
	at io.debezium.converters.CloudEventsConverter.<clinit>(CloudEventsConverter.java:135)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:789)
	at java.base/java.util.ServiceLoader$ProviderImpl.get(ServiceLoader.java:729)
	at java.base/java.util.ServiceLoader$3.next(ServiceLoader.java:1403)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:177)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:61)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:84)
	... 5 more
[2024-12-17 00:11:23,339] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:23,350] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-sync-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:23,370] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-sync-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:23,370] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:23,411] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:23,411] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/bson-record-codec-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:23,414] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/bson-record-codec-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:23,414] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/bson-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:23,453] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/bson-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:23,454] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-core-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:23,593] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-core-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:23,593] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-sink-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:23,598] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-sink-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:23,599] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-api-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:23,604] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-api-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:23,604] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:23,697] ERROR Failed to discover Converter in /opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar: Unable to instantiate CloudEventsConverter: Plugin class has a dependency which is missing or invalid (org.apache.kafka.connect.runtime.isolation.ReflectionScanner:139)
java.lang.NoClassDefFoundError: Could not initialize class io.debezium.converters.CloudEventsConverter
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.versionFor(ReflectionScanner.java:74)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.getPluginDesc(ReflectionScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.scanPlugins(ReflectionScanner.java:90)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:92)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.lang.ExceptionInInitializerError: Exception java.util.ServiceConfigurationError: io.debezium.converters.spi.CloudEventsProvider: io.debezium.connector.mongodb.converters.MongoDbCloudEventsProvider not a subtype [in thread "main"]
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:593)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1244)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)
	at io.debezium.converters.CloudEventsConverter.<clinit>(CloudEventsConverter.java:135)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:789)
	at java.base/java.util.ServiceLoader$ProviderImpl.get(ServiceLoader.java:729)
	at java.base/java.util.ServiceLoader$3.next(ServiceLoader.java:1403)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:177)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:61)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:84)
	... 5 more
[2024-12-17 00:11:23,700] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:23,700] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/waffle-jna-3.2.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:23,708] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/waffle-jna-3.2.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:23,708] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jaxb-core-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:23,718] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-core-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:23,718] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/txw2-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:23,725] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/txw2-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:23,726] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/ojdbc11-21.15.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,028] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/ojdbc11-21.15.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,028] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/c3p0-0.9.5.5.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,063] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/c3p0-0.9.5.5.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,063] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/angus-activation-2.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,066] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/angus-activation-2.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,067] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jandex-3.1.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,086] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jandex-3.1.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,086] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-c3p0-6.4.8.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,089] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-c3p0-6.4.8.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,089] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mysql-connector-j-9.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,218] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mysql-connector-j-9.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,219] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/error_prone_annotations-2.10.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,221] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/error_prone_annotations-2.10.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,221] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.activation-api-2.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,226] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.activation-api-2.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,226] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/byte-buddy-1.14.11.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,451] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/byte-buddy-1.14.11.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,451] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/istack-commons-runtime-4.1.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,455] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/istack-commons-runtime-4.1.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,455] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mssql-jdbc-12.4.2.jre8.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,550] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mssql-jdbc-12.4.2.jre8.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,557] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mchange-commons-java-0.2.19.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,597] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mchange-commons-java-0.2.19.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,597] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/caffeine-2.9.3.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,655] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/caffeine-2.9.3.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,656] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jaxb-runtime-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,700] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-runtime-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,700] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jboss-logging-3.5.0.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,706] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jboss-logging-3.5.0.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,706] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.persistence-api-3.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,715] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.persistence-api-3.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,715] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.xml.bind-api-4.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,723] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.xml.bind-api-4.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,723] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.inject-api-2.0.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,724] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.inject-api-2.0.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,725] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mariadb-java-client-3.2.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,756] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mariadb-java-client-3.2.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,757] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jna-platform-5.12.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,830] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jna-platform-5.12.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,831] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/antlr4-runtime-4.10.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,850] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/antlr4-runtime-4.10.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,850] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jcl-over-slf4j-1.7.36.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,853] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jcl-over-slf4j-1.7.36.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,853] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-commons-annotations-6.0.6.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,858] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-commons-annotations-6.0.6.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,859] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/postgresql-42.6.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,907] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/postgresql-42.6.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,908] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.transaction-api-2.0.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,909] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.transaction-api-2.0.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,910] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-sink-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,912] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-sink-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,913] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-api-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,916] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-api-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,916] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/classmate-1.5.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,921] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/classmate-1.5.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,921] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-connector-jdbc-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:24,945] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-connector-jdbc-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:24,945] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:25,018] ERROR Failed to discover Converter in /opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar: Unable to instantiate CloudEventsConverter: Plugin class has a dependency which is missing or invalid (org.apache.kafka.connect.runtime.isolation.ReflectionScanner:139)
java.lang.NoClassDefFoundError: Could not initialize class io.debezium.converters.CloudEventsConverter
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.versionFor(ReflectionScanner.java:74)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.getPluginDesc(ReflectionScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.scanPlugins(ReflectionScanner.java:90)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:92)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.lang.ExceptionInInitializerError: Exception java.util.ServiceConfigurationError: io.debezium.converters.spi.CloudEventsProvider: io.debezium.connector.mongodb.converters.MongoDbCloudEventsProvider not a subtype [in thread "main"]
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:593)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1244)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)
	at io.debezium.converters.CloudEventsConverter.<clinit>(CloudEventsConverter.java:135)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:789)
	at java.base/java.util.ServiceLoader$ProviderImpl.get(ServiceLoader.java:729)
	at java.base/java.util.ServiceLoader$3.next(ServiceLoader.java:1403)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:177)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:61)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:84)
	... 5 more
[2024-12-17 00:11:25,023] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:25,023] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jna-5.12.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:25,036] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jna-5.12.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:25,036] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-core-6.4.8.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:25,611] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-core-6.4.8.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:25,611] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 00:11:28,445] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 00:11:28,446] INFO Scanning plugins with ReflectionScanner took 10216 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:71)
[2024-12-17 00:11:28,451] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/opt/kafka/plugins/debezium-connector-mongodb/	io.debezium.connector.mongodb.MongoDbSinkConnector	sink	3.0.4.Final
file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar	io.debezium.connector.mongodb.MongoDbSinkConnector	sink	3.0.4.Final
classpath	io.debezium.connector.mongodb.MongoDbSinkConnector	sink	3.0.4.Final
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:123)
[2024-12-17 00:11:28,453] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,453] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,453] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,453] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,453] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,453] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,454] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,454] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,454] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,454] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,454] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,454] INFO Added plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,454] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,455] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,455] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,455] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,455] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,455] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,455] INFO Added plugin 'io.debezium.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,455] INFO Added plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,455] INFO Added plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,455] INFO Added plugin 'io.debezium.connector.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,456] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,456] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,456] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,456] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,456] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,456] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,456] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,456] INFO Added plugin 'io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,457] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,457] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,457] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,457] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,457] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,457] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,457] INFO Added plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,457] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,457] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,458] INFO Added plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,458] INFO Added plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,458] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,458] INFO Added plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,458] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,458] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,458] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,459] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,459] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,459] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,459] INFO Added plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,459] INFO Added plugin 'io.debezium.connector.jdbc.transforms.ConvertCloudEventToSaveableForm' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,460] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,460] INFO Added plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,460] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,460] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,460] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,460] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,460] INFO Added plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,460] INFO Added plugin 'io.debezium.connector.mongodb.transforms.ExtractNewDocumentState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,460] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,460] INFO Added plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,460] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,460] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,460] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,460] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,460] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,460] INFO Added plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,461] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,461] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 00:11:28,467] INFO Added alias 'ExtractNewDocumentState' to plugin 'io.debezium.connector.mongodb.transforms.ExtractNewDocumentState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,468] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,468] INFO Added alias 'CloudEventsConverter' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,468] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,468] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,468] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,468] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,469] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,469] INFO Added alias 'HeaderToValue' to plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,469] INFO Added alias 'PartitionRouting' to plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,473] INFO Added alias 'MongoDbSink' to plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,475] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,475] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,476] INFO Added alias 'MongoDbConnector' to plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,476] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,476] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,476] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,477] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,477] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,477] INFO Added alias 'ExtractSchemaToNewRecord' to plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,478] INFO Added alias 'BinaryData' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,478] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,478] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,478] INFO Added alias 'CloudEvents' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,479] INFO Added alias 'TimezoneConverter' to plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,479] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,479] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,479] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,480] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,480] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,480] INFO Added alias 'DebeziumMongoDb' to plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,481] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,481] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,482] INFO Added alias 'DebeziumMongoDbConnectRestExtension' to plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,482] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,482] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,482] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,483] INFO Added alias 'ExtractChangedRecordState' to plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,483] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,483] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,484] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,484] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,484] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,484] INFO Added alias 'JdbcSinkConnector' to plugin 'io.debezium.connector.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,485] INFO Added alias 'JdbcSink' to plugin 'io.debezium.connector.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,485] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,485] INFO Added alias 'MongoDbSinkConnector' to plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,486] INFO Added alias 'MongoDb' to plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,486] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,486] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,486] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,487] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,487] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,488] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,488] INFO Added alias 'SchemaChangeEventFilter' to plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,488] INFO Added alias 'ConvertCloudEventToSaveableForm' to plugin 'io.debezium.connector.jdbc.transforms.ConvertCloudEventToSaveableForm' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,488] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,489] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,489] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,489] INFO Added alias 'ActivateTracingSpan' to plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,490] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,490] INFO Added alias 'BinaryDataConverter' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,490] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,490] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,491] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,491] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,491] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,492] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,492] INFO Added alias 'MongoEventRouter' to plugin 'io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,492] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,492] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 00:11:28,532] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = mongo-source-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [HTTP://0.0.0.0:8083]
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [/opt/kafka/plugins, /opt/kafka/plugins/debezium-connector-mongodb, /opt/kafka/plugins/debezium-connector-jdbc]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = 172.30.2.147
	rest.advertised.listener = null
	rest.advertised.port = 8083
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:371)
[2024-12-17 00:11:28,540] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:281)
[2024-12-17 00:11:28,549] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:371)
[2024-12-17 00:11:28,630] INFO These configurations '[config.storage.topic, listeners, rest.advertised.host.name, status.storage.topic, group.id, rest.advertised.port, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2024-12-17 00:11:28,632] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 00:11:28,632] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 00:11:28,632] INFO Kafka startTimeMs: 1734369088631 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 00:11:29,127] INFO Kafka cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.connect.runtime.WorkerConfig:298)
[2024-12-17 00:11:29,128] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 00:11:29,138] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 00:11:29,138] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 00:11:29,139] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 00:11:29,145] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [HTTP://0.0.0.0:8083]
	response.http.headers.config = 
	rest.advertised.host.name = 172.30.2.147
	rest.advertised.listener = null
	rest.advertised.port = 8083
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:371)
[2024-12-17 00:11:29,158] INFO Logging initialized @13761ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2024-12-17 00:11:29,201] INFO Added connector for HTTP://0.0.0.0:8083 (org.apache.kafka.connect.runtime.rest.RestServer:125)
[2024-12-17 00:11:29,202] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:196)
[2024-12-17 00:11:29,226] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 17.0.13+11-Ubuntu-2ubuntu122.04 (org.eclipse.jetty.server.Server:375)
[2024-12-17 00:11:29,258] INFO Started http_0.0.0.08083@50195abf{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2024-12-17 00:11:29,259] INFO Started @13863ms (org.eclipse.jetty.server.Server:415)
[2024-12-17 00:11:29,280] INFO Advertised URI: http://172.30.2.147:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2024-12-17 00:11:29,281] INFO REST server listening at http://0.0.0.0:8083/, advertising URL http://172.30.2.147:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:216)
[2024-12-17 00:11:29,281] INFO Advertised URI: http://172.30.2.147:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2024-12-17 00:11:29,282] INFO REST admin endpoints at http://172.30.2.147:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2024-12-17 00:11:29,282] INFO Advertised URI: http://172.30.2.147:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2024-12-17 00:11:29,283] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:45)
[2024-12-17 00:11:29,289] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 00:11:29,308] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 00:11:29,309] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 00:11:29,309] INFO Kafka startTimeMs: 1734369089308 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 00:11:29,317] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 00:11:29,318] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 00:11:29,338] INFO Advertised URI: http://172.30.2.147:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2024-12-17 00:11:29,371] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 00:11:29,372] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 00:11:29,372] INFO Kafka startTimeMs: 1734369089371 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 00:11:29,376] INFO Kafka Connect worker initialization took 12963ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2024-12-17 00:11:29,376] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:67)
[2024-12-17 00:11:29,380] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2024-12-17 00:11:29,391] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:375)
[2024-12-17 00:11:29,393] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:233)
[2024-12-17 00:11:29,394] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:232)
[2024-12-17 00:11:29,394] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:254)
[2024-12-17 00:11:29,395] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = mongo-source-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:371)
[2024-12-17 00:11:29,413] INFO These configurations '[config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, group.id, rest.advertised.port, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2024-12-17 00:11:29,413] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 00:11:29,414] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 00:11:29,414] INFO Kafka startTimeMs: 1734369089413 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 00:11:29,443] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:238)
[2024-12-17 00:11:29,491] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = mongo-source-cluster-offsets
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-17 00:11:29,514] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2024-12-17 00:11:29,514] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2024-12-17 00:11:29,516] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2024-12-17 00:11:29,553] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 00:11:29,629] INFO These configurations '[group.id, rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-17 00:11:29,630] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 00:11:29,630] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 00:11:29,630] INFO Kafka startTimeMs: 1734369089629 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 00:11:29,651] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = mongo-source-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mongo-source-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2024-12-17 00:11:29,677] INFO [Producer clientId=mongo-source-cluster-offsets] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 00:11:29,688] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 00:11:29,777] INFO These configurations '[rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2024-12-17 00:11:29,777] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 00:11:29,778] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 00:11:29,778] INFO Kafka startTimeMs: 1734369089777 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 00:11:29,807] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 00:11:29,825] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:579)
[2024-12-17 00:11:29,832] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,836] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,836] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,836] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,842] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,842] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,842] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,842] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,845] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,845] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,846] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,847] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,848] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,849] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,850] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,850] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,851] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,851] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,851] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,852] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,852] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,852] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,852] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,853] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,854] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:29,933] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,936] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,937] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,938] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,938] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,938] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,939] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,939] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,943] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,944] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,944] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,944] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,945] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,945] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,946] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,946] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,946] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,947] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,947] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,947] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,948] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,948] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,951] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,952] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:29,952] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:30,125] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:311)
[2024-12-17 00:11:30,126] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:313)
[2024-12-17 00:11:30,126] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:249)
[2024-12-17 00:11:30,127] INFO Worker started (org.apache.kafka.connect.runtime.Worker:243)
[2024-12-17 00:11:30,127] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:254)
[2024-12-17 00:11:30,143] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = mongo-source-cluster-statuses
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-17 00:11:30,144] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 00:11:30,159] INFO These configurations '[group.id, rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-17 00:11:30,159] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 00:11:30,160] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 00:11:30,160] INFO Kafka startTimeMs: 1734369090159 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 00:11:30,161] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = mongo-source-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mongo-source-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2024-12-17 00:11:30,161] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 00:11:30,221] INFO [Producer clientId=mongo-source-cluster-statuses] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 00:11:30,224] INFO These configurations '[rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2024-12-17 00:11:30,227] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 00:11:30,227] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 00:11:30,227] INFO Kafka startTimeMs: 1734369090224 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 00:11:30,246] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 00:11:30,253] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:579)
[2024-12-17 00:11:30,253] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:30,255] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:30,255] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:30,255] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:30,255] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:30,280] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:30,281] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:30,281] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:30,281] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:30,281] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:30,469] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:311)
[2024-12-17 00:11:30,469] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:313)
[2024-12-17 00:11:30,474] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:378)
[2024-12-17 00:11:30,474] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:254)
[2024-12-17 00:11:30,556] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = mongo-source-cluster-configs
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-17 00:11:30,557] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 00:11:30,574] INFO These configurations '[group.id, rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-17 00:11:30,575] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 00:11:30,575] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 00:11:30,575] INFO Kafka startTimeMs: 1734369090574 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 00:11:30,576] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = mongo-source-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mongo-source-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2024-12-17 00:11:30,579] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 00:11:30,599] INFO [Producer clientId=mongo-source-cluster-configs] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 00:11:30,600] INFO These configurations '[rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2024-12-17 00:11:30,605] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 00:11:30,605] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 00:11:30,605] INFO Kafka startTimeMs: 1734369090605 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 00:11:30,612] INFO Started o.e.j.s.ServletContextHandler@75d773fa{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2024-12-17 00:11:30,613] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:303)
[2024-12-17 00:11:30,613] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:77)
[2024-12-17 00:11:30,619] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 00:11:30,623] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:579)
[2024-12-17 00:11:30,627] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 00:11:30,662] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 00:11:30,703] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,711] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,712] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,715] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,718] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,722] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,725] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,727] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,730] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,735] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,737] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,741] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,743] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,746] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,747] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,747] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,748] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,751] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,752] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,756] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,757] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,757] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,758] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,758] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,758] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,759] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,760] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,764] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,765] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,766] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,766] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,767] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,767] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,768] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,768] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,769] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,774] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,775] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,775] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,776] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,776] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,776] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,777] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,777] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,778] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,778] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,779] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,779] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,780] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,782] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,783] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,786] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,786] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,788] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,788] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,788] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,789] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,792] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,792] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,793] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,793] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,796] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,797] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,798] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,798] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,798] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,799] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,812] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,815] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,816] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,818] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,819] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,825] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,825] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,825] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,826] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,826] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,826] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,827] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,828] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,829] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,832] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,832] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,836] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,837] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,841] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,843] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,844] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,849] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:11:30,855] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:311)
[2024-12-17 00:11:30,856] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:313)
[2024-12-17 00:11:30,856] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:402)
[2024-12-17 00:11:30,877] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 00:11:30,881] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 00:11:30,884] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:11:30,884] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:11:30,899] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:11:30,905] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=412, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:11:30,945] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=412, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:11:30,946] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 412 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=656, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:11:30,948] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:387)
[2024-12-17 00:11:30,949] WARN [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1811)
[2024-12-17 00:11:30,949] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Current config state offset -1 is behind group assignment 656, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1884)
[2024-12-17 00:11:30,957] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 656 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1911)
[2024-12-17 00:11:30,957] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 656 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:11:30,963] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mongodb-source-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 00:11:30,965] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 00:11:30,971] INFO [mongodb-source-connector|worker] Creating connector mongodb-source-connector of type io.debezium.connector.mongodb.MongoDbConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 00:11:30,977] INFO [mongodb-source-connector|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-17 00:11:30,979] INFO [mongodb-source-connector|task-0] Creating task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 00:11:30,982] INFO [mongodb-source-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 00:11:30,988] INFO [mongodb-source-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:11:30,991] INFO [mongodb-source-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:11:31,002] INFO [mongodb-source-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.MongoDbConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:371)
[2024-12-17 00:11:31,005] INFO [mongodb-source-connector|task-0] Instantiated task mongodb-source-connector-0 with version 3.0.4.Final of type io.debezium.connector.mongodb.MongoDbConnectorTask (org.apache.kafka.connect.runtime.Worker:665)
[2024-12-17 00:11:31,006] INFO [mongodb-source-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 00:11:31,006] INFO [mongodb-source-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 00:11:31,006] INFO [mongodb-source-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-source-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:680)
[2024-12-17 00:11:31,006] INFO [mongodb-source-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-source-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:686)
[2024-12-17 00:11:31,010] INFO [mongodb-source-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mongodb-source-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:691)
[2024-12-17 00:11:31,019] INFO [mongodb-source-connector|worker] Instantiated connector mongodb-source-connector with version 3.0.4.Final of type class io.debezium.connector.mongodb.MongoDbConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 00:11:31,020] WARN [mongodb-source-connector|task-0] The deleted record handling configs "drop.tombstones" and "delete.handling.mode" have been deprecated, please use "delete.tombstone.handling.mode" instead. (io.debezium.transforms.AbstractExtractNewRecordState:110)
[2024-12-17 00:11:31,020] INFO [mongodb-source-connector|worker] Finished creating connector mongodb-source-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 00:11:31,035] WARN [mongodb-source-connector|task-0] Configuration key whitelist is deprecated and may be removed in the future.  Please update your configuration to use include instead. (org.apache.kafka.common.utils.ConfigUtils:114)
[2024-12-17 00:11:31,036] INFO [mongodb-source-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{io.debezium.connector.mongodb.transforms.ExtractNewDocumentState, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.TimestampConverter$Value} (org.apache.kafka.connect.runtime.Worker:1795)
[2024-12-17 00:11:31,038] INFO [mongodb-source-connector|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-17 00:11:31,044] INFO [mongodb-source-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:11:31,050] INFO [mongodb-source-connector|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-mongodb-source-connector-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-17 00:11:31,054] INFO [mongodb-source-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 00:11:31,066] INFO [mongodb-source-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-17 00:11:31,066] INFO [mongodb-source-connector|task-0] Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 00:11:31,066] INFO [mongodb-source-connector|task-0] Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 00:11:31,067] INFO [mongodb-source-connector|task-0] Kafka startTimeMs: 1734369091066 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 00:11:31,082] INFO [mongodb-source-connector|worker] Successfully started MongoDB connector (io.debezium.connector.mongodb.MongoDbConnector:67)
[2024-12-17 00:11:31,088] INFO [mongodb-source-connector|task-0] Starting MongoDbConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:245)
[2024-12-17 00:11:31,089] INFO [mongodb-source-connector|task-0] [Producer clientId=connector-producer-mongodb-source-connector-0] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 00:11:31,096] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:11:31,101] INFO [mongodb-source-connector|task-0]    connector.class = io.debezium.connector.mongodb.MongoDbConnector (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,101] INFO [mongodb-source-connector|task-0]    collection.include.list = test.customers (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,102] INFO [mongodb-source-connector|task-0]    transforms.unwrap.delete.handling.mode = drop (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,102] INFO [mongodb-source-connector|task-0]    transforms.unwrap.array.encoding = array (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,102] INFO [mongodb-source-connector|task-0]    mongodb.connection.string = ******** (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,102] INFO [mongodb-source-connector|task-0]    tasks.max = 1 (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,102] INFO [mongodb-source-connector|task-0]    transforms = unwrap,extractNew,convertDate (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,102] INFO [mongodb-source-connector|task-0]    transforms.unwrap.add.source.fields = db,collection (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,103] INFO [mongodb-source-connector|task-0]    topic.prefix = fullfillment (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,103] INFO [mongodb-source-connector|task-0]    transforms.convertDate.format = yyyy-MM-dd HH:mm:ss (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,103] INFO [mongodb-source-connector|task-0]    mongodb.server.selection.timeout.ms = 10000 (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,104] INFO [mongodb-source-connector|task-0]    transforms.unwrap.drop.tombstones = false (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,104] INFO [mongodb-source-connector|task-0]    transforms.unwrap.type = io.debezium.connector.mongodb.transforms.ExtractNewDocumentState (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,104] INFO [mongodb-source-connector|task-0]    value.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,105] INFO [mongodb-source-connector|task-0]    mongodb.connect.timeout.ms = 10000 (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,105] INFO [mongodb-source-connector|task-0]    mongodb.auth.source = admin (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,105] INFO [mongodb-source-connector|task-0]    key.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,105] INFO [mongodb-source-connector|task-0]    transforms.convertDate.type = org.apache.kafka.connect.transforms.TimestampConverter$Value (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,105] INFO [mongodb-source-connector|task-0]    transforms.extractNew.type = org.apache.kafka.connect.transforms.ReplaceField$Value (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,105] INFO [mongodb-source-connector|task-0]    key.converter.schemas.enable = true (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,105] INFO [mongodb-source-connector|task-0]    transforms.extractNew.whitelist = _id,name,email,age,createdAt (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,105] INFO [mongodb-source-connector|task-0]    task.class = io.debezium.connector.mongodb.MongoDbConnectorTask (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,105] INFO [mongodb-source-connector|task-0]    transforms.convertDate.field = createdAt (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,106] INFO [mongodb-source-connector|task-0]    value.converter.schemas.enable = true (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,106] INFO [mongodb-source-connector|task-0]    name = mongodb-source-connector (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,106] INFO [mongodb-source-connector|task-0]    transforms.convertDate.target.type = string (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,106] INFO [mongodb-source-connector|task-0]    database.include.list = test (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,106] INFO [mongodb-source-connector|task-0]    snapshot.mode = initial (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,106] INFO [mongodb-source-connector|task-0]    transforms.unwrap.operation.header = true (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 00:11:31,110] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,117] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,118] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,133] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,135] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-17 00:11:31,138] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:11:31,155] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,161] INFO [mongodb-source-connector|task-0] Loading the custom topic naming strategy plugin: io.debezium.schema.DefaultTopicNamingStrategy (io.debezium.config.CommonConnectorConfig:1401)
[2024-12-17 00:11:31,162] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,164] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,166] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,345] INFO [mongodb-source-connector|task-0] Found previous partition offset MongoDbPartition [sourcePartition={server_id=fullfillment}]: {sec=1734365014, ord=1, resume_token=zQAAAAJfZGF0YQC9AAAAODI2NzYwNEY1NjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNEY1NjQ5NkY2QjQ1OTk5NjQwMzcwMDAwMDQAAA==} (io.debezium.connector.common.BaseSourceTask:527)
[2024-12-17 00:11:31,360] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = fullfillment named = SignalProcessor (io.debezium.util.Threads:270)
[2024-12-17 00:11:31,378] WARN [mongodb-source-connector|task-0] Found a not connector specific implementation io.debezium.snapshot.lock.NoLockingSupport for lock mode no_locking_support (io.debezium.snapshot.SnapshotLockProvider:82)
[2024-12-17 00:11:31,391] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,393] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,393] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,395] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,396] INFO [mongodb-source-connector|task-0] Found existing offset for at {sec=1734365014, ord=1, resume_token=zQAAAAJfZGF0YQC9AAAAODI2NzYwNEY1NjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNEY1NjQ5NkY2QjQ1OTk5NjQwMzcwMDAwMDQAAA==} (io.debezium.connector.mongodb.connection.MongoDbConnection:202)
[2024-12-17 00:11:31,426] INFO [mongodb-source-connector|task-0] Adding discovered server 172.30.2.147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:31,485] INFO [mongodb-source-connector|task-0] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.11.0"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-125-generic"}, "platform": "Java/Ubuntu/17.0.13+11-Ubuntu-2ubuntu122.04"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@187e43dd, com.mongodb.Jep395RecordCodecProvider@15b8a588, com.mongodb.KotlinCodecProvider@5c7058e7]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[172.30.2.147:27017], srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='rs0', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='10000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=javax.net.ssl.SSLContext@74617ae4}, applicationName='null', compressorList=[], uuidRepresentation=STANDARD, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null} (org.mongodb.driver.client:71)
[2024-12-17 00:11:31,526] INFO [mongodb-source-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=172.30.2.147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=27136726, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Tue Dec 17 00:11:28 ICT 2024, lastUpdateTimeNanos=75908269646943} (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:31,530] INFO [mongodb-source-connector|task-0] Adding discovered server linux-ip-147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:31,534] INFO [mongodb-source-connector|task-0] Effective change stream pipeline: [{"$replaceRoot": {"newRoot": {"namespace": {"$concat": ["$ns.db", ".", "$ns.coll"]}, "event": "$$ROOT"}}}, {"$match": {"$and": [{"$and": [{"event.ns.db": {"$regularExpression": {"pattern": "test", "options": "i"}}}, {"namespace": {"$regularExpression": {"pattern": "test.customers", "options": "i"}}}]}, {"event.operationType": {"$in": ["insert", "update", "replace", "delete"]}}]}}, {"$replaceRoot": {"newRoot": "$event"}}] (io.debezium.connector.mongodb.ChangeStreamPipelineFactory:56)
[2024-12-17 00:11:31,537] INFO [mongodb-source-connector|task-0] Server 172.30.2.147:27017 is no longer a member of the replica set.  Removing from client view of cluster. (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:31,540] INFO [mongodb-source-connector|task-0] Discovered replica set primary 172.30.2.147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:31,546] INFO [mongodb-source-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=linux-ip-147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=8701577, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Tue Dec 17 00:11:28 ICT 2024, lastUpdateTimeNanos=75908306437376} (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:31,546] INFO [mongodb-source-connector|task-0] Discovered replica set primary linux-ip-147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:31,694] INFO [mongodb-source-connector|task-0] Valid resume token present, so no snapshot will be performed' (io.debezium.connector.mongodb.connection.MongoDbConnection:220)
[2024-12-17 00:11:31,717] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = fullfillment named = change-event-source-coordinator (io.debezium.util.Threads:270)
[2024-12-17 00:11:31,718] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = fullfillment named = blocking-snapshot (io.debezium.util.Threads:270)
[2024-12-17 00:11:31,722] INFO [mongodb-source-connector|task-0] Creating thread debezium-mongodbconnector-fullfillment-change-event-source-coordinator (io.debezium.util.Threads:287)
[2024-12-17 00:11:31,723] INFO [mongodb-source-connector|task-0] WorkerSourceTask{id=mongodb-source-connector-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:280)
[2024-12-17 00:11:31,738] INFO [mongodb-source-connector|task-0] Metrics registered (io.debezium.pipeline.ChangeEventSourceCoordinator:137)
[2024-12-17 00:11:31,740] INFO [mongodb-source-connector|task-0] Context created (io.debezium.pipeline.ChangeEventSourceCoordinator:140)
[2024-12-17 00:11:31,746] INFO [mongodb-source-connector|task-0] A previous offset indicating a completed snapshot has been found. (io.debezium.connector.mongodb.MongoDbSnapshotChangeEventSource:144)
[2024-12-17 00:11:31,746] INFO [mongodb-source-connector|task-0] According to the connector configuration, no snapshot will occur. (io.debezium.connector.mongodb.MongoDbSnapshotChangeEventSource:151)
[2024-12-17 00:11:31,764] INFO [mongodb-source-connector|task-0] Snapshot ended with SnapshotResult [status=SKIPPED, offset=MongoDbOffsetContext [sourceInfo=SourceInfo [initialSync=false, collectionId=null, position=Position [ts=Timestamp{value=7449041014456582145, seconds=1734365014, inc=1}, changeStreamSessionTxnId=null, resumeToken=zQAAAAJfZGF0YQC9AAAAODI2NzYwNEY1NjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNEY1NjQ5NkY2QjQ1OTk5NjQwMzcwMDAwMDQAAA==]]]] (io.debezium.pipeline.ChangeEventSourceCoordinator:298)
[2024-12-17 00:11:31,768] INFO [mongodb-source-connector|task-0] Connected metrics set to 'true' (io.debezium.pipeline.ChangeEventSourceCoordinator:477)
[2024-12-17 00:11:31,773] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = mongodb named = incremental-snapshot (io.debezium.util.Threads:270)
[2024-12-17 00:11:31,775] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,776] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,778] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,780] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,782] INFO [mongodb-source-connector|task-0] No incremental snapshot in progress, no action needed on start (io.debezium.connector.mongodb.snapshot.MongoDbIncrementalSnapshotChangeEventSource:262)
[2024-12-17 00:11:31,798] INFO [mongodb-source-connector|task-0] SignalProcessor started. Scheduling it every 5000ms (io.debezium.pipeline.signal.SignalProcessor:105)
[2024-12-17 00:11:31,799] INFO [mongodb-source-connector|task-0] Creating thread debezium-mongodbconnector-fullfillment-SignalProcessor (io.debezium.util.Threads:287)
[2024-12-17 00:11:31,800] INFO [mongodb-source-connector|task-0] Starting streaming (io.debezium.pipeline.ChangeEventSourceCoordinator:323)
[2024-12-17 00:11:31,801] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,802] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,804] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,805] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 00:11:31,808] INFO [mongodb-source-connector|task-0] Adding discovered server 172.30.2.147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:31,828] INFO [mongodb-source-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=172.30.2.147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=2872355, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Tue Dec 17 00:11:28 ICT 2024, lastUpdateTimeNanos=75908588946209} (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:31,831] INFO [mongodb-source-connector|task-0] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.11.0"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-125-generic"}, "platform": "Java/Ubuntu/17.0.13+11-Ubuntu-2ubuntu122.04"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@187e43dd, com.mongodb.Jep395RecordCodecProvider@15b8a588, com.mongodb.KotlinCodecProvider@5c7058e7]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[172.30.2.147:27017], srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='rs0', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='10000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=javax.net.ssl.SSLContext@2716485b}, applicationName='null', compressorList=[], uuidRepresentation=STANDARD, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null} (org.mongodb.driver.client:71)
[2024-12-17 00:11:31,832] INFO [mongodb-source-connector|task-0] Reading change stream (io.debezium.connector.mongodb.MongoDbStreamingChangeEventSource:100)
[2024-12-17 00:11:31,836] INFO [mongodb-source-connector|task-0] Effective change stream pipeline: [{"$replaceRoot": {"newRoot": {"namespace": {"$concat": ["$ns.db", ".", "$ns.coll"]}, "event": "$$ROOT"}}}, {"$match": {"$and": [{"$and": [{"event.ns.db": {"$regularExpression": {"pattern": "test", "options": "i"}}}, {"namespace": {"$regularExpression": {"pattern": "test.customers", "options": "i"}}}]}, {"event.operationType": {"$in": ["insert", "update", "replace", "delete"]}}]}}, {"$replaceRoot": {"newRoot": "$event"}}] (io.debezium.connector.mongodb.ChangeStreamPipelineFactory:56)
[2024-12-17 00:11:31,844] INFO [mongodb-source-connector|task-0] Adding discovered server linux-ip-147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:31,845] INFO [mongodb-source-connector|task-0] Resuming streaming from token 'zQAAAAJfZGF0YQC9AAAAODI2NzYwNEY1NjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNEY1NjQ5NkY2QjQ1OTk5NjQwMzcwMDAwMDQAAA==' (io.debezium.connector.mongodb.MongoDbStreamingChangeEventSource:207)
[2024-12-17 00:11:31,850] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = fullfillment named = replicator-fetcher (io.debezium.util.Threads:270)
[2024-12-17 00:11:31,853] INFO [mongodb-source-connector|task-0] Fetcher submitted for execution: io.debezium.connector.mongodb.events.BufferingChangeStreamCursor$EventFetcher@6ca3f6cf @ java.util.concurrent.ThreadPoolExecutor@4dc17918[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] (io.debezium.connector.mongodb.events.BufferingChangeStreamCursor:367)
[2024-12-17 00:11:31,856] INFO [mongodb-source-connector|task-0] Creating thread debezium-mongodbconnector-fullfillment-replicator-fetcher-0 (io.debezium.util.Threads:287)
[2024-12-17 00:11:31,857] INFO [mongodb-source-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=linux-ip-147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=4607598, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Tue Dec 17 00:11:28 ICT 2024, lastUpdateTimeNanos=75908617518725} (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:31,858] INFO [mongodb-source-connector|task-0] Server 172.30.2.147:27017 is no longer a member of the replica set.  Removing from client view of cluster. (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:31,860] INFO [mongodb-source-connector|task-0] Discovered replica set primary 172.30.2.147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:31,867] INFO [mongodb-source-connector|task-0] No server chosen by ReadPreferenceServerSelector{readPreference=primary} from cluster description ClusterDescription{type=REPLICA_SET, connectionMode=MULTIPLE, serverDescriptions=[ServerDescription{address=172.30.2.147:27017, type=UNKNOWN, state=CONNECTING}]}. Waiting for 10000 ms before timing out (org.mongodb.driver.cluster:71)
[2024-12-17 00:11:31,870] INFO [mongodb-source-connector|task-0] Discovered replica set primary linux-ip-147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-17 00:12:35,310] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 00:12:35,313] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:12:35,314] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:12:35,323] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=413, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:12:35,347] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=413, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:12:35,348] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 413 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=657, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:12:35,349] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 657 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:12:35,351] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 00:12:35,353] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 00:12:35,358] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:12:35,365] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:12:35,368] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 00:12:35,369] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 00:12:35,369] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:12:35,384] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:12:35,392] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:12:35,503] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:12:35,526] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:12:35,529] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:12:35,530] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:12:35,535] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=414, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:12:35,541] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=414, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:12:35,542] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 414 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=661, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:12:35,543] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 661 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:12:35,544] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:12:58,711] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:12:58,712] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 00:12:58,712] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:12:58,719] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:12:58,727] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=415, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:12:58,734] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=415, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:12:58,740] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 00:12:58,741] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 00:12:58,743] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 00:12:58,751] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 00:12:58,764] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 00:12:58,765] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 415 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=663, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:12:58,771] INFO 172.30.2.207 - - [16/Dec/2024:17:12:58 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 205 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 00:12:58,774] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 663 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:12:58,789] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:12:58,789] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:12:58,789] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:12:58,794] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=416, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:12:58,802] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=416, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:12:58,802] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 416 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=663, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:12:58,803] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 663 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:12:58,803] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:13:58,674] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 00:13:58,687] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:13:58,687] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:13:58,693] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=417, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:13:58,700] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=417, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:13:58,700] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 417 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=664, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:13:58,701] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 664 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:13:58,704] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 00:13:58,710] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 00:13:58,732] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:13:58,758] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:13:58,759] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:13:58,769] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 00:13:58,779] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 00:13:58,780] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:13:58,781] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:13:58,782] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:13:58,786] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=418, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:13:58,791] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=418, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:13:58,792] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 418 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=666, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:13:58,793] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 666 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:13:58,799] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 00:13:58,813] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 00:13:58,817] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 00:13:58,822] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:13:58,834] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-17 00:13:58,850] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:13:58,853] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:13:58,863] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:22:19,600] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:22:19,602] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 00:22:19,606] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:22:19,607] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:22:19,613] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=419, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:22:19,614] INFO 172.30.2.207 - - [16/Dec/2024:17:22:19 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 110 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 00:22:19,626] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=419, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:22:19,630] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 00:22:19,631] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 00:22:19,632] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-17 00:22:19,633] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-17 00:22:19,643] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 00:22:19,645] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 00:22:19,658] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 00:22:19,659] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 419 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=668, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:22:19,661] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 668 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:22:19,662] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:22:19,663] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:22:19,663] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:22:19,669] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=420, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:22:19,682] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=420, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:22:19,683] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 420 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=668, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:22:19,684] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 668 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:22:19,685] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:23:01,514] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 00:23:01,533] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:23:01,534] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:23:01,552] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=421, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:23:01,573] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=421, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:23:01,574] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 421 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=669, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:23:01,577] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 669 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:23:01,579] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 00:23:01,581] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 00:23:01,585] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:23:01,589] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:23:01,592] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 00:23:01,609] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 00:23:01,609] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:23:01,617] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:23:01,628] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:23:01,653] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:23:01,680] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:23:01,688] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:23:01,688] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:23:01,692] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=422, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:23:01,703] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=422, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:23:01,704] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 422 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=673, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:23:01,705] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 673 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:23:01,706] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 00:23:01,708] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 00:23:01,710] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 00:23:01,716] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:23:01,731] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-17 00:23:01,743] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:27:53,022] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:27:53,024] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 00:27:53,052] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:27:53,053] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:27:53,057] INFO 172.30.2.207 - - [16/Dec/2024:17:27:52 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 82 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 00:27:53,059] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=423, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:27:53,072] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=423, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:27:53,073] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 00:27:53,074] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-17 00:27:53,075] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-17 00:27:53,076] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 00:27:53,084] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 00:27:53,087] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 00:27:53,130] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 00:27:53,131] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 423 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=675, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:27:53,133] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 675 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:27:53,134] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:27:53,134] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:27:53,134] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:27:53,140] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=424, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:27:53,152] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=424, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:27:53,152] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 424 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=675, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:27:53,153] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 675 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:27:53,153] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:28:14,611] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 00:28:14,615] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:28:14,616] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:28:14,624] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=425, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:28:14,637] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=425, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:28:14,638] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 425 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=676, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:28:14,640] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 676 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:28:14,641] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 00:28:14,644] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 00:28:14,651] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, RenameFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:28:14,664] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, RenameFields]
	transforms.RenameFields.blacklist = null
	transforms.RenameFields.exclude = []
	transforms.RenameFields.include = []
	transforms.RenameFields.negate = false
	transforms.RenameFields.predicate = null
	transforms.RenameFields.renames = [_id:_id, name:name, email:email, age:age, createdAt:createdAt]
	transforms.RenameFields.replace.null.with.default = true
	transforms.RenameFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.RenameFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:28:14,673] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 00:28:14,677] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 00:28:14,678] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:28:14,691] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, RenameFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:28:14,702] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, RenameFields]
	transforms.RenameFields.blacklist = null
	transforms.RenameFields.exclude = []
	transforms.RenameFields.include = []
	transforms.RenameFields.negate = false
	transforms.RenameFields.predicate = null
	transforms.RenameFields.renames = [_id:_id, name:name, email:email, age:age, createdAt:createdAt]
	transforms.RenameFields.replace.null.with.default = true
	transforms.RenameFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.RenameFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:28:14,759] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:28:14,760] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:28:14,761] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:28:14,770] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=426, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:28:14,774] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:28:14,775] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=426, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:28:14,776] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 426 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=679, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:28:14,776] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 679 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:28:14,778] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 00:28:14,779] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 00:28:14,781] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, RenameFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 00:28:14,792] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, RenameFields]
	transforms.RenameFields.blacklist = null
	transforms.RenameFields.exclude = []
	transforms.RenameFields.include = []
	transforms.RenameFields.negate = false
	transforms.RenameFields.predicate = null
	transforms.RenameFields.renames = [_id:_id, name:name, email:email, age:age, createdAt:createdAt]
	transforms.RenameFields.replace.null.with.default = true
	transforms.RenameFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.RenameFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:28:14,815] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-17 00:28:14,834] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:28:14,836] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:28:14,836] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:28:14,841] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=427, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:28:14,854] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=427, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:28:14,856] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-17 00:28:14,856] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-17 00:28:14,857] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 00:28:14,858] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 00:28:14,859] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 427 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=680, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:28:14,860] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 680 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:28:14,861] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:28:14,861] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:28:14,862] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:28:14,868] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=428, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:28:14,874] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=428, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:28:14,875] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 428 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=680, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:28:14,876] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 680 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:28:14,877] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:28:32,563] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:28:32,564] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 00:28:32,565] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:28:32,565] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:28:32,574] INFO 172.30.2.207 - - [16/Dec/2024:17:28:32 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 50 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 00:28:32,579] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=429, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:28:32,592] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=429, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:28:32,594] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 00:28:32,594] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 00:28:32,597] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 00:28:32,599] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 00:28:32,602] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 00:28:32,603] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 429 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=682, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:28:32,603] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 682 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:28:32,604] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:28:32,605] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:28:32,605] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:28:32,618] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=430, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:28:32,626] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=430, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:28:32,626] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 430 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=682, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:28:32,627] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 682 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:28:32,628] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:29:08,638] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 00:29:08,643] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:29:08,644] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:29:08,653] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=431, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:29:08,662] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=431, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:29:08,663] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 431 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=683, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:29:08,663] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 683 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:29:08,664] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 00:29:08,666] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 00:29:08,670] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, RenameFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:29:08,674] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, RenameFields]
	transforms.RenameFields.blacklist = null
	transforms.RenameFields.exclude = []
	transforms.RenameFields.include = []
	transforms.RenameFields.negate = false
	transforms.RenameFields.predicate = null
	transforms.RenameFields.renames = [_id:_id, name:name, email:email, age:age, createdAt:createdAt]
	transforms.RenameFields.replace.null.with.default = true
	transforms.RenameFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.RenameFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:29:08,676] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 00:29:08,681] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 00:29:08,681] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:29:08,684] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, RenameFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:29:08,686] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, RenameFields]
	transforms.RenameFields.blacklist = null
	transforms.RenameFields.exclude = []
	transforms.RenameFields.include = []
	transforms.RenameFields.negate = false
	transforms.RenameFields.predicate = null
	transforms.RenameFields.renames = [_id:_id, name:name, email:email, age:age, createdAt:createdAt]
	transforms.RenameFields.replace.null.with.default = true
	transforms.RenameFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.RenameFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:29:08,757] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:29:08,758] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:29:08,758] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:29:08,762] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=432, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:29:08,771] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=432, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:29:08,772] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 432 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=685, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:29:08,773] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 685 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:29:08,774] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 00:29:08,775] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 00:29:08,777] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, RenameFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 00:29:08,779] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, RenameFields]
	transforms.RenameFields.blacklist = null
	transforms.RenameFields.exclude = []
	transforms.RenameFields.include = []
	transforms.RenameFields.negate = false
	transforms.RenameFields.predicate = null
	transforms.RenameFields.renames = [_id:_id, name:name, email:email, age:age, createdAt:createdAt]
	transforms.RenameFields.replace.null.with.default = true
	transforms.RenameFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.RenameFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:29:08,791] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:29:08,797] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-17 00:29:08,801] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:29:08,801] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Handling task config update by stopping tasks [mysql-sink-connector-0], which will be restarted after rebalance if still assigned to this worker (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2024-12-17 00:29:08,802] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-17 00:29:08,802] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-17 00:29:08,802] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:29:08,802] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:29:08,812] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=433, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:29:08,817] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=433, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:29:08,818] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 433 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=687, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:29:08,818] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 687 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:29:08,819] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 00:29:08,820] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 00:29:08,823] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, RenameFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 00:29:08,825] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, RenameFields]
	transforms.RenameFields.blacklist = null
	transforms.RenameFields.exclude = []
	transforms.RenameFields.include = []
	transforms.RenameFields.negate = false
	transforms.RenameFields.predicate = null
	transforms.RenameFields.renames = [_id:_id, name:name, email:email, age:age, createdAt:createdAt]
	transforms.RenameFields.replace.null.with.default = true
	transforms.RenameFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.RenameFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:29:08,830] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-17 00:29:08,849] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:30:54,484] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:30:54,486] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 00:30:54,487] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:30:54,488] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:30:54,495] INFO 172.30.2.207 - - [16/Dec/2024:17:30:54 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 55 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 00:30:54,498] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=434, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:30:54,508] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=434, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:30:54,510] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 00:30:54,511] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 00:30:54,516] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 00:30:54,518] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-17 00:30:54,518] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-17 00:30:54,520] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 00:30:54,533] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 00:30:54,535] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 434 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=689, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:30:54,538] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 689 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:30:54,539] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:30:54,540] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:30:54,541] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:30:54,550] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=435, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:30:54,560] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=435, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:30:54,562] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 435 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=689, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:30:54,562] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 689 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:30:54,563] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:34:04,428] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 00:34:04,432] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:34:04,436] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:34:04,452] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=436, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:34:04,458] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=436, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:34:04,458] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 436 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=690, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:34:04,460] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 690 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:34:04,461] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 00:34:04,463] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 00:34:04,466] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, RenameFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:34:04,477] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, RenameFields]
	transforms.RenameFields.blacklist = null
	transforms.RenameFields.exclude = []
	transforms.RenameFields.include = []
	transforms.RenameFields.negate = false
	transforms.RenameFields.predicate = null
	transforms.RenameFields.renames = [_id:_id, name:name, email:email, age:age, createdAt:createdAt]
	transforms.RenameFields.replace.null.with.default = true
	transforms.RenameFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.RenameFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:34:04,495] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 00:34:04,500] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 00:34:04,501] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:34:04,509] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, RenameFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:34:04,516] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:34:04,520] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, RenameFields]
	transforms.RenameFields.blacklist = null
	transforms.RenameFields.exclude = []
	transforms.RenameFields.include = []
	transforms.RenameFields.negate = false
	transforms.RenameFields.predicate = null
	transforms.RenameFields.renames = [_id:_id, name:name, email:email, age:age, createdAt:createdAt]
	transforms.RenameFields.replace.null.with.default = true
	transforms.RenameFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.RenameFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:34:04,557] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:34:04,567] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:34:04,567] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:34:04,572] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=437, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:34:04,577] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=437, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:34:04,577] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 437 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=694, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:34:04,578] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 694 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:34:04,579] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 00:34:04,580] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 00:34:04,582] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, RenameFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 00:34:04,587] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, RenameFields]
	transforms.RenameFields.blacklist = null
	transforms.RenameFields.exclude = []
	transforms.RenameFields.include = []
	transforms.RenameFields.negate = false
	transforms.RenameFields.predicate = null
	transforms.RenameFields.renames = [_id:_id, name:name, email:email, age:age, createdAt:createdAt]
	transforms.RenameFields.replace.null.with.default = true
	transforms.RenameFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.RenameFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:34:04,604] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-17 00:34:04,628] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:38:52,337] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:38:52,338] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 00:38:52,339] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:38:52,340] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:38:52,346] INFO 172.30.2.207 - - [16/Dec/2024:17:38:52 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 66 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 00:38:52,356] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=438, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:38:52,371] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=438, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:38:52,373] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 00:38:52,374] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 00:38:52,373] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-17 00:38:52,376] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-17 00:38:52,380] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 00:38:52,382] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 00:38:52,401] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 00:38:52,401] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 438 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=696, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:38:52,405] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 696 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:38:52,408] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:38:52,409] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:38:52,412] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:38:52,420] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=439, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:38:52,429] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=439, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:38:52,430] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 439 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=696, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:38:52,431] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 696 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:38:52,431] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:39:38,699] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 00:39:38,707] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:39:38,708] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:39:38,717] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=440, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:39:38,754] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=440, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:39:38,756] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 440 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=697, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:39:38,758] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 697 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:39:38,759] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 00:39:38,761] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 00:39:38,766] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, route]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:39:38,770] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, route]
	transforms.route.negate = false
	transforms.route.predicate = null
	transforms.route.regex = .*
	transforms.route.replacement = mongodb_customers
	transforms.route.type = class org.apache.kafka.connect.transforms.RegexRouter
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:39:38,772] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 00:39:38,779] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 00:39:38,780] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:39:38,782] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, route]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:39:38,796] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, route]
	transforms.route.negate = false
	transforms.route.predicate = null
	transforms.route.regex = .*
	transforms.route.replacement = mongodb_customers
	transforms.route.type = class org.apache.kafka.connect.transforms.RegexRouter
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:39:38,811] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:39:38,849] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:39:38,850] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:39:38,850] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:39:38,855] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=441, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:39:38,862] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=441, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:39:38,863] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 441 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=701, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:39:38,864] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 701 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:39:38,866] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 00:39:38,867] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 00:39:38,871] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, route]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 00:39:38,878] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, route]
	transforms.route.negate = false
	transforms.route.predicate = null
	transforms.route.regex = .*
	transforms.route.replacement = mongodb_customers
	transforms.route.type = class org.apache.kafka.connect.transforms.RegexRouter
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:39:38,890] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-17 00:39:38,903] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:42:19,125] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:42:19,127] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 00:42:19,128] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:42:19,128] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:42:19,138] INFO 172.30.2.207 - - [16/Dec/2024:17:42:19 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 70 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 00:42:19,144] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=442, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:42:19,159] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=442, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:42:19,160] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 00:42:19,161] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 00:42:19,161] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-17 00:42:19,162] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-17 00:42:19,166] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 00:42:19,168] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 00:42:19,180] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 00:42:19,181] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 442 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=703, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:42:19,184] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 703 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:42:19,184] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:42:19,185] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:42:19,185] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:42:19,195] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=443, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:42:19,212] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=443, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:42:19,216] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 443 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=703, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:42:19,217] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 703 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:42:19,217] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:44:05,784] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 00:44:05,794] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:44:05,795] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:44:05,822] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=444, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:44:05,831] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=444, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:44:05,832] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 444 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=704, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:44:05,833] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 704 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:44:05,834] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 00:44:05,836] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 00:44:05,841] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:44:05,856] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:44:05,858] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 00:44:05,865] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 00:44:05,866] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:44:05,886] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:44:05,896] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:44:05,927] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:44:05,938] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:44:05,950] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:44:05,951] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:44:05,954] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=445, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:44:05,958] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=445, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:44:05,958] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 445 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=708, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:44:05,959] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 708 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:44:05,959] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:44:24,327] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:44:24,328] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 00:44:24,329] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:44:24,329] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:44:24,333] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=446, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:44:24,336] INFO 172.30.2.207 - - [16/Dec/2024:17:44:24 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 53 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 00:44:24,342] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=446, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:44:24,343] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 00:44:24,344] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 00:44:24,346] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 00:44:24,348] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 00:44:24,354] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 00:44:24,354] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 446 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=710, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:44:24,355] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 710 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:44:24,356] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:44:24,356] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:44:24,357] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:44:24,361] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=447, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:44:24,370] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=447, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:44:24,372] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 447 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=710, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:44:24,374] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 710 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:44:24,375] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:45:19,817] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 00:45:19,822] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:45:19,822] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:45:19,832] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=448, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:45:19,850] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=448, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:45:19,851] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 448 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=711, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:45:19,852] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 711 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:45:19,853] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 00:45:19,854] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 00:45:19,858] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:45:19,861] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:45:19,867] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 00:45:19,876] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 00:45:19,877] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:45:19,881] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:45:19,884] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:45:19,959] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:45:19,972] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:45:19,973] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:45:19,974] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:45:19,984] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=449, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:45:19,991] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=449, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:45:19,991] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 449 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=714, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:45:19,992] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 714 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:45:19,993] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 00:45:19,994] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 00:45:19,997] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 00:45:20,002] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:45:20,012] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-17 00:45:20,023] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:45:20,023] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Handling task config update by stopping tasks [mysql-sink-connector-0], which will be restarted after rebalance if still assigned to this worker (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2024-12-17 00:45:20,024] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-17 00:45:20,025] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-17 00:45:20,025] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:45:20,025] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:45:20,032] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=450, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:45:20,040] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=450, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:45:20,041] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 450 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=715, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:45:20,042] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 715 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:45:20,042] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 00:45:20,043] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 00:45:20,045] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 00:45:20,047] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:45:20,048] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-17 00:45:20,059] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:47:03,018] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:47:03,020] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 00:47:03,021] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:47:03,021] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:47:03,027] INFO 172.30.2.207 - - [16/Dec/2024:17:47:02 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 66 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 00:47:03,029] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=451, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:47:03,037] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=451, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:47:03,038] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 00:47:03,038] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 00:47:03,040] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-17 00:47:03,041] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-17 00:47:03,042] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 00:47:03,044] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 00:47:03,059] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 00:47:03,061] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 451 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=717, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:47:03,063] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 717 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:47:03,064] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:47:03,066] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:47:03,066] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:47:03,073] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=452, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:47:03,094] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=452, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:47:03,095] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 452 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=717, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:47:03,095] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 717 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:47:03,096] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:47:57,066] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 00:47:57,072] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:47:57,073] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:47:57,092] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=453, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:47:57,110] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=453, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:47:57,111] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 453 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=718, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:47:57,112] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 718 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:47:57,113] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 00:47:57,114] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 00:47:57,119] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:47:57,122] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:47:57,124] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 00:47:57,132] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 00:47:57,132] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:47:57,134] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:47:57,140] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:47:57,194] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:47:57,219] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:47:57,220] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:47:57,220] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:47:57,225] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=454, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:47:57,236] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=454, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:47:57,236] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 454 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=722, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:47:57,238] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 722 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:47:57,238] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:48:24,816] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:48:24,817] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 00:48:24,818] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:48:24,818] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:48:24,824] INFO 172.30.2.207 - - [16/Dec/2024:17:48:24 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 41 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 00:48:24,828] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=455, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:48:24,835] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=455, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:48:24,836] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 00:48:24,836] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 00:48:24,838] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 00:48:24,840] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 00:48:24,846] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 00:48:24,847] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 455 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=724, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:48:24,848] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 724 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:48:24,848] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:48:24,849] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:48:24,849] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:48:24,855] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=456, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:48:24,865] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=456, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:48:24,866] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 456 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=724, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:48:24,867] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 724 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:48:24,867] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:50:02,760] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 00:50:02,765] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:50:02,766] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:50:02,787] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=457, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:50:02,796] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=457, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:50:02,797] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 457 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=725, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:50:02,798] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 725 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:50:02,799] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 00:50:02,801] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 00:50:02,808] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:50:02,820] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:50:02,824] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 00:50:02,825] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 00:50:02,828] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:50:02,835] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:50:02,838] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:50:02,866] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:50:02,882] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:50:02,893] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:50:02,894] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:50:02,898] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=458, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:50:02,922] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=458, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:50:02,924] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 458 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=729, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:50:02,925] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 729 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:50:02,926] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:50:15,528] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:50:15,529] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 00:50:15,529] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:50:15,530] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:50:15,534] INFO 172.30.2.207 - - [16/Dec/2024:17:50:15 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 37 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 00:50:15,544] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=459, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:50:15,549] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=459, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:50:15,550] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 00:50:15,550] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 00:50:15,552] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 00:50:15,553] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 00:50:15,560] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 00:50:15,561] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 459 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=731, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:50:15,562] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 731 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:50:15,562] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:50:15,562] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:50:15,563] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:50:15,566] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=460, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:50:15,572] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=460, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:50:15,572] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 460 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=731, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:50:15,573] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 731 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:50:15,573] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:51:16,645] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 00:51:16,649] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:51:16,650] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:51:16,658] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=461, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:51:16,667] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=461, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:51:16,667] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 461 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=732, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:51:16,668] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 732 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:51:16,670] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 00:51:16,672] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 00:51:16,675] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:51:16,678] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:51:16,682] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 00:51:16,685] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 00:51:16,686] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:51:16,698] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 00:51:16,700] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:51:16,758] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:51:16,769] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:51:16,769] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:51:16,773] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=462, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:51:16,778] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=462, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:51:16,778] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 462 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=734, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:51:16,779] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 734 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:51:16,780] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 00:51:16,780] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 00:51:16,783] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 00:51:16,790] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:51:16,796] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 00:51:16,801] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-17 00:51:16,812] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:51:16,813] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Handling task config update by stopping tasks [mysql-sink-connector-0], which will be restarted after rebalance if still assigned to this worker (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2024-12-17 00:51:16,814] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-17 00:51:16,815] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-17 00:51:16,816] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:51:16,817] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:51:16,821] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=463, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:51:16,827] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=463, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:51:16,828] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 463 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=736, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:51:16,829] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 736 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:51:16,830] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 00:51:16,831] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 00:51:16,833] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 00:51:16,842] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 00:51:16,849] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-17 00:51:16,857] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:59:28,875] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 00:59:28,883] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 00:59:28,884] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:59:28,885] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:59:28,889] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=464, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:59:28,891] INFO 172.30.2.207 - - [16/Dec/2024:17:59:28 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 88 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 00:59:28,910] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=464, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:59:28,911] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 00:59:28,912] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 00:59:28,913] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-17 00:59:28,914] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-17 00:59:28,919] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 00:59:28,921] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 00:59:28,929] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 00:59:28,929] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 464 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=738, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:59:28,932] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 738 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:59:28,932] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 00:59:28,933] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 00:59:28,933] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 00:59:28,950] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=465, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 00:59:28,956] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=465, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 00:59:28,958] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 465 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=738, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 00:59:28,959] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 738 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 00:59:28,959] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
