[2024-12-16 23:00:18,461] INFO 172.30.0.4 - - [16/Dec/2024:16:00:18 +0000] "GET /connectors/mongodb-source-connector/status HTTP/1.1" 404 85 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36" 56 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-16 23:00:47,331] INFO Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,334] INFO Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,335] INFO Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,342] INFO Adding discovered server 172.30.2.147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,356] INFO MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.11.0"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-125-generic"}, "platform": "Java/Ubuntu/17.0.13+11-Ubuntu-2ubuntu122.04"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@5691a171, com.mongodb.Jep395RecordCodecProvider@415feae4, com.mongodb.KotlinCodecProvider@26839f41]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[172.30.2.147:27017], srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='rs0', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='10000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=javax.net.ssl.SSLContext@3bcd68}, applicationName='null', compressorList=[], uuidRepresentation=STANDARD, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null} (org.mongodb.driver.client:71)
[2024-12-16 23:00:47,362] INFO No server chosen by ReadPreferenceServerSelector{readPreference=primary} from cluster description ClusterDescription{type=REPLICA_SET, connectionMode=MULTIPLE, serverDescriptions=[ServerDescription{address=172.30.2.147:27017, type=UNKNOWN, state=CONNECTING}]}. Waiting for 10000 ms before timing out (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,369] INFO Monitor thread successfully connected to server with description ServerDescription{address=172.30.2.147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=13278472, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Mon Dec 16 23:00:38 ICT 2024, lastUpdateTimeNanos=71664128713852} (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,370] INFO Adding discovered server linux-ip-147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,379] INFO Server 172.30.2.147:27017 is no longer a member of the replica set.  Removing from client view of cluster. (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,382] INFO Discovered replica set primary 172.30.2.147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,385] INFO Monitor thread successfully connected to server with description ServerDescription{address=linux-ip-147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=2424481, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Mon Dec 16 23:00:38 ICT 2024, lastUpdateTimeNanos=71664145634005} (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,388] INFO Discovered replica set primary linux-ip-147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,475] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:371)
[2024-12-16 23:00:47,522] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mongodb-source-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-16 23:00:47,525] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:00:47,528] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:00:47,541] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=360, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:00:47,550] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=360, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:00:47,551] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 360 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=578, connectorIds=[mongodb-source-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:00:47,552] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 578 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:00:47,554] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mongodb-source-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-16 23:00:47,555] INFO [mongodb-source-connector|worker] Creating connector mongodb-source-connector of type io.debezium.connector.mongodb.MongoDbConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-16 23:00:47,558] INFO [mongodb-source-connector|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-16 23:00:47,571] INFO [mongodb-source-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:00:47,588] INFO [mongodb-source-connector|worker] Instantiated connector mongodb-source-connector with version 3.0.4.Final of type class io.debezium.connector.mongodb.MongoDbConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-16 23:00:47,595] INFO [mongodb-source-connector|worker] Finished creating connector mongodb-source-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-16 23:00:47,596] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:00:47,612] INFO [mongodb-source-connector|worker] Successfully started MongoDB connector (io.debezium.connector.mongodb.MongoDbConnector:67)
[2024-12-16 23:00:47,616] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-16 23:00:47,625] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:00:47,662] INFO 172.30.2.147 - - [16/Dec/2024:16:00:47 +0000] "POST /connectors HTTP/1.1" 201 1485 "-" "curl/7.81.0" 368 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-16 23:00:47,674] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mongodb-source-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:00:47,675] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:00:47,675] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:00:47,681] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=361, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:00:47,685] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=361, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:00:47,685] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 361 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=580, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:00:47,686] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 580 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:00:47,686] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-16 23:00:47,687] INFO [mongodb-source-connector|task-0] Creating task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-16 23:00:47,689] INFO [mongodb-source-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-16 23:00:47,690] INFO [mongodb-source-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:00:47,690] INFO [mongodb-source-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.MongoDbConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:371)
[2024-12-16 23:00:47,693] INFO [mongodb-source-connector|task-0] Instantiated task mongodb-source-connector-0 with version 3.0.4.Final of type io.debezium.connector.mongodb.MongoDbConnectorTask (org.apache.kafka.connect.runtime.Worker:665)
[2024-12-16 23:00:47,694] INFO [mongodb-source-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-16 23:00:47,694] INFO [mongodb-source-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-16 23:00:47,694] INFO [mongodb-source-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-source-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:680)
[2024-12-16 23:00:47,694] INFO [mongodb-source-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-source-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:686)
[2024-12-16 23:00:47,695] INFO [mongodb-source-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mongodb-source-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:691)
[2024-12-16 23:00:47,696] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mongodb-source-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:00:47,696] WARN [mongodb-source-connector|task-0] The deleted record handling configs "drop.tombstones" and "delete.handling.mode" have been deprecated, please use "delete.tombstone.handling.mode" instead. (io.debezium.transforms.AbstractExtractNewRecordState:110)
[2024-12-16 23:00:47,698] WARN [mongodb-source-connector|task-0] Configuration key whitelist is deprecated and may be removed in the future.  Please update your configuration to use include instead. (org.apache.kafka.common.utils.ConfigUtils:114)
[2024-12-16 23:00:47,702] INFO [mongodb-source-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{io.debezium.connector.mongodb.transforms.ExtractNewDocumentState, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.TimestampConverter$Value} (org.apache.kafka.connect.runtime.Worker:1795)
[2024-12-16 23:00:47,703] INFO [mongodb-source-connector|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-16 23:00:47,704] INFO [mongodb-source-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:00:47,705] INFO [mongodb-source-connector|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-mongodb-source-connector-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-16 23:00:47,706] INFO [mongodb-source-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-16 23:00:47,718] INFO [mongodb-source-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-16 23:00:47,718] INFO [mongodb-source-connector|task-0] Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-16 23:00:47,718] INFO [mongodb-source-connector|task-0] Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-16 23:00:47,718] INFO [mongodb-source-connector|task-0] Kafka startTimeMs: 1734364847718 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-16 23:00:47,723] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:00:47,723] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Handling task config update by stopping tasks [mongodb-source-connector-0], which will be restarted after rebalance if still assigned to this worker (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2024-12-16 23:00:47,723] INFO [mongodb-source-connector|task-0] Stopping task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.Worker:1048)
[2024-12-16 23:00:47,724] INFO [mongodb-source-connector|task-0] [Producer clientId=connector-producer-mongodb-source-connector-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2024-12-16 23:00:47,749] INFO [mongodb-source-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-16 23:00:47,749] INFO [mongodb-source-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-16 23:00:47,752] INFO [mongodb-source-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-16 23:00:47,752] INFO [mongodb-source-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-16 23:00:47,753] INFO [mongodb-source-connector|task-0] App info kafka.producer for connector-producer-mongodb-source-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-16 23:00:47,755] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:00:47,756] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:00:47,759] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=362, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:00:47,764] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=362, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:00:47,765] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 362 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=582, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:00:47,766] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 582 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:00:47,766] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-16 23:00:47,767] INFO [mongodb-source-connector|task-0] Creating task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-16 23:00:47,768] INFO [mongodb-source-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-16 23:00:47,769] INFO [mongodb-source-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:00:47,769] INFO [mongodb-source-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.MongoDbConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:371)
[2024-12-16 23:00:47,770] INFO [mongodb-source-connector|task-0] Instantiated task mongodb-source-connector-0 with version 3.0.4.Final of type io.debezium.connector.mongodb.MongoDbConnectorTask (org.apache.kafka.connect.runtime.Worker:665)
[2024-12-16 23:00:47,770] INFO [mongodb-source-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-16 23:00:47,771] INFO [mongodb-source-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-16 23:00:47,771] INFO [mongodb-source-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-source-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:680)
[2024-12-16 23:00:47,771] INFO [mongodb-source-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-source-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:686)
[2024-12-16 23:00:47,771] INFO [mongodb-source-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mongodb-source-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:691)
[2024-12-16 23:00:47,772] WARN [mongodb-source-connector|task-0] The deleted record handling configs "drop.tombstones" and "delete.handling.mode" have been deprecated, please use "delete.tombstone.handling.mode" instead. (io.debezium.transforms.AbstractExtractNewRecordState:110)
[2024-12-16 23:00:47,779] WARN [mongodb-source-connector|task-0] Configuration key whitelist is deprecated and may be removed in the future.  Please update your configuration to use include instead. (org.apache.kafka.common.utils.ConfigUtils:114)
[2024-12-16 23:00:47,780] INFO [mongodb-source-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{io.debezium.connector.mongodb.transforms.ExtractNewDocumentState, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.TimestampConverter$Value} (org.apache.kafka.connect.runtime.Worker:1795)
[2024-12-16 23:00:47,780] INFO [mongodb-source-connector|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-16 23:00:47,782] INFO [mongodb-source-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:00:47,785] INFO [mongodb-source-connector|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-mongodb-source-connector-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-16 23:00:47,786] INFO [mongodb-source-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-16 23:00:47,800] INFO [mongodb-source-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-16 23:00:47,800] INFO [mongodb-source-connector|task-0] Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-16 23:00:47,800] INFO [mongodb-source-connector|task-0] Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-16 23:00:47,800] INFO [mongodb-source-connector|task-0] Kafka startTimeMs: 1734364847800 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-16 23:00:47,817] INFO [mongodb-source-connector|task-0] Starting MongoDbConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:245)
[2024-12-16 23:00:47,817] INFO [mongodb-source-connector|task-0]    connector.class = io.debezium.connector.mongodb.MongoDbConnector (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,818] INFO [mongodb-source-connector|task-0]    collection.include.list = test.customers (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,818] INFO [mongodb-source-connector|task-0]    transforms.unwrap.delete.handling.mode = drop (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,818] INFO [mongodb-source-connector|task-0]    transforms.unwrap.array.encoding = array (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,818] INFO [mongodb-source-connector|task-0]    mongodb.connection.string = ******** (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,818] INFO [mongodb-source-connector|task-0]    tasks.max = 1 (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,818] INFO [mongodb-source-connector|task-0]    transforms = unwrap,extractNew,convertDate (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,818] INFO [mongodb-source-connector|task-0]    transforms.unwrap.add.source.fields = db,collection (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,818] INFO [mongodb-source-connector|task-0]    topic.prefix = fullfillment (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,818] INFO [mongodb-source-connector|task-0]    transforms.convertDate.format = yyyy-MM-dd HH:mm:ss (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,818] INFO [mongodb-source-connector|task-0]    mongodb.server.selection.timeout.ms = 10000 (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,818] INFO [mongodb-source-connector|task-0]    transforms.unwrap.drop.tombstones = false (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,818] INFO [mongodb-source-connector|task-0]    transforms.unwrap.type = io.debezium.connector.mongodb.transforms.ExtractNewDocumentState (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,819] INFO [mongodb-source-connector|task-0]    value.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,819] INFO [mongodb-source-connector|task-0]    mongodb.connect.timeout.ms = 10000 (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,819] INFO [mongodb-source-connector|task-0]    mongodb.auth.source = admin (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,819] INFO [mongodb-source-connector|task-0]    key.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,819] INFO [mongodb-source-connector|task-0]    transforms.convertDate.type = org.apache.kafka.connect.transforms.TimestampConverter$Value (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,819] INFO [mongodb-source-connector|task-0]    transforms.extractNew.type = org.apache.kafka.connect.transforms.ReplaceField$Value (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,819] INFO [mongodb-source-connector|task-0]    key.converter.schemas.enable = true (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,820] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:00:47,822] INFO [mongodb-source-connector|task-0]    transforms.extractNew.whitelist = _id,name,email,age,createdAt (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,822] INFO [mongodb-source-connector|task-0]    task.class = io.debezium.connector.mongodb.MongoDbConnectorTask (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,822] INFO [mongodb-source-connector|task-0]    transforms.convertDate.field = createdAt (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,822] INFO [mongodb-source-connector|task-0]    value.converter.schemas.enable = true (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,822] INFO [mongodb-source-connector|task-0]    name = mongodb-source-connector (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,823] INFO [mongodb-source-connector|task-0]    transforms.convertDate.target.type = string (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,823] INFO [mongodb-source-connector|task-0]    database.include.list = test (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,823] INFO [mongodb-source-connector|task-0]    snapshot.mode = initial (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,823] INFO [mongodb-source-connector|task-0]    transforms.unwrap.operation.header = true (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-16 23:00:47,823] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,824] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,824] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,828] INFO [mongodb-source-connector|task-0] [Producer clientId=connector-producer-mongodb-source-connector-0] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-16 23:00:47,829] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,830] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,831] INFO [mongodb-source-connector|task-0] Loading the custom topic naming strategy plugin: io.debezium.schema.DefaultTopicNamingStrategy (io.debezium.config.CommonConnectorConfig:1401)
[2024-12-16 23:00:47,831] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,832] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,833] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,843] INFO [mongodb-source-connector|task-0] Found previous partition offset MongoDbPartition [sourcePartition={server_id=fullfillment}]: {sec=1734361270, ord=1, resume_token=zQAAAAJfZGF0YQC9AAAAODI2NzYwNDBCNjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNDBCNjQ5NkY2QjQ1OTk5NjQwMzMwMDAwMDQAAA==} (io.debezium.connector.common.BaseSourceTask:527)
[2024-12-16 23:00:47,844] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = fullfillment named = SignalProcessor (io.debezium.util.Threads:270)
[2024-12-16 23:00:47,846] WARN [mongodb-source-connector|task-0] Found a not connector specific implementation io.debezium.snapshot.lock.NoLockingSupport for lock mode no_locking_support (io.debezium.snapshot.SnapshotLockProvider:82)
[2024-12-16 23:00:47,848] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,849] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,849] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,850] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,851] INFO [mongodb-source-connector|task-0] Found existing offset for at {sec=1734361270, ord=1, resume_token=zQAAAAJfZGF0YQC9AAAAODI2NzYwNDBCNjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNDBCNjQ5NkY2QjQ1OTk5NjQwMzMwMDAwMDQAAA==} (io.debezium.connector.mongodb.connection.MongoDbConnection:202)
[2024-12-16 23:00:47,852] INFO [mongodb-source-connector|task-0] Adding discovered server 172.30.2.147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,856] INFO [mongodb-source-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=172.30.2.147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=1148922, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Mon Dec 16 23:00:38 ICT 2024, lastUpdateTimeNanos=71664616315731} (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,857] INFO [mongodb-source-connector|task-0] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.11.0"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-125-generic"}, "platform": "Java/Ubuntu/17.0.13+11-Ubuntu-2ubuntu122.04"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@5691a171, com.mongodb.Jep395RecordCodecProvider@415feae4, com.mongodb.KotlinCodecProvider@26839f41]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[172.30.2.147:27017], srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='rs0', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='10000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=javax.net.ssl.SSLContext@347141f2}, applicationName='null', compressorList=[], uuidRepresentation=STANDARD, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null} (org.mongodb.driver.client:71)
[2024-12-16 23:00:47,859] INFO [mongodb-source-connector|task-0] Effective change stream pipeline: [{"$replaceRoot": {"newRoot": {"namespace": {"$concat": ["$ns.db", ".", "$ns.coll"]}, "event": "$$ROOT"}}}, {"$match": {"$and": [{"$and": [{"event.ns.db": {"$regularExpression": {"pattern": "test", "options": "i"}}}, {"namespace": {"$regularExpression": {"pattern": "test.customers", "options": "i"}}}]}, {"event.operationType": {"$in": ["insert", "update", "replace", "delete"]}}]}}, {"$replaceRoot": {"newRoot": "$event"}}] (io.debezium.connector.mongodb.ChangeStreamPipelineFactory:56)
[2024-12-16 23:00:47,864] INFO [mongodb-source-connector|task-0] No server chosen by ReadPreferenceServerSelector{readPreference=primary} from cluster description ClusterDescription{type=REPLICA_SET, connectionMode=MULTIPLE, serverDescriptions=[ServerDescription{address=172.30.2.147:27017, type=UNKNOWN, state=CONNECTING}]}. Waiting for 10000 ms before timing out (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,865] INFO [mongodb-source-connector|task-0] Adding discovered server linux-ip-147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,867] INFO [mongodb-source-connector|task-0] Server 172.30.2.147:27017 is no longer a member of the replica set.  Removing from client view of cluster. (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,869] INFO [mongodb-source-connector|task-0] Discovered replica set primary 172.30.2.147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,870] INFO [mongodb-source-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=linux-ip-147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=2895553, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Mon Dec 16 23:00:38 ICT 2024, lastUpdateTimeNanos=71664630823000} (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,871] INFO [mongodb-source-connector|task-0] Discovered replica set primary linux-ip-147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,912] INFO [mongodb-source-connector|task-0] Valid resume token present, so no snapshot will be performed' (io.debezium.connector.mongodb.connection.MongoDbConnection:220)
[2024-12-16 23:00:47,916] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = fullfillment named = change-event-source-coordinator (io.debezium.util.Threads:270)
[2024-12-16 23:00:47,916] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = fullfillment named = blocking-snapshot (io.debezium.util.Threads:270)
[2024-12-16 23:00:47,917] INFO [mongodb-source-connector|task-0] Creating thread debezium-mongodbconnector-fullfillment-change-event-source-coordinator (io.debezium.util.Threads:287)
[2024-12-16 23:00:47,917] INFO [mongodb-source-connector|task-0] WorkerSourceTask{id=mongodb-source-connector-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:280)
[2024-12-16 23:00:47,919] INFO [mongodb-source-connector|task-0] Metrics registered (io.debezium.pipeline.ChangeEventSourceCoordinator:137)
[2024-12-16 23:00:47,919] INFO [mongodb-source-connector|task-0] Context created (io.debezium.pipeline.ChangeEventSourceCoordinator:140)
[2024-12-16 23:00:47,920] INFO [mongodb-source-connector|task-0] A previous offset indicating a completed snapshot has been found. (io.debezium.connector.mongodb.MongoDbSnapshotChangeEventSource:144)
[2024-12-16 23:00:47,920] INFO [mongodb-source-connector|task-0] According to the connector configuration, no snapshot will occur. (io.debezium.connector.mongodb.MongoDbSnapshotChangeEventSource:151)
[2024-12-16 23:00:47,920] INFO [mongodb-source-connector|task-0] Snapshot ended with SnapshotResult [status=SKIPPED, offset=MongoDbOffsetContext [sourceInfo=SourceInfo [initialSync=false, collectionId=null, position=Position [ts=Timestamp{value=7449024934099025921, seconds=1734361270, inc=1}, changeStreamSessionTxnId=null, resumeToken=zQAAAAJfZGF0YQC9AAAAODI2NzYwNDBCNjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNDBCNjQ5NkY2QjQ1OTk5NjQwMzMwMDAwMDQAAA==]]]] (io.debezium.pipeline.ChangeEventSourceCoordinator:298)
[2024-12-16 23:00:47,920] INFO [mongodb-source-connector|task-0] Connected metrics set to 'true' (io.debezium.pipeline.ChangeEventSourceCoordinator:477)
[2024-12-16 23:00:47,921] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = mongodb named = incremental-snapshot (io.debezium.util.Threads:270)
[2024-12-16 23:00:47,921] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,923] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,928] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,929] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,930] INFO [mongodb-source-connector|task-0] No incremental snapshot in progress, no action needed on start (io.debezium.connector.mongodb.snapshot.MongoDbIncrementalSnapshotChangeEventSource:262)
[2024-12-16 23:00:47,931] INFO [mongodb-source-connector|task-0] SignalProcessor started. Scheduling it every 5000ms (io.debezium.pipeline.signal.SignalProcessor:105)
[2024-12-16 23:00:47,932] INFO [mongodb-source-connector|task-0] Creating thread debezium-mongodbconnector-fullfillment-SignalProcessor (io.debezium.util.Threads:287)
[2024-12-16 23:00:47,932] INFO [mongodb-source-connector|task-0] Starting streaming (io.debezium.pipeline.ChangeEventSourceCoordinator:323)
[2024-12-16 23:00:47,933] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,933] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,934] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,935] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-16 23:00:47,936] INFO [mongodb-source-connector|task-0] Adding discovered server 172.30.2.147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,940] INFO [mongodb-source-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=172.30.2.147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=932488, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Mon Dec 16 23:00:38 ICT 2024, lastUpdateTimeNanos=71664700641911} (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,941] INFO [mongodb-source-connector|task-0] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.11.0"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-125-generic"}, "platform": "Java/Ubuntu/17.0.13+11-Ubuntu-2ubuntu122.04"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@5691a171, com.mongodb.Jep395RecordCodecProvider@415feae4, com.mongodb.KotlinCodecProvider@26839f41]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[172.30.2.147:27017], srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='rs0', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='10000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=javax.net.ssl.SSLContext@61516ad5}, applicationName='null', compressorList=[], uuidRepresentation=STANDARD, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null} (org.mongodb.driver.client:71)
[2024-12-16 23:00:47,942] INFO [mongodb-source-connector|task-0] Reading change stream (io.debezium.connector.mongodb.MongoDbStreamingChangeEventSource:100)
[2024-12-16 23:00:47,943] INFO [mongodb-source-connector|task-0] Effective change stream pipeline: [{"$replaceRoot": {"newRoot": {"namespace": {"$concat": ["$ns.db", ".", "$ns.coll"]}, "event": "$$ROOT"}}}, {"$match": {"$and": [{"$and": [{"event.ns.db": {"$regularExpression": {"pattern": "test", "options": "i"}}}, {"namespace": {"$regularExpression": {"pattern": "test.customers", "options": "i"}}}]}, {"event.operationType": {"$in": ["insert", "update", "replace", "delete"]}}]}}, {"$replaceRoot": {"newRoot": "$event"}}] (io.debezium.connector.mongodb.ChangeStreamPipelineFactory:56)
[2024-12-16 23:00:47,948] INFO [mongodb-source-connector|task-0] Resuming streaming from token 'zQAAAAJfZGF0YQC9AAAAODI2NzYwNDBCNjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNDBCNjQ5NkY2QjQ1OTk5NjQwMzMwMDAwMDQAAA==' (io.debezium.connector.mongodb.MongoDbStreamingChangeEventSource:207)
[2024-12-16 23:00:47,949] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = fullfillment named = replicator-fetcher (io.debezium.util.Threads:270)
[2024-12-16 23:00:47,949] INFO [mongodb-source-connector|task-0] Fetcher submitted for execution: io.debezium.connector.mongodb.events.BufferingChangeStreamCursor$EventFetcher@50d1b79 @ java.util.concurrent.ThreadPoolExecutor@63d928ba[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] (io.debezium.connector.mongodb.events.BufferingChangeStreamCursor:367)
[2024-12-16 23:00:47,949] INFO [mongodb-source-connector|task-0] Creating thread debezium-mongodbconnector-fullfillment-replicator-fetcher-0 (io.debezium.util.Threads:287)
[2024-12-16 23:00:47,950] INFO [mongodb-source-connector|task-0] Adding discovered server linux-ip-147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,958] INFO [mongodb-source-connector|task-0] Server 172.30.2.147:27017 is no longer a member of the replica set.  Removing from client view of cluster. (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,959] INFO [mongodb-source-connector|task-0] Discovered replica set primary 172.30.2.147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,961] INFO [mongodb-source-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=linux-ip-147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=4616415, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Mon Dec 16 23:00:38 ICT 2024, lastUpdateTimeNanos=71664721302743} (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,973] INFO [mongodb-source-connector|task-0] No server chosen by ReadPreferenceServerSelector{readPreference=primary} from cluster description ClusterDescription{type=REPLICA_SET, connectionMode=MULTIPLE, serverDescriptions=[ServerDescription{address=172.30.2.147:27017, type=UNKNOWN, state=CONNECTING}]}. Waiting for 10000 ms before timing out (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:47,977] INFO [mongodb-source-connector|task-0] Discovered replica set primary linux-ip-147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-16 23:00:57,820] INFO [mongodb-source-connector|task-0|offsets] WorkerSourceTask{id=mongodb-source-connector-0} Committing offsets for 6 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:236)
[2024-12-16 23:01:24,756] INFO 172.30.0.4 - - [16/Dec/2024:16:01:24 +0000] "GET /connectors/mongodb-source-connector/status HTTP/1.1" 200 184 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36" 47 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-16 23:01:38,872] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-16 23:01:38,874] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:01:38,875] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:01:38,887] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=363, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:01:38,897] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=363, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:01:38,898] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 363 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=583, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:01:38,898] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 583 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:01:38,899] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-16 23:01:38,901] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-16 23:01:38,904] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:01:38,907] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:01:38,910] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-16 23:01:38,912] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-16 23:01:38,912] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:01:38,918] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:01:38,920] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:01:38,972] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:01:38,979] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:01:38,979] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:01:38,984] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:01:38,988] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=364, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:01:38,994] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=364, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:01:38,995] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 364 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=586, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:01:38,996] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 586 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:01:38,997] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-16 23:01:38,998] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-16 23:01:39,001] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-16 23:01:39,009] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:01:39,021] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-16 23:01:39,037] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:01:39,037] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Handling task config update by stopping tasks [mysql-sink-connector-0], which will be restarted after rebalance if still assigned to this worker (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2024-12-16 23:01:39,038] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-16 23:01:39,038] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-16 23:01:39,038] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:01:39,038] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:01:39,042] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=365, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:01:39,049] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=365, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:01:39,049] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 365 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=587, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:01:39,050] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 587 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:01:39,050] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-16 23:01:39,051] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-16 23:01:39,053] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-16 23:01:39,054] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:01:39,056] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-16 23:01:39,058] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:03:03,796] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-16 23:03:03,798] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-16 23:03:03,807] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:03:03,808] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:03:03,812] INFO 172.30.2.207 - - [16/Dec/2024:16:03:03 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 63 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-16 23:03:03,836] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=366, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:03:03,846] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=366, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:03:03,848] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-16 23:03:03,850] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-16 23:03:03,851] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-16 23:03:03,853] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-16 23:03:03,861] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-16 23:03:03,873] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-16 23:03:03,874] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-16 23:03:03,874] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 366 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=589, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:03:03,875] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 589 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:03:03,875] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:03:03,876] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:03:03,876] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:03:03,889] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=367, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:03:03,903] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=367, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:03:03,905] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 367 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=589, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:03:03,906] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 589 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:03:03,906] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:03:05,668] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-16 23:03:05,670] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:03:05,671] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:03:05,680] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=368, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:03:05,691] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=368, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:03:05,692] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 368 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=590, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:03:05,694] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 590 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:03:05,695] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-16 23:03:05,696] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-16 23:03:05,700] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:03:05,716] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:03:05,726] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-16 23:03:05,726] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-16 23:03:05,731] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:03:05,733] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:03:05,740] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:03:05,783] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:03:05,785] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:03:05,785] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:03:05,790] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=369, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:03:05,796] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=369, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:03:05,797] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 369 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=592, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:03:05,798] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 592 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:03:05,798] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:03:05,800] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-16 23:03:05,801] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-16 23:03:05,803] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-16 23:03:05,806] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:03:05,812] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-16 23:03:05,816] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:03:05,817] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Handling task config update by stopping tasks [mysql-sink-connector-0], which will be restarted after rebalance if still assigned to this worker (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2024-12-16 23:03:05,817] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-16 23:03:05,818] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-16 23:03:05,818] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:03:05,818] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:03:05,822] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=370, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:03:05,834] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=370, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:03:05,835] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 370 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=594, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:03:05,836] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 594 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:03:05,837] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-16 23:03:05,838] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-16 23:03:05,845] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-16 23:03:05,855] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:03:05,857] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-16 23:03:05,866] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:03:31,319] INFO [mongodb-source-connector|task-0] 11 records sent during previous 00:02:43.548, last recorded offset of {server_id=fullfillment} partition is {sec=1734365010, ord=1, resume_token=zQAAAAJfZGF0YQC9AAAAODI2NzYwNEY1MjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2NDY1NkM2NTc0NjUwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNEU2QjQ5NkY2QjQ1OTk5NjQwMzYwMDAwMDQAAA==} (io.debezium.connector.common.BaseSourceTask:349)
[2024-12-16 23:03:37,878] INFO [mongodb-source-connector|task-0|offsets] WorkerSourceTask{id=mongodb-source-connector-0} Committing offsets for 2 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:236)
[2024-12-16 23:04:15,203] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-16 23:04:15,206] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-16 23:04:15,207] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:04:15,211] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:04:15,214] INFO 172.30.2.207 - - [16/Dec/2024:16:04:15 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 77 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-16 23:04:15,220] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=371, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:04:15,226] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=371, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:04:15,228] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-16 23:04:15,228] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-16 23:04:15,229] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-16 23:04:15,230] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-16 23:04:15,233] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-16 23:04:15,235] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-16 23:04:15,261] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-16 23:04:15,262] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 371 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=596, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:04:15,265] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 596 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:04:15,268] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:04:15,268] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:04:15,269] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:04:15,278] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=372, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:04:15,293] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=372, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:04:15,294] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 372 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=596, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:04:15,295] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 596 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:04:15,296] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:04:17,160] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-16 23:04:17,162] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:04:17,163] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:04:17,175] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=373, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:04:17,184] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=373, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:04:17,184] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 373 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=597, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:04:17,185] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 597 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:04:17,186] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-16 23:04:17,188] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-16 23:04:17,191] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:04:17,202] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:04:17,212] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-16 23:04:17,216] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-16 23:04:17,216] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:04:17,219] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:04:17,222] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:04:17,259] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:04:17,269] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:04:17,270] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:04:17,271] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:04:17,278] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=374, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:04:17,287] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=374, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:04:17,288] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 374 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=601, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:04:17,289] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 601 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:04:17,290] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:04:30,152] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-16 23:04:30,153] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-16 23:04:30,154] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:04:30,154] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:04:30,160] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=375, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:04:30,162] INFO 172.30.2.207 - - [16/Dec/2024:16:04:30 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 40 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-16 23:04:30,173] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=375, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:04:30,174] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-16 23:04:30,174] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-16 23:04:30,176] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-16 23:04:30,178] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-16 23:04:30,184] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-16 23:04:30,184] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 375 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=603, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:04:30,185] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 603 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:04:30,185] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:04:30,186] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:04:30,186] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:04:30,195] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=376, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:04:30,208] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=376, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:04:30,209] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 376 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=603, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:04:30,210] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 603 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:04:30,210] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:06:29,062] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-16 23:06:29,067] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:06:29,067] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:06:29,091] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=377, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:06:29,104] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=377, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:06:29,105] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 377 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=604, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:06:29,106] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 604 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:06:29,106] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-16 23:06:29,108] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-16 23:06:29,112] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:06:29,115] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:06:29,118] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-16 23:06:29,120] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-16 23:06:29,120] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:06:29,132] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:06:29,134] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:06:29,175] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:06:29,177] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:06:29,178] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:06:29,182] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=378, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:06:29,183] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:06:29,186] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=378, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:06:29,187] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 378 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=607, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:06:29,188] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 607 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:06:29,189] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-16 23:06:29,189] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-16 23:06:29,192] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-16 23:06:29,196] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:06:29,204] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-16 23:06:29,211] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:06:29,212] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:06:29,213] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:06:29,219] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=379, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:06:29,223] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=379, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:06:29,224] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-16 23:06:29,225] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-16 23:06:29,225] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-16 23:06:29,227] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-16 23:06:29,227] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 379 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=608, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:06:29,232] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 608 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:06:29,232] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:06:29,232] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:06:29,234] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:06:29,237] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=380, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:06:29,247] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=380, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:06:29,248] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 380 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=608, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:06:29,250] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 608 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:06:29,251] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:06:45,809] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-16 23:06:45,810] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-16 23:06:45,821] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:06:45,822] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:06:45,826] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=381, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:06:45,830] INFO 172.30.2.207 - - [16/Dec/2024:16:06:45 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 44 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-16 23:06:45,834] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=381, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:06:45,836] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-16 23:06:45,836] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-16 23:06:45,839] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-16 23:06:45,841] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-16 23:06:45,851] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-16 23:06:45,851] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 381 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=610, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:06:45,854] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 610 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:06:45,855] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:06:45,855] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:06:45,855] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:06:45,861] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=382, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:06:45,867] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=382, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:06:45,868] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 382 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=610, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:06:45,869] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 610 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:06:45,869] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:07:36,196] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-16 23:07:36,202] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:07:36,202] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:07:36,219] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=383, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:07:36,236] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=383, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:07:36,237] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 383 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=611, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:07:36,238] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 611 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:07:36,240] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-16 23:07:36,242] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-16 23:07:36,248] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:07:36,254] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:07:36,261] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-16 23:07:36,272] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-16 23:07:36,273] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:07:36,278] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:07:36,281] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:07:36,300] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:07:36,329] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:07:36,335] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:07:36,335] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:07:36,339] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=384, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:07:36,343] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=384, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:07:36,344] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 384 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=615, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:07:36,345] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 615 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:07:36,346] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-16 23:07:36,347] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-16 23:07:36,350] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-16 23:07:36,354] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:07:36,361] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-16 23:07:36,372] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:08:18,393] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-16 23:08:18,394] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-16 23:08:18,395] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:08:18,396] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:08:18,427] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=385, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:08:18,432] INFO 172.30.2.207 - - [16/Dec/2024:16:08:18 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 104 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-16 23:08:18,442] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=385, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:08:18,444] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-16 23:08:18,445] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-16 23:08:18,445] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-16 23:08:18,447] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-16 23:08:18,451] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-16 23:08:18,454] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-16 23:08:18,457] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-16 23:08:18,458] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 385 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=617, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:08:18,460] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 617 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:08:18,460] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:08:18,461] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:08:18,462] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:08:18,468] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=386, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:08:18,473] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=386, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:08:18,474] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 386 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=617, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:08:18,474] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 617 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:08:18,475] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:09:19,604] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2510)
[2024-12-16 23:09:19,606] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2510)
[2024-12-16 23:11:30,136] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-16 23:11:30,141] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:11:30,142] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:11:30,158] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=387, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:11:30,170] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=387, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:11:30,172] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 387 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=620, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:11:30,173] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 620 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:11:30,174] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-16 23:11:30,175] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-16 23:11:30,179] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:11:30,183] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:11:30,185] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-16 23:11:30,186] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-16 23:11:30,187] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:11:30,194] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:11:30,198] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:11:30,266] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:11:30,279] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:11:30,280] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:11:30,280] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:11:30,283] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=388, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:11:30,287] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=388, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:11:30,288] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 388 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=624, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:11:30,288] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 624 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:11:30,289] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:11:45,961] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-16 23:11:45,962] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-16 23:11:45,962] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:11:45,962] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:11:45,970] INFO 172.30.2.207 - - [16/Dec/2024:16:11:45 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 67 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-16 23:11:45,975] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=389, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:11:45,982] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=389, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:11:45,983] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-16 23:11:45,984] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-16 23:11:45,985] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-16 23:11:45,987] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-16 23:11:45,989] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-16 23:11:45,989] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 389 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=626, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:11:45,990] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 626 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:11:45,991] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:11:45,991] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:11:45,991] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:11:45,996] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=390, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:11:46,010] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=390, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:11:46,011] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 390 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=626, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:11:46,013] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 626 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:11:46,013] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:12:50,432] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-16 23:12:50,436] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:12:50,436] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:12:50,449] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=391, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:12:50,461] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=391, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:12:50,462] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 391 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=627, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:12:50,463] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 627 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:12:50,464] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-16 23:12:50,466] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-16 23:12:50,470] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:12:50,473] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:12:50,476] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-16 23:12:50,478] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-16 23:12:50,479] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:12:50,492] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:12:50,494] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:12:50,544] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:12:50,547] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:12:50,547] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:12:50,548] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:12:50,556] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=392, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:12:50,564] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=392, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:12:50,564] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 392 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=631, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:12:50,565] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 631 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:12:50,565] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:13:27,934] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-16 23:13:27,936] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-16 23:13:27,983] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:13:27,984] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:13:27,986] INFO 172.30.2.207 - - [16/Dec/2024:16:13:27 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 86 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-16 23:13:27,990] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=393, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:13:27,996] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=393, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:13:27,997] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-16 23:13:27,997] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-16 23:13:27,999] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-16 23:13:28,003] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-16 23:13:28,004] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-16 23:13:28,004] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 393 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=633, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:13:28,006] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 633 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:13:28,006] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:13:28,006] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:13:28,007] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:13:28,020] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=394, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:13:28,026] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=394, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:13:28,026] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 394 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=633, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:13:28,027] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 633 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:13:28,027] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:15:10,259] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-16 23:15:10,264] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:15:10,265] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:15:10,274] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=395, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:15:10,289] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=395, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:15:10,290] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 395 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=634, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:15:10,291] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 634 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:15:10,292] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-16 23:15:10,294] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-16 23:15:10,301] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:15:10,304] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:15:10,306] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-16 23:15:10,308] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-16 23:15:10,309] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:15:10,317] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:15:10,320] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:15:10,374] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:15:10,375] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:15:10,376] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:15:10,382] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=396, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:15:10,391] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=396, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:15:10,392] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 396 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=636, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:15:10,392] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 636 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:15:10,393] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-16 23:15:10,394] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-16 23:15:10,396] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-16 23:15:10,397] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:15:10,402] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:15:10,404] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-16 23:15:10,409] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:15:10,409] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Handling task config update by stopping tasks [mysql-sink-connector-0], which will be restarted after rebalance if still assigned to this worker (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2024-12-16 23:15:10,409] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-16 23:15:10,410] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-16 23:15:10,410] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:15:10,410] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:15:10,428] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=397, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:15:10,442] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=397, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:15:10,442] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 397 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=638, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:15:10,443] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 638 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:15:10,444] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-16 23:15:10,445] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-16 23:15:10,447] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-16 23:15:10,451] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:15:10,455] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-16 23:15:10,463] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:37:36,839] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-16 23:37:36,841] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-16 23:37:36,847] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:37:36,848] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:37:36,852] INFO 172.30.2.207 - - [16/Dec/2024:16:37:36 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 100 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-16 23:37:36,856] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=398, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:37:36,862] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=398, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:37:36,864] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-16 23:37:36,864] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-16 23:37:36,865] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-16 23:37:36,867] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-16 23:37:36,871] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-16 23:37:36,878] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-16 23:37:36,879] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-16 23:37:36,880] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 398 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=640, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:37:36,881] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 640 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:37:36,882] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:37:36,882] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:37:36,882] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:37:36,887] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=399, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:37:36,900] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=399, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:37:36,901] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 399 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=640, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:37:36,902] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 640 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:37:36,903] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:37:49,686] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-16 23:37:49,687] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:37:49,687] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:37:49,694] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=400, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:37:49,701] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=400, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:37:49,701] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 400 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=641, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:37:49,702] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 641 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:37:49,703] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-16 23:37:49,704] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-16 23:37:49,708] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:37:49,715] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:37:49,719] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-16 23:37:49,720] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-16 23:37:49,720] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:37:49,724] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:37:49,725] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:37:49,781] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:37:49,786] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:37:49,786] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:37:49,792] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=401, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:37:49,793] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:37:49,799] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=401, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:37:49,800] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 401 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=644, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:37:49,801] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 644 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:37:49,802] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-16 23:37:49,804] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-16 23:37:49,806] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-16 23:37:49,812] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:37:49,821] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-16 23:37:49,832] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:37:49,832] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Handling task config update by stopping tasks [mysql-sink-connector-0], which will be restarted after rebalance if still assigned to this worker (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2024-12-16 23:37:49,832] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-16 23:37:49,833] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-16 23:37:49,833] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:37:49,833] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:37:49,837] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=402, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:37:49,842] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=402, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:37:49,845] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 402 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=645, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:37:49,846] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 645 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:37:49,847] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-16 23:37:49,848] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-16 23:37:49,851] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-16 23:37:49,855] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:37:49,858] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-16 23:37:49,865] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:59:03,143] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-16 23:59:03,145] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-16 23:59:03,149] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:59:03,150] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:59:03,155] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=403, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:59:03,157] INFO 172.30.2.207 - - [16/Dec/2024:16:59:03 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 80 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-16 23:59:03,163] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=403, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:59:03,164] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-16 23:59:03,164] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-16 23:59:03,166] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-16 23:59:03,167] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-16 23:59:03,183] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-16 23:59:03,186] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-16 23:59:03,193] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-16 23:59:03,193] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 403 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=647, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:59:03,194] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 647 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:59:03,195] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:59:03,195] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:59:03,195] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:59:03,201] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=404, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:59:03,215] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=404, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:59:03,216] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 404 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=647, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:59:03,218] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 647 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:59:03,219] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:59:04,700] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-16 23:59:04,702] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:59:04,703] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:59:04,706] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=405, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:59:04,713] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=405, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:59:04,714] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 405 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=648, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:59:04,714] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 648 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:59:04,715] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-16 23:59:04,716] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-16 23:59:04,718] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:59:04,724] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:59:04,725] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-16 23:59:04,729] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-16 23:59:04,730] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:59:04,734] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-16 23:59:04,741] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:59:04,762] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:59:04,777] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:59:04,778] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:59:04,786] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=406, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:59:04,814] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=406, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:59:04,815] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 406 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=650, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:59:04,815] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 650 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:59:04,816] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-16 23:59:04,817] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-16 23:59:04,819] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-16 23:59:04,824] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:59:04,829] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-16 23:59:04,833] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-16 23:59:04,867] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-16 23:59:04,868] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Handling task config update by stopping tasks [mysql-sink-connector-0], which will be restarted after rebalance if still assigned to this worker (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2024-12-16 23:59:04,868] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-16 23:59:04,869] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-16 23:59:04,869] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-16 23:59:04,869] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-16 23:59:04,872] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=407, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-16 23:59:04,876] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=407, memberId='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-16 23:59:04,877] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 407 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-423e807c-b1a6-4424-b8a4-454b167b0254', leaderUrl='http://172.30.2.147:8083/', offset=652, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-16 23:59:04,878] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 652 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-16 23:59:04,885] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-16 23:59:04,886] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-16 23:59:04,888] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-16 23:59:04,890] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-16 23:59:04,891] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-16 23:59:04,896] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
