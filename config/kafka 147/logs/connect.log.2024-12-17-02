[2024-12-17 02:06:03,317] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:06:03,324] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 02:06:03,325] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:06:03,325] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:06:03,334] INFO 172.30.2.207 - - [16/Dec/2024:19:06:03 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 75 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 02:06:03,340] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=514, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:06:03,350] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=514, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:06:03,351] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 02:06:03,352] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 02:06:03,353] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-17 02:06:03,353] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-17 02:06:03,360] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 02:06:03,363] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 02:06:03,380] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 02:06:03,381] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 514 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=813, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:06:03,382] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 813 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:06:03,383] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:06:03,384] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:06:03,384] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:06:03,387] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=515, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:06:03,392] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=515, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:06:03,392] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 515 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=813, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:06:03,394] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 813 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:06:03,394] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:07:39,337] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 02:07:39,349] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:07:39,350] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:07:39,358] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=516, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:07:39,370] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=516, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:07:39,371] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 516 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=814, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:07:39,372] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 814 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:07:39,374] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 02:07:39,376] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 02:07:39,382] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:07:39,401] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:07:39,415] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 02:07:39,417] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 02:07:39,427] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:07:39,433] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 02:07:39,438] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:07:39,439] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:07:39,445] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=517, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:07:39,457] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=517, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:07:39,459] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 517 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=816, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:07:39,461] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 816 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:07:39,462] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 02:07:39,464] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 02:07:39,468] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 02:07:39,474] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:07:39,482] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-17 02:07:39,491] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:07:39,497] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:07:39,505] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:09:19,599] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2510)
[2024-12-17 02:09:19,605] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2510)
[2024-12-17 02:21:47,211] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:21:47,215] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 02:21:47,237] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:21:47,239] INFO 172.30.2.207 - - [16/Dec/2024:19:21:47 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 77 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 02:21:47,239] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:21:47,249] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=518, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:21:47,260] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=518, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:21:47,262] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 02:21:47,262] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-17 02:21:47,264] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-17 02:21:47,263] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 02:21:47,272] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 02:21:47,275] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 02:21:47,298] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 02:21:47,300] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 518 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=820, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:21:47,302] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 820 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:21:47,303] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:21:47,303] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:21:47,303] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:21:47,309] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=519, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:21:47,339] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=519, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:21:47,339] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 519 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=820, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:21:47,340] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 820 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:21:47,341] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:24:01,420] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 02:24:01,434] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:24:01,436] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:24:01,467] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=520, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:24:01,480] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=520, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:24:01,481] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 520 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=821, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:24:01,482] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 821 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:24:01,483] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 02:24:01,485] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 02:24:01,492] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:24:01,499] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:24:01,504] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 02:24:01,509] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 02:24:01,509] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:24:01,521] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:24:01,523] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:24:01,550] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 02:24:01,558] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 02:24:01,564] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:24:01,564] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:24:01,567] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=521, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:24:01,586] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=521, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:24:01,587] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 521 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=825, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:24:01,587] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 825 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:24:01,588] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:25:55,972] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:25:55,974] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 02:25:55,975] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:25:55,975] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:25:55,983] INFO 172.30.2.207 - - [16/Dec/2024:19:25:55 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 54 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 02:25:55,988] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=522, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:25:55,997] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=522, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:25:55,999] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 02:25:55,999] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 02:25:56,003] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 02:25:56,010] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 02:25:56,016] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 02:25:56,017] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 522 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=827, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:25:56,019] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 827 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:25:56,021] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:25:56,021] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:25:56,022] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:25:56,025] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=523, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:25:56,030] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=523, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:25:56,031] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 523 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=827, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:25:56,032] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 827 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:25:56,032] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:30:16,843] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 02:30:16,849] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:30:16,849] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:30:16,870] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=524, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:30:16,880] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=524, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:30:16,881] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 524 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=828, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:30:16,882] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 828 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:30:16,883] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 02:30:16,885] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 02:30:16,888] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:30:16,895] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:30:16,912] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 02:30:16,914] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 02:30:16,915] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:30:16,921] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:30:16,924] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:30:16,947] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 02:30:16,981] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 02:30:16,982] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:30:16,983] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:30:16,988] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=525, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:30:16,993] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=525, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:30:16,994] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 525 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=832, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:30:16,995] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 832 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:30:16,996] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 02:30:16,997] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 02:30:17,001] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 02:30:17,015] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:30:17,029] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-17 02:30:17,035] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:32:39,835] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:32:39,837] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 02:32:39,838] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:32:39,839] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:32:39,844] INFO 172.30.2.207 - - [16/Dec/2024:19:32:39 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 79 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 02:32:39,857] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=526, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:32:39,869] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=526, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:32:39,870] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 02:32:39,870] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-17 02:32:39,871] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-17 02:32:39,870] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 02:32:39,877] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 02:32:39,879] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 02:32:39,893] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 02:32:39,894] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 526 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=834, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:32:39,896] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 834 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:32:39,897] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:32:39,897] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:32:39,897] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:32:39,911] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=527, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:32:39,919] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=527, memberId='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:32:39,919] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 527 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3', leaderUrl='http://172.30.2.147:8083/', offset=834, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:32:39,920] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 834 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:32:39,920] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:35:57,910] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:87)
[2024-12-17 02:35:57,916] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:358)
[2024-12-17 02:35:57,936] INFO Stopped http_0.0.0.08083@50195abf{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2024-12-17 02:35:57,942] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2024-12-17 02:35:57,976] INFO Stopped o.e.j.s.ServletContextHandler@75d773fa{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2024-12-17 02:35:57,976] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:387)
[2024-12-17 02:35:57,977] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:851)
[2024-12-17 02:35:57,977] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:808)
[2024-12-17 02:35:57,978] INFO [mongodb-source-connector|worker] Stopping connector mongodb-source-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 02:35:57,978] INFO [mongodb-source-connector|worker] Scheduled shutdown for WorkerConnector{id=mongodb-source-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 02:35:57,979] INFO [mongodb-source-connector|worker] Stopping MongoDB connector (io.debezium.connector.mongodb.MongoDbConnector:82)
[2024-12-17 02:35:57,979] INFO [mongodb-source-connector|worker] Stopped MongoDB connector (io.debezium.connector.mongodb.MongoDbConnector:86)
[2024-12-17 02:35:57,983] INFO [mongodb-source-connector|worker] Completed shutdown for WorkerConnector{id=mongodb-source-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 02:35:57,991] INFO [mongodb-source-connector|task-0] Stopping task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.Worker:1048)
[2024-12-17 02:35:58,472] INFO [mongodb-source-connector|task-0] Stopping down connector (io.debezium.connector.common.BaseSourceTask:432)
[2024-12-17 02:35:58,940] INFO [mongodb-source-connector|task-0] Awaiting fetcher thread termination (io.debezium.connector.mongodb.events.BufferingChangeStreamCursor:457)
[2024-12-17 02:35:59,764] INFO [mongodb-source-connector|task-0] Finished streaming (io.debezium.pipeline.ChangeEventSourceCoordinator:325)
[2024-12-17 02:35:59,768] INFO [mongodb-source-connector|task-0] Connected metrics set to 'false' (io.debezium.pipeline.ChangeEventSourceCoordinator:477)
[2024-12-17 02:35:59,771] INFO [mongodb-source-connector|task-0] SignalProcessor stopped (io.debezium.pipeline.signal.SignalProcessor:127)
[2024-12-17 02:35:59,774] INFO [mongodb-source-connector|task-0] Debezium ServiceRegistry stopped. (io.debezium.service.DefaultServiceRegistry:105)
[2024-12-17 02:35:59,776] INFO [mongodb-source-connector|task-0] [Producer clientId=connector-producer-mongodb-source-connector-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2024-12-17 02:35:59,794] INFO [mongodb-source-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:35:59,794] INFO [mongodb-source-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:59,794] INFO [mongodb-source-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:59,794] INFO [mongodb-source-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:35:59,797] INFO [mongodb-source-connector|task-0] App info kafka.producer for connector-producer-mongodb-source-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:35:59,804] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:317)
[2024-12-17 02:35:59,808] INFO [Producer clientId=mongo-source-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2024-12-17 02:35:59,838] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:35:59,839] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:59,840] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:59,840] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:35:59,841] INFO App info kafka.producer for mongo-source-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:35:59,847] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2024-12-17 02:35:59,850] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 02:35:59,859] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Node 0 sent an invalid full fetch response with extraIds=(BvVnx0t_SlGXkZscTz3wEQ), response=() (org.apache.kafka.clients.FetchSessionHandler:556)
[2024-12-17 02:35:59,863] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:35:59,864] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:59,865] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:59,865] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:35:59,886] INFO App info kafka.consumer for mongo-source-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:35:59,887] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:341)
[2024-12-17 02:35:59,888] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:407)
[2024-12-17 02:35:59,889] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:317)
[2024-12-17 02:35:59,890] INFO [Producer clientId=mongo-source-cluster-configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2024-12-17 02:35:59,910] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:35:59,911] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:59,912] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:59,912] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:35:59,914] INFO App info kafka.producer for mongo-source-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:35:59,914] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2024-12-17 02:35:59,915] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 02:36:00,213] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:36:00,214] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:36:00,214] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:36:00,214] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:36:00,227] INFO App info kafka.consumer for mongo-source-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:36:00,227] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:341)
[2024-12-17 02:36:00,227] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:412)
[2024-12-17 02:36:00,227] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:250)
[2024-12-17 02:36:00,230] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:261)
[2024-12-17 02:36:00,230] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:317)
[2024-12-17 02:36:00,230] INFO [Producer clientId=mongo-source-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2024-12-17 02:36:00,256] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:36:00,256] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:36:00,257] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:36:00,257] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:36:00,258] INFO App info kafka.producer for mongo-source-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:36:00,258] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2024-12-17 02:36:00,259] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 02:36:00,332] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:36:00,333] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:36:00,333] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:36:00,333] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:36:00,342] INFO App info kafka.consumer for mongo-source-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:36:00,351] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:341)
[2024-12-17 02:36:00,351] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:263)
[2024-12-17 02:36:00,351] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:36:00,351] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:36:00,352] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:36:00,352] INFO App info kafka.connect for 172.30.2.147:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:36:00,352] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:271)
[2024-12-17 02:36:00,357] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Member connect-172.30.2.147:8083-244b4e1d-f1cb-4631-ad9c-add47a44b7e3 sending LeaveGroup request to coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1174)
[2024-12-17 02:36:00,360] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1056)
[2024-12-17 02:36:00,360] WARN [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1141)
[2024-12-17 02:36:00,360] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:36:00,360] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:36:00,361] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:36:00,369] INFO App info kafka.connect for connect-172.30.2.147:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:36:00,375] INFO App info kafka.admin.client for mongo-source-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:36:00,382] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:36:00,383] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:36:00,383] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:36:00,384] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:394)
[2024-12-17 02:36:00,388] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:858)
[2024-12-17 02:36:00,389] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:92)
[2024-12-17 02:36:02,844] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2024-12-17 02:36:02,854] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/opt/kafka/bin/../logs, -Dlog4j.configuration=file:/opt/kafka/bin/../config/connect-log4j.properties
	jvm.spec = Ubuntu, OpenJDK 64-Bit Server VM, 17.0.13, 17.0.13+11-Ubuntu-2ubuntu122.04
	jvm.classpath = /opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-sync-4.11.0.jar:/opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar:/opt/kafka/plugins/debezium-connector-mongodb/bson-record-codec-4.11.0.jar:/opt/kafka/plugins/debezium-connector-mongodb/bson-4.11.0.jar:/opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-core-4.11.0.jar:/opt/kafka/plugins/debezium-connector-mongodb/debezium-sink-3.0.4.Final.jar:/opt/kafka/plugins/debezium-connector-mongodb/debezium-api-3.0.4.Final.jar:/opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar:/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.12.0.jar:/opt/kafka/bin/../libs/caffeine-2.9.3.jar:/opt/kafka/bin/../libs/commons-beanutils-1.9.4.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-collections-3.2.2.jar:/opt/kafka/bin/../libs/commons-digester-2.1.jar:/opt/kafka/bin/../libs/commons-io-2.14.0.jar:/opt/kafka/bin/../libs/commons-lang3-3.12.0.jar:/opt/kafka/bin/../libs/commons-logging-1.2.jar:/opt/kafka/bin/../libs/commons-validator-1.7.jar:/opt/kafka/bin/../libs/connect-api-3.9.0.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-3.9.0.jar:/opt/kafka/bin/../libs/connect-json-3.9.0.jar:/opt/kafka/bin/../libs/connect-mirror-3.9.0.jar:/opt/kafka/bin/../libs/connect-mirror-client-3.9.0.jar:/opt/kafka/bin/../libs/connect-runtime-3.9.0.jar:/opt/kafka/bin/../libs/connect-transforms-3.9.0.jar:/opt/kafka/bin/../libs/error_prone_annotations-2.10.0.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.16.2.jar:/opt/kafka/bin/../libs/jackson-core-2.16.2.jar:/opt/kafka/bin/../libs/jackson-databind-2.16.2.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/opt/kafka/bin/../libs/jackson-module-afterburner-2.16.2.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.2.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/opt/kafka/bin/../libs/javassist-3.29.2-GA.jar:/opt/kafka/bin/../libs/javax.activation-api-1.2.0.jar:/opt/kafka/bin/../libs/javax.annotation-api-1.3.2.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.1.jar:/opt/kafka/bin/../libs/jersey-client-2.39.1.jar:/opt/kafka/bin/../libs/jersey-common-2.39.1.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.39.1.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/opt/kafka/bin/../libs/jersey-hk2-2.39.1.jar:/opt/kafka/bin/../libs/jersey-server-2.39.1.jar:/opt/kafka/bin/../libs/jetty-client-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-http-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-io-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-security-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-server-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-util-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jline-3.25.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/jose4j-0.9.4.jar:/opt/kafka/bin/../libs/jsr305-3.0.2.jar:/opt/kafka/bin/../libs/kafka-clients-3.9.0.jar:/opt/kafka/bin/../libs/kafka-group-coordinator-3.9.0.jar:/opt/kafka/bin/../libs/kafka-group-coordinator-api-3.9.0.jar:/opt/kafka/bin/../libs/kafka-metadata-3.9.0.jar:/opt/kafka/bin/../libs/kafka-raft-3.9.0.jar:/opt/kafka/bin/../libs/kafka-server-3.9.0.jar:/opt/kafka/bin/../libs/kafka-server-common-3.9.0.jar:/opt/kafka/bin/../libs/kafka-shell-3.9.0.jar:/opt/kafka/bin/../libs/kafka-storage-3.9.0.jar:/opt/kafka/bin/../libs/kafka-storage-api-3.9.0.jar:/opt/kafka/bin/../libs/kafka-streams-3.9.0.jar:/opt/kafka/bin/../libs/kafka-streams-examples-3.9.0.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-3.9.0.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-3.9.0.jar:/opt/kafka/bin/../libs/kafka-tools-3.9.0.jar:/opt/kafka/bin/../libs/kafka-tools-api-3.9.0.jar:/opt/kafka/bin/../libs/kafka-transaction-coordinator-3.9.0.jar:/opt/kafka/bin/../libs/kafka_2.13-3.9.0.jar:/opt/kafka/bin/../libs/lz4-java-1.8.0.jar:/opt/kafka/bin/../libs/maven-artifact-3.9.6.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-transport-classes-epoll-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.111.Final.jar:/opt/kafka/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/pcollections-4.0.1.jar:/opt/kafka/bin/../libs/plexus-utils-3.5.1.jar:/opt/kafka/bin/../libs/protobuf-java-3.25.5.jar:/opt/kafka/bin/../libs/reflections-0.10.2.jar:/opt/kafka/bin/../libs/reload4j-1.2.25.jar:/opt/kafka/bin/../libs/rocksdbjni-7.9.2.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/opt/kafka/bin/../libs/scala-library-2.13.14.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.5.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.14.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.36.jar:/opt/kafka/bin/../libs/slf4j-reload4j-1.7.36.jar:/opt/kafka/bin/../libs/snappy-java-1.1.10.5.jar:/opt/kafka/bin/../libs/swagger-annotations-2.2.8.jar:/opt/kafka/bin/../libs/trogdor-3.9.0.jar:/opt/kafka/bin/../libs/zookeeper-3.8.4.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.8.4.jar:/opt/kafka/bin/../libs/zstd-jni-1.5.6-4.jar
	os.spec = Linux, amd64, 5.15.0-125-generic
	os.vcpus = 2
 (org.apache.kafka.connect.runtime.WorkerInfo:72)
[2024-12-17 02:36:02,857] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2024-12-17 02:36:02,950] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:03,080] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 02:36:03,443] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:03,446] INFO Loading plugin from: /opt/kafka/plugins/hibernate-core-6.4.1.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:03,462] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 02:36:03,548] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/hibernate-core-6.4.1.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:03,549] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:03,581] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 02:36:03,584] ERROR Failed to discover Converter in /opt/kafka/plugins/debezium-connector-jdbc (org.apache.kafka.connect.runtime.isolation.PluginScanner:139)
java.util.ServiceConfigurationError: org.apache.kafka.connect.storage.Converter: Provider io.debezium.converters.CloudEventsConverter could not be instantiated
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:586)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:813)
	at java.base/java.util.ServiceLoader$ProviderImpl.get(ServiceLoader.java:729)
	at java.base/java.util.ServiceLoader$3.next(ServiceLoader.java:1403)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:177)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:61)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:84)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.util.ServiceConfigurationError: io.debezium.converters.spi.CloudEventsProvider: io.debezium.connector.mongodb.converters.MongoDbCloudEventsProvider not a subtype
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:593)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1244)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)
	at io.debezium.converters.CloudEventsConverter.<clinit>(CloudEventsConverter.java:135)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:789)
	... 13 more
[2024-12-17 02:36:03,635] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:03,875] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-sync-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:03,889] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-sync-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:03,890] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:03,907] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:03,908] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/bson-record-codec-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:03,918] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/bson-record-codec-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:03,919] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/bson-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:03,929] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/bson-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:03,930] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-core-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:03,941] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-core-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:03,942] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-sink-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:03,951] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-sink-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:03,952] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-api-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:03,962] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-api-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:03,962] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:03,970] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 02:36:03,972] ERROR Failed to discover Converter in /opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:139)
java.util.ServiceConfigurationError: org.apache.kafka.connect.storage.Converter: Provider io.debezium.converters.CloudEventsConverter could not be instantiated
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:586)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:813)
	at java.base/java.util.ServiceLoader$ProviderImpl.get(ServiceLoader.java:729)
	at java.base/java.util.ServiceLoader$3.next(ServiceLoader.java:1403)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:177)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:61)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:84)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.util.ServiceConfigurationError: io.debezium.converters.spi.CloudEventsProvider: io.debezium.connector.mongodb.converters.MongoDbCloudEventsProvider not a subtype
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:593)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1244)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)
	at io.debezium.converters.CloudEventsConverter.<clinit>(CloudEventsConverter.java:135)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:789)
	... 13 more
[2024-12-17 02:36:04,071] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,074] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/waffle-jna-3.2.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,119] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/waffle-jna-3.2.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,121] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jaxb-core-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,152] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-core-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,153] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/txw2-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,170] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/txw2-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,172] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/ojdbc11-21.15.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,186] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/ojdbc11-21.15.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,253] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/c3p0-0.9.5.5.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,290] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/c3p0-0.9.5.5.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,291] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/angus-activation-2.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,317] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/angus-activation-2.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,317] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jandex-3.1.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,337] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jandex-3.1.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,338] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-c3p0-6.4.8.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,371] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-c3p0-6.4.8.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,372] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mysql-connector-j-9.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,395] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mysql-connector-j-9.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,403] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/error_prone_annotations-2.10.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,421] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/error_prone_annotations-2.10.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,421] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.activation-api-2.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,439] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.activation-api-2.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,440] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/byte-buddy-1.14.11.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,458] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/byte-buddy-1.14.11.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,459] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/istack-commons-runtime-4.1.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,472] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/istack-commons-runtime-4.1.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,473] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mssql-jdbc-12.4.2.jre8.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,496] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mssql-jdbc-12.4.2.jre8.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,578] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mchange-commons-java-0.2.19.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,596] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mchange-commons-java-0.2.19.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,597] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/caffeine-2.9.3.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,622] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/caffeine-2.9.3.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,622] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jaxb-runtime-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,630] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-runtime-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,630] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jboss-logging-3.5.0.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,638] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jboss-logging-3.5.0.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,639] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.persistence-api-3.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,646] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.persistence-api-3.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,647] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.xml.bind-api-4.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,655] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.xml.bind-api-4.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,655] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.inject-api-2.0.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,664] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.inject-api-2.0.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,664] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mariadb-java-client-3.2.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,677] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mariadb-java-client-3.2.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,680] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jna-platform-5.12.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,689] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jna-platform-5.12.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,690] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/antlr4-runtime-4.10.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,697] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/antlr4-runtime-4.10.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,697] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jcl-over-slf4j-1.7.36.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,705] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jcl-over-slf4j-1.7.36.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,705] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-commons-annotations-6.0.6.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,713] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-commons-annotations-6.0.6.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,713] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/postgresql-42.6.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,721] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/postgresql-42.6.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,724] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.transaction-api-2.0.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,733] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.transaction-api-2.0.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,733] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-sink-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,753] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-sink-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,754] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-api-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,761] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-api-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,762] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/classmate-1.5.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,769] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/classmate-1.5.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,769] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-connector-jdbc-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,783] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-connector-jdbc-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,783] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,792] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 02:36:04,793] ERROR Failed to discover Converter in /opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:139)
java.util.ServiceConfigurationError: org.apache.kafka.connect.storage.Converter: Provider io.debezium.converters.CloudEventsConverter could not be instantiated
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:586)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:813)
	at java.base/java.util.ServiceLoader$ProviderImpl.get(ServiceLoader.java:729)
	at java.base/java.util.ServiceLoader$3.next(ServiceLoader.java:1403)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:177)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:61)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:84)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.util.ServiceConfigurationError: io.debezium.converters.spi.CloudEventsProvider: io.debezium.connector.mongodb.converters.MongoDbCloudEventsProvider not a subtype
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:593)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1244)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)
	at io.debezium.converters.CloudEventsConverter.<clinit>(CloudEventsConverter.java:135)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:789)
	... 13 more
[2024-12-17 02:36:04,837] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,837] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jna-5.12.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,845] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jna-5.12.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,845] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-core-6.4.8.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,874] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-core-6.4.8.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,882] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:04,908] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:04,909] INFO Scanning plugins with ServiceLoaderScanner took 1959 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:71)
[2024-12-17 02:36:04,912] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:05,843] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:05,848] INFO Loading plugin from: /opt/kafka/plugins/hibernate-core-6.4.1.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:07,405] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/hibernate-core-6.4.1.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:07,407] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:10,981] ERROR Failed to discover Converter in /opt/kafka/plugins/debezium-connector-jdbc: Unable to instantiate CloudEventsConverter: Plugin class has a dependency which is missing or invalid (org.apache.kafka.connect.runtime.isolation.ReflectionScanner:139)
java.lang.NoClassDefFoundError: Could not initialize class io.debezium.converters.CloudEventsConverter
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.versionFor(ReflectionScanner.java:74)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.getPluginDesc(ReflectionScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.scanPlugins(ReflectionScanner.java:90)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:92)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.lang.ExceptionInInitializerError: Exception java.util.ServiceConfigurationError: io.debezium.converters.spi.CloudEventsProvider: io.debezium.connector.mongodb.converters.MongoDbCloudEventsProvider not a subtype [in thread "main"]
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:593)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1244)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)
	at io.debezium.converters.CloudEventsConverter.<clinit>(CloudEventsConverter.java:135)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:789)
	at java.base/java.util.ServiceLoader$ProviderImpl.get(ServiceLoader.java:729)
	at java.base/java.util.ServiceLoader$3.next(ServiceLoader.java:1403)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:177)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:61)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:84)
	... 5 more
[2024-12-17 02:36:10,999] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:11,023] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-sync-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:11,058] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-sync-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:11,060] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:11,122] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:11,123] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/bson-record-codec-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:11,127] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/bson-record-codec-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:11,128] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/bson-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:11,197] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/bson-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:11,198] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-core-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:11,390] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-core-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:11,391] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-sink-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:11,398] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-sink-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:11,398] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-api-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:11,407] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-api-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:11,408] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:11,557] ERROR Failed to discover Converter in /opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar: Unable to instantiate CloudEventsConverter: Plugin class has a dependency which is missing or invalid (org.apache.kafka.connect.runtime.isolation.ReflectionScanner:139)
java.lang.NoClassDefFoundError: Could not initialize class io.debezium.converters.CloudEventsConverter
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.versionFor(ReflectionScanner.java:74)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.getPluginDesc(ReflectionScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.scanPlugins(ReflectionScanner.java:90)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:92)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.lang.ExceptionInInitializerError: Exception java.util.ServiceConfigurationError: io.debezium.converters.spi.CloudEventsProvider: io.debezium.connector.mongodb.converters.MongoDbCloudEventsProvider not a subtype [in thread "main"]
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:593)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1244)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)
	at io.debezium.converters.CloudEventsConverter.<clinit>(CloudEventsConverter.java:135)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:789)
	at java.base/java.util.ServiceLoader$ProviderImpl.get(ServiceLoader.java:729)
	at java.base/java.util.ServiceLoader$3.next(ServiceLoader.java:1403)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:177)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:61)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:84)
	... 5 more
[2024-12-17 02:36:11,572] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:11,572] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/waffle-jna-3.2.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:11,583] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/waffle-jna-3.2.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:11,584] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jaxb-core-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:11,599] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-core-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:11,600] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/txw2-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:11,610] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/txw2-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:11,611] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/ojdbc11-21.15.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:11,982] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/ojdbc11-21.15.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:11,983] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/c3p0-0.9.5.5.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,022] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/c3p0-0.9.5.5.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,023] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/angus-activation-2.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,027] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/angus-activation-2.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,028] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jandex-3.1.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,052] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jandex-3.1.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,052] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-c3p0-6.4.8.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,057] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-c3p0-6.4.8.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,057] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mysql-connector-j-9.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,207] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mysql-connector-j-9.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,208] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/error_prone_annotations-2.10.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,211] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/error_prone_annotations-2.10.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,212] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.activation-api-2.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,218] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.activation-api-2.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,219] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/byte-buddy-1.14.11.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,488] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/byte-buddy-1.14.11.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,489] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/istack-commons-runtime-4.1.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,494] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/istack-commons-runtime-4.1.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,494] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mssql-jdbc-12.4.2.jre8.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,603] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mssql-jdbc-12.4.2.jre8.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,615] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mchange-commons-java-0.2.19.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,663] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mchange-commons-java-0.2.19.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,664] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/caffeine-2.9.3.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,716] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/caffeine-2.9.3.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,716] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jaxb-runtime-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,767] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-runtime-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,768] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jboss-logging-3.5.0.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,774] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jboss-logging-3.5.0.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,774] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.persistence-api-3.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,785] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.persistence-api-3.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,786] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.xml.bind-api-4.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,796] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.xml.bind-api-4.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,796] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.inject-api-2.0.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,801] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.inject-api-2.0.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,802] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mariadb-java-client-3.2.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,836] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mariadb-java-client-3.2.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,838] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jna-platform-5.12.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,922] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jna-platform-5.12.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,922] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/antlr4-runtime-4.10.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,948] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/antlr4-runtime-4.10.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,949] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jcl-over-slf4j-1.7.36.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,953] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jcl-over-slf4j-1.7.36.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,954] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-commons-annotations-6.0.6.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:12,964] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-commons-annotations-6.0.6.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:12,964] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/postgresql-42.6.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:13,039] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/postgresql-42.6.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:13,041] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.transaction-api-2.0.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:13,044] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.transaction-api-2.0.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:13,044] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-sink-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:13,049] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-sink-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:13,050] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-api-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:13,054] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-api-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:13,054] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/classmate-1.5.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:13,061] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/classmate-1.5.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:13,066] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-connector-jdbc-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:13,088] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-connector-jdbc-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:13,089] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:13,173] ERROR Failed to discover Converter in /opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar: Unable to instantiate CloudEventsConverter: Plugin class has a dependency which is missing or invalid (org.apache.kafka.connect.runtime.isolation.ReflectionScanner:139)
java.lang.NoClassDefFoundError: Could not initialize class io.debezium.converters.CloudEventsConverter
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.versionFor(ReflectionScanner.java:74)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.getPluginDesc(ReflectionScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.scanPlugins(ReflectionScanner.java:90)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:92)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.lang.ExceptionInInitializerError: Exception java.util.ServiceConfigurationError: io.debezium.converters.spi.CloudEventsProvider: io.debezium.connector.mongodb.converters.MongoDbCloudEventsProvider not a subtype [in thread "main"]
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:593)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1244)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)
	at io.debezium.converters.CloudEventsConverter.<clinit>(CloudEventsConverter.java:135)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:789)
	at java.base/java.util.ServiceLoader$ProviderImpl.get(ServiceLoader.java:729)
	at java.base/java.util.ServiceLoader$3.next(ServiceLoader.java:1403)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:177)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:61)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:84)
	... 5 more
[2024-12-17 02:36:13,181] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:13,182] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jna-5.12.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:13,196] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jna-5.12.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:13,196] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-core-6.4.8.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:13,866] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-core-6.4.8.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:13,867] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:17,639] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:17,640] INFO Scanning plugins with ReflectionScanner took 12728 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:71)
[2024-12-17 02:36:17,652] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/opt/kafka/plugins/debezium-connector-mongodb/	io.debezium.connector.mongodb.MongoDbSinkConnector	sink	3.0.4.Final
file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar	io.debezium.connector.mongodb.MongoDbSinkConnector	sink	3.0.4.Final
classpath	io.debezium.connector.mongodb.MongoDbSinkConnector	sink	3.0.4.Final
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:123)
[2024-12-17 02:36:17,655] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,655] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,656] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,656] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,657] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,657] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,657] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,658] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,658] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,658] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,659] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,659] INFO Added plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,659] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,660] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,660] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,660] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,661] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,661] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,661] INFO Added plugin 'io.debezium.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,662] INFO Added plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,662] INFO Added plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,662] INFO Added plugin 'io.debezium.connector.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,663] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,663] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,663] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,664] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,664] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,664] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,665] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,665] INFO Added plugin 'io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,665] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,666] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,666] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,666] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,667] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,667] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,668] INFO Added plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,668] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,668] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,669] INFO Added plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,669] INFO Added plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,669] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,670] INFO Added plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,670] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,670] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,671] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,671] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,671] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,672] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,672] INFO Added plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,672] INFO Added plugin 'io.debezium.connector.jdbc.transforms.ConvertCloudEventToSaveableForm' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,673] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,673] INFO Added plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,673] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,674] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,674] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,674] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,675] INFO Added plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,675] INFO Added plugin 'io.debezium.connector.mongodb.transforms.ExtractNewDocumentState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,676] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,676] INFO Added plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,676] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,676] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,677] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,677] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,677] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,678] INFO Added plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,678] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,678] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:17,682] INFO Added alias 'ExtractNewDocumentState' to plugin 'io.debezium.connector.mongodb.transforms.ExtractNewDocumentState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,683] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,683] INFO Added alias 'CloudEventsConverter' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,683] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,684] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,684] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,684] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,685] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,685] INFO Added alias 'HeaderToValue' to plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,685] INFO Added alias 'PartitionRouting' to plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,686] INFO Added alias 'MongoDbSink' to plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,686] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,686] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,687] INFO Added alias 'MongoDbConnector' to plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,687] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,687] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,688] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,688] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,688] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,689] INFO Added alias 'ExtractSchemaToNewRecord' to plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,689] INFO Added alias 'BinaryData' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,689] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,690] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,690] INFO Added alias 'CloudEvents' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,690] INFO Added alias 'TimezoneConverter' to plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,691] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,691] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,691] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,691] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,692] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,692] INFO Added alias 'DebeziumMongoDb' to plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,692] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,693] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,693] INFO Added alias 'DebeziumMongoDbConnectRestExtension' to plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,693] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,694] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,694] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,694] INFO Added alias 'ExtractChangedRecordState' to plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,695] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,695] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,695] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,696] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,696] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,696] INFO Added alias 'JdbcSinkConnector' to plugin 'io.debezium.connector.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,697] INFO Added alias 'JdbcSink' to plugin 'io.debezium.connector.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,697] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,697] INFO Added alias 'MongoDbSinkConnector' to plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,697] INFO Added alias 'MongoDb' to plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,698] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,698] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,698] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,699] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,699] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,699] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,700] INFO Added alias 'SchemaChangeEventFilter' to plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,700] INFO Added alias 'ConvertCloudEventToSaveableForm' to plugin 'io.debezium.connector.jdbc.transforms.ConvertCloudEventToSaveableForm' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,700] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,701] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,701] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,701] INFO Added alias 'ActivateTracingSpan' to plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,702] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,702] INFO Added alias 'BinaryDataConverter' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,702] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,703] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,703] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,703] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,704] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,704] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,704] INFO Added alias 'MongoEventRouter' to plugin 'io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,705] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,705] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:17,750] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = mongo-source-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [HTTP://0.0.0.0:8083]
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [/opt/kafka/plugins, /opt/kafka/plugins/debezium-connector-mongodb, /opt/kafka/plugins/debezium-connector-jdbc]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = 172.30.2.147
	rest.advertised.listener = null
	rest.advertised.port = 8083
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:371)
[2024-12-17 02:36:17,759] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:281)
[2024-12-17 02:36:17,773] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:371)
[2024-12-17 02:36:17,859] INFO These configurations '[config.storage.topic, listeners, rest.advertised.host.name, status.storage.topic, group.id, rest.advertised.port, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2024-12-17 02:36:17,860] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:17,860] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:17,860] INFO Kafka startTimeMs: 1734377777859 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:18,297] INFO Kafka cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.connect.runtime.WorkerConfig:298)
[2024-12-17 02:36:18,298] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:36:18,304] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:36:18,304] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:36:18,305] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:36:18,311] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [HTTP://0.0.0.0:8083]
	response.http.headers.config = 
	rest.advertised.host.name = 172.30.2.147
	rest.advertised.listener = null
	rest.advertised.port = 8083
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:371)
[2024-12-17 02:36:18,322] INFO Logging initialized @16511ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2024-12-17 02:36:18,364] INFO Added connector for HTTP://0.0.0.0:8083 (org.apache.kafka.connect.runtime.rest.RestServer:125)
[2024-12-17 02:36:18,365] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:196)
[2024-12-17 02:36:18,387] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 17.0.13+11-Ubuntu-2ubuntu122.04 (org.eclipse.jetty.server.Server:375)
[2024-12-17 02:36:18,413] INFO Started http_0.0.0.08083@6676b867{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2024-12-17 02:36:18,413] INFO Started @16602ms (org.eclipse.jetty.server.Server:415)
[2024-12-17 02:36:18,431] INFO Advertised URI: http://172.30.2.147:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2024-12-17 02:36:18,432] INFO REST server listening at http://0.0.0.0:8083/, advertising URL http://172.30.2.147:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:216)
[2024-12-17 02:36:18,432] INFO Advertised URI: http://172.30.2.147:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2024-12-17 02:36:18,432] INFO REST admin endpoints at http://172.30.2.147:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2024-12-17 02:36:18,432] INFO Advertised URI: http://172.30.2.147:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2024-12-17 02:36:18,433] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:45)
[2024-12-17 02:36:18,438] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:36:18,454] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:18,454] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:18,455] INFO Kafka startTimeMs: 1734377778454 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:18,462] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:36:18,463] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:36:18,480] INFO Advertised URI: http://172.30.2.147:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2024-12-17 02:36:18,517] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:18,518] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:18,518] INFO Kafka startTimeMs: 1734377778517 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:18,522] INFO Kafka Connect worker initialization took 15673ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2024-12-17 02:36:18,522] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:67)
[2024-12-17 02:36:18,525] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2024-12-17 02:36:18,535] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:375)
[2024-12-17 02:36:18,538] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:233)
[2024-12-17 02:36:18,540] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:232)
[2024-12-17 02:36:18,540] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:254)
[2024-12-17 02:36:18,542] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = mongo-source-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:371)
[2024-12-17 02:36:18,563] INFO These configurations '[config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, group.id, rest.advertised.port, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2024-12-17 02:36:18,567] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:18,567] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:18,567] INFO Kafka startTimeMs: 1734377778567 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:18,605] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:238)
[2024-12-17 02:36:18,621] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = mongo-source-cluster-offsets
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-17 02:36:18,671] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:36:18,700] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2024-12-17 02:36:18,701] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2024-12-17 02:36:18,702] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2024-12-17 02:36:18,719] INFO These configurations '[group.id, rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-17 02:36:18,720] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:18,720] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:18,720] INFO Kafka startTimeMs: 1734377778720 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:18,733] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = mongo-source-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mongo-source-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2024-12-17 02:36:18,761] INFO [Producer clientId=mongo-source-cluster-offsets] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:36:18,767] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:36:18,820] INFO These configurations '[rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2024-12-17 02:36:18,821] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:18,821] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:18,822] INFO Kafka startTimeMs: 1734377778821 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:18,848] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:36:18,864] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:579)
[2024-12-17 02:36:18,869] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,872] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,872] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,872] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,872] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,873] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,873] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,873] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,873] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,874] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,874] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,875] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,875] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,876] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,876] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,876] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,877] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,877] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,877] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,878] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,879] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,879] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,879] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,881] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,881] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:18,960] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,961] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,961] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,961] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,961] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,962] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,962] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,962] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,962] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,963] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,969] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,970] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,970] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,970] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,970] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,970] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,971] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,971] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,971] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,971] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,971] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,972] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,972] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,972] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:18,972] INFO [Consumer clientId=mongo-source-cluster-offsets, groupId=mongo-source-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:19,126] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:311)
[2024-12-17 02:36:19,128] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:313)
[2024-12-17 02:36:19,128] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:249)
[2024-12-17 02:36:19,130] INFO Worker started (org.apache.kafka.connect.runtime.Worker:243)
[2024-12-17 02:36:19,130] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:254)
[2024-12-17 02:36:19,142] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = mongo-source-cluster-statuses
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-17 02:36:19,152] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:36:19,171] INFO These configurations '[group.id, rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-17 02:36:19,174] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:19,174] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:19,174] INFO Kafka startTimeMs: 1734377779173 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:19,175] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = mongo-source-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mongo-source-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2024-12-17 02:36:19,185] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:36:19,197] INFO [Producer clientId=mongo-source-cluster-statuses] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:36:19,205] INFO These configurations '[rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2024-12-17 02:36:19,205] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:19,206] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:19,206] INFO Kafka startTimeMs: 1734377779205 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:19,217] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:36:19,221] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:579)
[2024-12-17 02:36:19,221] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:19,222] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:19,222] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:19,223] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:19,231] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:19,245] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:19,245] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:19,246] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:19,246] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:19,246] INFO [Consumer clientId=mongo-source-cluster-statuses, groupId=mongo-source-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:19,487] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:311)
[2024-12-17 02:36:19,488] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:313)
[2024-12-17 02:36:19,494] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:378)
[2024-12-17 02:36:19,494] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:254)
[2024-12-17 02:36:19,514] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = mongo-source-cluster-configs
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-17 02:36:19,522] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:36:19,533] INFO These configurations '[group.id, rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-17 02:36:19,534] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:19,534] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:19,534] INFO Kafka startTimeMs: 1734377779534 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:19,535] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = mongo-source-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mongo-source-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2024-12-17 02:36:19,551] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:36:19,559] INFO [Producer clientId=mongo-source-cluster-configs] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:36:19,561] INFO These configurations '[rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2024-12-17 02:36:19,563] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:19,564] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:19,564] INFO Kafka startTimeMs: 1734377779563 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:19,573] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:36:19,576] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:579)
[2024-12-17 02:36:19,579] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:19,618] INFO [Consumer clientId=mongo-source-cluster-configs, groupId=mongo-source-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:19,632] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,643] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,644] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,645] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,645] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,646] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,647] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,648] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,648] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,649] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,649] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,650] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,650] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,651] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,654] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,655] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,655] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,656] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,656] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,657] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,659] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,659] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,660] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,661] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,661] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,662] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,662] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,663] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,663] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,664] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,664] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,665] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,665] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,666] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,667] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,667] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,668] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,668] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,669] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,669] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,670] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,670] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,671] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,671] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,672] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,673] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,673] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,674] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,674] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,675] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,675] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,676] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,676] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,677] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,678] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,678] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,679] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,679] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,680] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,680] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,681] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,682] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,682] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,683] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,683] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,684] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,684] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,687] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,688] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,688] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,689] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,690] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,690] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,691] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,691] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,692] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,692] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,692] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,693] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,694] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,694] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,697] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,697] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,698] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,698] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,699] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,699] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,704] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,704] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,705] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,705] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,706] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,706] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,707] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,707] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,708] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,708] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,715] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,716] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,716] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,717] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,717] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,718] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,718] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,719] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,719] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,720] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,720] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,721] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,721] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,722] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,722] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,723] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,723] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,724] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:19,731] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:311)
[2024-12-17 02:36:19,731] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:313)
[2024-12-17 02:36:19,732] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:402)
[2024-12-17 02:36:19,740] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:36:19,741] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 02:36:19,759] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:36:19,759] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:36:19,765] INFO Started o.e.j.s.ServletContextHandler@6ca91165{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2024-12-17 02:36:19,765] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:303)
[2024-12-17 02:36:19,765] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:77)
[2024-12-17 02:36:19,768] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:36:19,771] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=529, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:36:19,792] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=529, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:36:19,792] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 529 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', leaderUrl='http://172.30.2.147:8083/', offset=834, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:36:19,794] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:387)
[2024-12-17 02:36:19,794] WARN [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1811)
[2024-12-17 02:36:19,794] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Current config state offset -1 is behind group assignment 834, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1884)
[2024-12-17 02:36:19,798] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 834 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1911)
[2024-12-17 02:36:19,799] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 834 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:36:19,800] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mongodb-source-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 02:36:19,807] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 02:36:19,832] INFO [mongodb-source-connector|worker] Creating connector mongodb-source-connector of type io.debezium.connector.mongodb.MongoDbConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 02:36:19,835] INFO [mongodb-source-connector|task-0] Creating task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 02:36:19,837] INFO [mongodb-source-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 02:36:19,840] INFO [mongodb-source-connector|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-17 02:36:19,848] INFO [mongodb-source-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:36:19,859] INFO [mongodb-source-connector|worker] Instantiated connector mongodb-source-connector with version 3.0.4.Final of type class io.debezium.connector.mongodb.MongoDbConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 02:36:19,860] INFO [mongodb-source-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:36:19,868] INFO [mongodb-source-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.MongoDbConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:371)
[2024-12-17 02:36:19,872] INFO [mongodb-source-connector|task-0] Instantiated task mongodb-source-connector-0 with version 3.0.4.Final of type io.debezium.connector.mongodb.MongoDbConnectorTask (org.apache.kafka.connect.runtime.Worker:665)
[2024-12-17 02:36:19,873] INFO [mongodb-source-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:36:19,874] INFO [mongodb-source-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:36:19,875] INFO [mongodb-source-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-source-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:680)
[2024-12-17 02:36:19,875] INFO [mongodb-source-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-source-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:686)
[2024-12-17 02:36:19,875] INFO [mongodb-source-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mongodb-source-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:691)
[2024-12-17 02:36:19,883] INFO [mongodb-source-connector|worker] Finished creating connector mongodb-source-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 02:36:19,884] WARN [mongodb-source-connector|task-0] The deleted record handling configs "drop.tombstones" and "delete.handling.mode" have been deprecated, please use "delete.tombstone.handling.mode" instead. (io.debezium.transforms.AbstractExtractNewRecordState:110)
[2024-12-17 02:36:19,898] WARN [mongodb-source-connector|task-0] Configuration key whitelist is deprecated and may be removed in the future.  Please update your configuration to use include instead. (org.apache.kafka.common.utils.ConfigUtils:114)
[2024-12-17 02:36:19,899] INFO [mongodb-source-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{io.debezium.connector.mongodb.transforms.ExtractNewDocumentState, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.TimestampConverter$Value} (org.apache.kafka.connect.runtime.Worker:1795)
[2024-12-17 02:36:19,900] INFO [mongodb-source-connector|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-17 02:36:19,904] INFO [mongodb-source-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:36:19,909] INFO [mongodb-source-connector|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.147:9092, 172.30.2.207:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-mongodb-source-connector-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-17 02:36:19,915] INFO [mongodb-source-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:36:19,923] INFO [mongodb-source-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-17 02:36:19,923] INFO [mongodb-source-connector|task-0] Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:19,924] INFO [mongodb-source-connector|task-0] Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:19,924] INFO [mongodb-source-connector|task-0] Kafka startTimeMs: 1734377779923 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:19,936] INFO [mongodb-source-connector|worker] Successfully started MongoDB connector (io.debezium.connector.mongodb.MongoDbConnector:67)
[2024-12-17 02:36:19,939] INFO [mongodb-source-connector|task-0] [Producer clientId=connector-producer-mongodb-source-connector-0] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:36:19,956] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:36:19,959] INFO [mongodb-source-connector|task-0] Starting MongoDbConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:245)
[2024-12-17 02:36:19,961] INFO [mongodb-source-connector|task-0]    connector.class = io.debezium.connector.mongodb.MongoDbConnector (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,961] INFO [mongodb-source-connector|task-0]    collection.include.list = test.customers (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,961] INFO [mongodb-source-connector|task-0]    transforms.unwrap.delete.handling.mode = drop (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,962] INFO [mongodb-source-connector|task-0]    transforms.unwrap.array.encoding = array (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,962] INFO [mongodb-source-connector|task-0]    mongodb.connection.string = ******** (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,962] INFO [mongodb-source-connector|task-0]    tasks.max = 1 (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,962] INFO [mongodb-source-connector|task-0]    transforms = unwrap,extractNew,convertDate (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,963] INFO [mongodb-source-connector|task-0]    transforms.unwrap.add.source.fields = db,collection (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,963] INFO [mongodb-source-connector|task-0]    topic.prefix = fullfillment (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,963] INFO [mongodb-source-connector|task-0]    transforms.convertDate.format = yyyy-MM-dd HH:mm:ss (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,964] INFO [mongodb-source-connector|task-0]    mongodb.server.selection.timeout.ms = 10000 (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,964] INFO [mongodb-source-connector|task-0]    transforms.unwrap.drop.tombstones = false (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,964] INFO [mongodb-source-connector|task-0]    transforms.unwrap.type = io.debezium.connector.mongodb.transforms.ExtractNewDocumentState (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,964] INFO [mongodb-source-connector|task-0]    value.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,964] INFO [mongodb-source-connector|task-0]    mongodb.connect.timeout.ms = 10000 (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,965] INFO [mongodb-source-connector|task-0]    mongodb.auth.source = admin (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,965] INFO [mongodb-source-connector|task-0]    key.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,965] INFO [mongodb-source-connector|task-0]    transforms.convertDate.type = org.apache.kafka.connect.transforms.TimestampConverter$Value (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,965] INFO [mongodb-source-connector|task-0]    transforms.extractNew.type = org.apache.kafka.connect.transforms.ReplaceField$Value (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,966] INFO [mongodb-source-connector|task-0]    key.converter.schemas.enable = true (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,966] INFO [mongodb-source-connector|task-0]    transforms.extractNew.whitelist = _id,name,email,age,createdAt (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,966] INFO [mongodb-source-connector|task-0]    task.class = io.debezium.connector.mongodb.MongoDbConnectorTask (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,966] INFO [mongodb-source-connector|task-0]    transforms.convertDate.field = createdAt (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,967] INFO [mongodb-source-connector|task-0]    value.converter.schemas.enable = true (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,967] INFO [mongodb-source-connector|task-0]    name = mongodb-source-connector (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,967] INFO [mongodb-source-connector|task-0]    transforms.convertDate.target.type = string (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,967] INFO [mongodb-source-connector|task-0]    database.include.list = test (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,968] INFO [mongodb-source-connector|task-0]    snapshot.mode = initial (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,968] INFO [mongodb-source-connector|task-0]    transforms.unwrap.operation.header = true (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:19,973] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:19,978] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:19,978] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:19,987] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:19,994] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:19,998] INFO [mongodb-source-connector|task-0] Loading the custom topic naming strategy plugin: io.debezium.schema.DefaultTopicNamingStrategy (io.debezium.config.CommonConnectorConfig:1401)
[2024-12-17 02:36:19,999] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:20,000] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:20,001] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:20,005] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-17 02:36:20,011] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:36:20,348] INFO [mongodb-source-connector|task-0] Found previous partition offset MongoDbPartition [sourcePartition={server_id=fullfillment}]: {sec=1734365014, ord=1, resume_token=zQAAAAJfZGF0YQC9AAAAODI2NzYwNEY1NjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNEY1NjQ5NkY2QjQ1OTk5NjQwMzcwMDAwMDQAAA==} (io.debezium.connector.common.BaseSourceTask:527)
[2024-12-17 02:36:20,371] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = fullfillment named = SignalProcessor (io.debezium.util.Threads:270)
[2024-12-17 02:36:20,390] WARN [mongodb-source-connector|task-0] Found a not connector specific implementation io.debezium.snapshot.lock.NoLockingSupport for lock mode no_locking_support (io.debezium.snapshot.SnapshotLockProvider:82)
[2024-12-17 02:36:20,410] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:20,411] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:20,411] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:20,413] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:20,414] INFO [mongodb-source-connector|task-0] Found existing offset for at {sec=1734365014, ord=1, resume_token=zQAAAAJfZGF0YQC9AAAAODI2NzYwNEY1NjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNEY1NjQ5NkY2QjQ1OTk5NjQwMzcwMDAwMDQAAA==} (io.debezium.connector.mongodb.connection.MongoDbConnection:202)
[2024-12-17 02:36:20,454] INFO [mongodb-source-connector|task-0] Adding discovered server 172.30.2.147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:20,508] INFO [mongodb-source-connector|task-0] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.11.0"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-125-generic"}, "platform": "Java/Ubuntu/17.0.13+11-Ubuntu-2ubuntu122.04"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@4e266013, com.mongodb.Jep395RecordCodecProvider@11645aca, com.mongodb.KotlinCodecProvider@780bb716]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[172.30.2.147:27017], srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='rs0', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='10000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=javax.net.ssl.SSLContext@6e3bd161}, applicationName='null', compressorList=[], uuidRepresentation=STANDARD, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null} (org.mongodb.driver.client:71)
[2024-12-17 02:36:20,591] INFO [mongodb-source-connector|task-0] Effective change stream pipeline: [{"$replaceRoot": {"newRoot": {"event": "$$ROOT", "namespace": {"$concat": ["$ns.db", ".", "$ns.coll"]}}}}, {"$match": {"$and": [{"$and": [{"event.ns.db": {"$regularExpression": {"pattern": "test", "options": "i"}}}, {"namespace": {"$regularExpression": {"pattern": "test.customers", "options": "i"}}}]}, {"event.operationType": {"$in": ["insert", "update", "replace", "delete"]}}]}}, {"$replaceRoot": {"newRoot": "$event"}}] (io.debezium.connector.mongodb.ChangeStreamPipelineFactory:56)
[2024-12-17 02:36:20,593] INFO [mongodb-source-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=172.30.2.147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=26109733, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Tue Dec 17 02:36:19 ICT 2024, lastUpdateTimeNanos=84597313540818} (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:20,608] INFO [mongodb-source-connector|task-0] Adding discovered server linux-ip-147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:20,622] INFO [mongodb-source-connector|task-0] Server 172.30.2.147:27017 is no longer a member of the replica set.  Removing from client view of cluster. (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:20,627] INFO [mongodb-source-connector|task-0] Discovered replica set primary 172.30.2.147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:20,634] INFO [mongodb-source-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=linux-ip-147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=11698903, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Tue Dec 17 02:36:19 ICT 2024, lastUpdateTimeNanos=84597394407681} (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:20,636] INFO [mongodb-source-connector|task-0] Discovered replica set primary linux-ip-147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:20,802] INFO [mongodb-source-connector|task-0] Valid resume token present, so no snapshot will be performed' (io.debezium.connector.mongodb.connection.MongoDbConnection:220)
[2024-12-17 02:36:20,825] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = fullfillment named = change-event-source-coordinator (io.debezium.util.Threads:270)
[2024-12-17 02:36:20,825] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = fullfillment named = blocking-snapshot (io.debezium.util.Threads:270)
[2024-12-17 02:36:20,827] INFO [mongodb-source-connector|task-0] Creating thread debezium-mongodbconnector-fullfillment-change-event-source-coordinator (io.debezium.util.Threads:287)
[2024-12-17 02:36:20,827] INFO [mongodb-source-connector|task-0] WorkerSourceTask{id=mongodb-source-connector-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:280)
[2024-12-17 02:36:20,837] INFO [mongodb-source-connector|task-0] Metrics registered (io.debezium.pipeline.ChangeEventSourceCoordinator:137)
[2024-12-17 02:36:20,837] INFO [mongodb-source-connector|task-0] Context created (io.debezium.pipeline.ChangeEventSourceCoordinator:140)
[2024-12-17 02:36:20,840] INFO [mongodb-source-connector|task-0] A previous offset indicating a completed snapshot has been found. (io.debezium.connector.mongodb.MongoDbSnapshotChangeEventSource:144)
[2024-12-17 02:36:20,841] INFO [mongodb-source-connector|task-0] According to the connector configuration, no snapshot will occur. (io.debezium.connector.mongodb.MongoDbSnapshotChangeEventSource:151)
[2024-12-17 02:36:20,850] INFO [mongodb-source-connector|task-0] Snapshot ended with SnapshotResult [status=SKIPPED, offset=MongoDbOffsetContext [sourceInfo=SourceInfo [initialSync=false, collectionId=null, position=Position [ts=Timestamp{value=7449041014456582145, seconds=1734365014, inc=1}, changeStreamSessionTxnId=null, resumeToken=zQAAAAJfZGF0YQC9AAAAODI2NzYwNEY1NjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNEY1NjQ5NkY2QjQ1OTk5NjQwMzcwMDAwMDQAAA==]]]] (io.debezium.pipeline.ChangeEventSourceCoordinator:298)
[2024-12-17 02:36:20,852] INFO [mongodb-source-connector|task-0] Connected metrics set to 'true' (io.debezium.pipeline.ChangeEventSourceCoordinator:477)
[2024-12-17 02:36:20,854] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = mongodb named = incremental-snapshot (io.debezium.util.Threads:270)
[2024-12-17 02:36:20,855] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:20,856] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:20,857] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:20,858] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:20,859] INFO [mongodb-source-connector|task-0] No incremental snapshot in progress, no action needed on start (io.debezium.connector.mongodb.snapshot.MongoDbIncrementalSnapshotChangeEventSource:262)
[2024-12-17 02:36:20,868] INFO [mongodb-source-connector|task-0] SignalProcessor started. Scheduling it every 5000ms (io.debezium.pipeline.signal.SignalProcessor:105)
[2024-12-17 02:36:20,869] INFO [mongodb-source-connector|task-0] Creating thread debezium-mongodbconnector-fullfillment-SignalProcessor (io.debezium.util.Threads:287)
[2024-12-17 02:36:20,870] INFO [mongodb-source-connector|task-0] Starting streaming (io.debezium.pipeline.ChangeEventSourceCoordinator:323)
[2024-12-17 02:36:20,871] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:20,871] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:20,872] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:20,874] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:20,875] INFO [mongodb-source-connector|task-0] Adding discovered server 172.30.2.147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:20,880] INFO [mongodb-source-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=172.30.2.147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=1582964, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Tue Dec 17 02:36:19 ICT 2024, lastUpdateTimeNanos=84597640602956} (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:20,882] INFO [mongodb-source-connector|task-0] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.11.0"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-125-generic"}, "platform": "Java/Ubuntu/17.0.13+11-Ubuntu-2ubuntu122.04"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@4e266013, com.mongodb.Jep395RecordCodecProvider@11645aca, com.mongodb.KotlinCodecProvider@780bb716]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[172.30.2.147:27017], srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='rs0', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='10000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=javax.net.ssl.SSLContext@44d26e2a}, applicationName='null', compressorList=[], uuidRepresentation=STANDARD, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null} (org.mongodb.driver.client:71)
[2024-12-17 02:36:20,883] INFO [mongodb-source-connector|task-0] Reading change stream (io.debezium.connector.mongodb.MongoDbStreamingChangeEventSource:100)
[2024-12-17 02:36:20,884] INFO [mongodb-source-connector|task-0] Effective change stream pipeline: [{"$replaceRoot": {"newRoot": {"event": "$$ROOT", "namespace": {"$concat": ["$ns.db", ".", "$ns.coll"]}}}}, {"$match": {"$and": [{"$and": [{"event.ns.db": {"$regularExpression": {"pattern": "test", "options": "i"}}}, {"namespace": {"$regularExpression": {"pattern": "test.customers", "options": "i"}}}]}, {"event.operationType": {"$in": ["insert", "update", "replace", "delete"]}}]}}, {"$replaceRoot": {"newRoot": "$event"}}] (io.debezium.connector.mongodb.ChangeStreamPipelineFactory:56)
[2024-12-17 02:36:20,888] INFO [mongodb-source-connector|task-0] Resuming streaming from token 'zQAAAAJfZGF0YQC9AAAAODI2NzYwNEY1NjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNEY1NjQ5NkY2QjQ1OTk5NjQwMzcwMDAwMDQAAA==' (io.debezium.connector.mongodb.MongoDbStreamingChangeEventSource:207)
[2024-12-17 02:36:20,892] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = fullfillment named = replicator-fetcher (io.debezium.util.Threads:270)
[2024-12-17 02:36:20,893] INFO [mongodb-source-connector|task-0] Fetcher submitted for execution: io.debezium.connector.mongodb.events.BufferingChangeStreamCursor$EventFetcher@7fb33e75 @ java.util.concurrent.ThreadPoolExecutor@26b7ee06[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] (io.debezium.connector.mongodb.events.BufferingChangeStreamCursor:367)
[2024-12-17 02:36:20,893] INFO [mongodb-source-connector|task-0] Creating thread debezium-mongodbconnector-fullfillment-replicator-fetcher-0 (io.debezium.util.Threads:287)
[2024-12-17 02:36:20,893] INFO [mongodb-source-connector|task-0] Adding discovered server linux-ip-147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:20,897] INFO [mongodb-source-connector|task-0] Server 172.30.2.147:27017 is no longer a member of the replica set.  Removing from client view of cluster. (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:20,898] INFO [mongodb-source-connector|task-0] Discovered replica set primary 172.30.2.147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:20,900] INFO [mongodb-source-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=linux-ip-147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=3106627, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Tue Dec 17 02:36:19 ICT 2024, lastUpdateTimeNanos=84597660708614} (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:20,903] INFO [mongodb-source-connector|task-0] No server chosen by ReadPreferenceServerSelector{readPreference=primary} from cluster description ClusterDescription{type=REPLICA_SET, connectionMode=MULTIPLE, serverDescriptions=[ServerDescription{address=172.30.2.147:27017, type=UNKNOWN, state=CONNECTING}]}. Waiting for 10000 ms before timing out (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:20,904] INFO [mongodb-source-connector|task-0] Discovered replica set primary linux-ip-147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-17 02:41:43,124] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 02:41:43,131] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:41:43,131] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:41:43,152] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=530, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:41:43,178] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=530, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:41:43,179] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 530 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', leaderUrl='http://172.30.2.147:8083/', offset=835, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:41:43,180] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 835 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:41:43,182] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 02:41:43,183] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 02:41:43,189] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:41:43,194] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted, createdAt]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:41:43,195] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 02:41:43,196] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 02:41:43,197] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:41:43,211] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:41:43,219] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted, createdAt]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:41:43,245] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 02:41:43,289] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 02:41:43,296] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:41:43,297] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:41:43,305] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=531, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:41:43,310] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=531, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:41:43,311] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 531 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', leaderUrl='http://172.30.2.147:8083/', offset=839, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:41:43,313] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 839 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:41:43,314] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 02:41:43,324] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 02:41:43,327] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 02:41:43,333] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted, createdAt]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:41:43,345] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-17 02:41:43,359] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:50:32,909] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:50:32,917] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 02:50:32,961] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:50:32,965] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:50:32,972] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=532, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:50:32,990] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=532, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:50:33,008] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 02:50:33,009] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 02:50:33,016] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-17 02:50:33,017] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-17 02:50:33,019] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 02:50:33,027] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 02:50:33,037] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 02:50:33,038] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 532 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', leaderUrl='http://172.30.2.147:8083/', offset=841, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:50:33,040] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 841 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:50:33,044] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:50:33,045] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:50:33,046] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:50:33,052] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=533, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:50:33,061] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=533, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:50:33,062] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 533 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', leaderUrl='http://172.30.2.147:8083/', offset=841, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:50:33,063] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 841 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:50:33,064] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:50:33,106] INFO 172.30.2.207 - - [16/Dec/2024:19:50:32 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 333 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 02:52:23,626] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 02:52:23,630] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:52:23,630] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:52:23,647] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=534, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:52:23,664] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=534, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:52:23,665] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 534 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', leaderUrl='http://172.30.2.147:8083/', offset=842, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:52:23,666] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 842 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:52:23,668] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 02:52:23,671] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 02:52:23,678] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:52:23,682] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:52:23,685] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 02:52:23,686] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 02:52:23,687] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:52:23,695] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:52:23,698] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:52:23,761] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 02:52:23,762] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:52:23,763] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:52:23,771] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=535, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:52:23,777] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=535, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:52:23,778] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 535 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', leaderUrl='http://172.30.2.147:8083/', offset=845, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:52:23,779] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 845 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:52:23,780] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 02:52:23,782] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 02:52:23,787] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 02:52:23,792] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:52:23,802] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Tasks [] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 02:52:23,806] ERROR [mysql-sink-connector|task-0] Failed to start task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:707)
java.lang.NoClassDefFoundError: org/hibernate/SharedSessionContract
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.apache.kafka.common.utils.Utils.loadClass(Utils.java:435)
	at org.apache.kafka.common.config.ConfigDef.parseType(ConfigDef.java:769)
	at org.apache.kafka.common.config.ConfigDef.parseValue(ConfigDef.java:531)
	at org.apache.kafka.common.config.ConfigDef.parse(ConfigDef.java:524)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:115)
	at org.apache.kafka.common.config.AbstractConfig.<init>(AbstractConfig.java:146)
	at org.apache.kafka.connect.runtime.TaskConfig.<init>(TaskConfig.java:51)
	at org.apache.kafka.connect.runtime.Worker.startTask(Worker.java:662)
	at org.apache.kafka.connect.runtime.Worker.startSinkTask(Worker.java:569)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:2026)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$40(DistributedHerder.java:2076)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.hibernate.SharedSessionContract
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 17 more
[2024-12-17 02:52:23,820] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:52:23,821] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:52:23,821] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:52:23,825] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=536, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:52:23,831] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=536, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:52:23,832] WARN [mysql-sink-connector|task-0] Ignoring stop request for unowned task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1044)
[2024-12-17 02:52:23,834] WARN [mysql-sink-connector|task-0] Ignoring await stop request for non-present task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1070)
[2024-12-17 02:52:23,834] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 02:52:23,835] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 02:52:23,836] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 536 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', leaderUrl='http://172.30.2.147:8083/', offset=846, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:52:23,838] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 846 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:52:23,839] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:52:23,841] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:52:23,842] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:52:23,845] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=537, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:52:23,849] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=537, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:52:23,850] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 537 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', leaderUrl='http://172.30.2.147:8083/', offset=846, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:52:23,852] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 846 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:52:23,852] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:57:24,013] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:57:24,014] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 02:57:24,015] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:57:24,016] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:57:24,025] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=538, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:57:24,029] INFO 172.30.2.207 - - [16/Dec/2024:19:57:23 +0000] "DELETE /connectors/mysql-sink-connector HTTP/1.1" 204 0 "-" "curl/7.81.0" 147 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 02:57:24,037] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=538, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:57:24,038] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 02:57:24,039] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 02:57:24,041] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 02:57:24,044] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 02:57:24,047] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 02:57:24,048] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 538 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', leaderUrl='http://172.30.2.147:8083/', offset=848, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:57:24,050] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 848 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:57:24,052] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:57:24,054] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:57:24,055] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:57:24,060] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully joined group with generation Generation{generationId=539, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:57:24,065] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Successfully synced group in generation Generation{generationId=539, memberId='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:57:24,069] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Joined group at generation 539 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.147:8083-c2da6b81-383f-4fbc-8bb2-55b0f881e4ac', leaderUrl='http://172.30.2.147:8083/', offset=848, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:57:24,070] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Starting connectors and tasks using config offset 848 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:57:24,071] INFO [Worker clientId=connect-172.30.2.147:8083, groupId=mongo-source-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
