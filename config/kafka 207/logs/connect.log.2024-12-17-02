[2024-12-17 02:06:03,299] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:06:03,307] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 02:06:03,309] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:06:03,310] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:06:03,335] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=506, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:06:03,353] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=506, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:06:03,355] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 02:06:03,355] INFO [mysql-sink-connector|task-0] Stopping task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1048)
[2024-12-17 02:06:03,356] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 02:06:03,367] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 02:06:03,370] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 02:06:03,374] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 02:06:03,375] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 506 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', leaderUrl='http://172.30.2.207:8083/', offset=812, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:06:03,377] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 812 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:06:03,378] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:06:03,380] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:06:03,383] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:06:03,394] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=507, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:06:03,400] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=507, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:06:03,402] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 507 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', leaderUrl='http://172.30.2.207:8083/', offset=813, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:06:03,403] WARN [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1811)
[2024-12-17 02:06:03,406] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Current config state offset 812 is behind group assignment 813, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1884)
[2024-12-17 02:06:03,431] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 813 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1911)
[2024-12-17 02:06:03,432] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 813 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:06:03,432] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:07:39,299] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:371)
[2024-12-17 02:07:39,333] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 02:07:39,335] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:07:39,336] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:07:39,345] INFO 172.30.2.207 - - [16/Dec/2024:19:07:39 +0000] "POST /connectors HTTP/1.1" 201 1117 "-" "curl/7.81.0" 77 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 02:07:39,356] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=508, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:07:39,364] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=508, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:07:39,365] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 508 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', leaderUrl='http://172.30.2.207:8083/', offset=814, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:07:39,367] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 814 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:07:39,368] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 02:07:39,370] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 02:07:39,372] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:07:39,381] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:07:39,387] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 02:07:39,396] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 02:07:39,398] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:07:39,402] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:07:39,405] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:07:39,427] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 02:07:39,450] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:07:39,451] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:07:39,455] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=509, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:07:39,460] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=509, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:07:39,461] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 509 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', leaderUrl='http://172.30.2.207:8083/', offset=816, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:07:39,464] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 816 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:07:39,465] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 02:07:39,465] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 02:07:39,467] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 02:07:39,468] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:07:39,469] INFO [mysql-sink-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.jdbc.JdbcSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:371)
[2024-12-17 02:07:39,469] INFO [mysql-sink-connector|task-0] New InternalSinkRecord class found (io.debezium.connector.jdbc.JdbcSinkConnectorTask:74)
[2024-12-17 02:07:39,469] INFO [mysql-sink-connector|task-0] Instantiated task mysql-sink-connector-0 with version 3.0.4.Final of type io.debezium.connector.jdbc.JdbcSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:665)
[2024-12-17 02:07:39,470] INFO [mysql-sink-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:07:39,470] INFO [mysql-sink-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:07:39,470] INFO [mysql-sink-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:680)
[2024-12-17 02:07:39,471] INFO [mysql-sink-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:686)
[2024-12-17 02:07:39,471] INFO [mysql-sink-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-sink-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:691)
[2024-12-17 02:07:39,476] WARN [mysql-sink-connector|task-0] The deleted record handling configs "drop.tombstones" and "delete.handling.mode" have been deprecated, please use "delete.tombstone.handling.mode" instead. (io.debezium.transforms.AbstractExtractNewRecordState:110)
[2024-12-17 02:07:39,477] INFO [mysql-sink-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{io.debezium.connector.mongodb.transforms.ExtractNewDocumentState} (org.apache.kafka.connect.runtime.Worker:1795)
[2024-12-17 02:07:39,478] INFO [mysql-sink-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:07:39,480] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:07:39,481] INFO [mysql-sink-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mysql-sink-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mysql-sink-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2024-12-17 02:07:39,483] INFO [mysql-sink-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:07:39,493] INFO [mysql-sink-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2024-12-17 02:07:39,495] INFO [mysql-sink-connector|task-0] Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:07:39,495] INFO [mysql-sink-connector|task-0] Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:07:39,495] INFO [mysql-sink-connector|task-0] Kafka startTimeMs: 1734376059493 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:07:39,500] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:07:39,501] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Subscribed to topic(s): fullfillment.test.customers (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:481)
[2024-12-17 02:07:39,509] INFO [mysql-sink-connector|task-0] Starting JdbcSinkConnectorConfig with configuration: (io.debezium.connector.jdbc.JdbcSinkConnectorTask:410)
[2024-12-17 02:07:39,510] INFO [mysql-sink-connector|task-0]    connector.class = io.debezium.connector.jdbc.JdbcSinkConnector (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,510] INFO [mysql-sink-connector|task-0]    connection.password = ******** (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,510] INFO [mysql-sink-connector|task-0]    tasks.max = 1 (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,510] INFO [mysql-sink-connector|task-0]    transforms = unwrap (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,510] INFO [mysql-sink-connector|task-0]    collection.name.format = mongodb_customers (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,511] INFO [mysql-sink-connector|task-0]    schema.evolution = basic (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,511] INFO [mysql-sink-connector|task-0]    auto.evolve = false (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,511] INFO [mysql-sink-connector|task-0]    transforms.unwrap.drop.tombstones = false (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,511] INFO [mysql-sink-connector|task-0]    driver.class = com.mysql.cj.jdbc.Driver (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,511] INFO [mysql-sink-connector|task-0]    transforms.unwrap.type = io.debezium.connector.mongodb.transforms.ExtractNewDocumentState (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,512] INFO [mysql-sink-connector|task-0]    value.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,512] INFO [mysql-sink-connector|task-0]    insert.mode = upsert (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,512] INFO [mysql-sink-connector|task-0]    key.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,512] INFO [mysql-sink-connector|task-0]    primary.key.mode = record_key (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,512] INFO [mysql-sink-connector|task-0]    topics = fullfillment.test.customers (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,512] INFO [mysql-sink-connector|task-0]    batch.size = 1000 (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,512] INFO [mysql-sink-connector|task-0]    connection.username = phuc (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,513] INFO [mysql-sink-connector|task-0]    key.converter.schemas.enable = true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,513] INFO [mysql-sink-connector|task-0]    delete.enabled = true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,513] INFO [mysql-sink-connector|task-0]    task.class = io.debezium.connector.jdbc.JdbcSinkConnectorTask (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,513] INFO [mysql-sink-connector|task-0]    name = mysql-sink-connector (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,513] INFO [mysql-sink-connector|task-0]    value.converter.schemas.enable = true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,513] INFO [mysql-sink-connector|task-0]    primary.key.fields = _id (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,513] INFO [mysql-sink-connector|task-0]    auto.create = false (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,513] INFO [mysql-sink-connector|task-0]    connection.url = jdbc:mysql://172.30.2.207:3306/demo?useSSL=false&allowPublicKeyRetrieval=true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,514] INFO [mysql-sink-connector|task-0]    transforms.unwrap.handle.duplicate.fields = skip (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,514] INFO [mysql-sink-connector|task-0]    transforms.unwrap.operation.header = true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:07:39,527] INFO [mysql-sink-connector|task-0] HHH000026: Second-level cache disabled (org.hibernate.cache.internal.RegionFactoryInitiator:50)
[2024-12-17 02:07:39,535] INFO [mysql-sink-connector|task-0] HHH000130: Instantiating explicit connection provider: org.hibernate.c3p0.internal.C3P0ConnectionProvider (org.hibernate.engine.jdbc.connections.internal.ConnectionProviderInitiator:131)
[2024-12-17 02:07:39,536] INFO [mysql-sink-connector|task-0] HHH010002: C3P0 using driver: null at URL: jdbc:mysql://172.30.2.207:3306/demo?useSSL=false&allowPublicKeyRetrieval=true (org.hibernate.orm.connections.pooling.c3p0:124)
[2024-12-17 02:07:39,536] INFO [mysql-sink-connector|task-0] HHH10001001: Connection properties: {password=****, user=phuc} (org.hibernate.orm.connections.pooling.c3p0:125)
[2024-12-17 02:07:39,537] INFO [mysql-sink-connector|task-0] HHH10001003: Autocommit mode: false (org.hibernate.orm.connections.pooling.c3p0:128)
[2024-12-17 02:07:39,537] WARN [mysql-sink-connector|task-0] HHH10001006: No JDBC Driver class was specified by property `jakarta.persistence.jdbc.driver`, `hibernate.driver` or `javax.persistence.jdbc.driver` (org.hibernate.orm.connections.pooling.c3p0:131)
[2024-12-17 02:07:39,592] INFO [mysql-sink-connector|task-0] HHH10001007: JDBC isolation level: <unknown> (org.hibernate.orm.connections.pooling.c3p0:200)
[2024-12-17 02:07:39,596] INFO [mysql-sink-connector|task-0] Initializing c3p0 pool... com.mchange.v2.c3p0.PoolBackedDataSource@2710cd68 [ connectionPoolDataSource -> com.mchange.v2.c3p0.WrapperConnectionPoolDataSource@ac121eb0 [ acquireIncrement -> 32, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, contextClassLoaderSource -> caller, debugUnreturnedConnectionStackTraces -> false, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, forceSynchronousCheckins -> false, identityToken -> z8kfsxb71lu9trp1602o2g|29e03694, idleConnectionTestPeriod -> 0, initialPoolSize -> 5, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 0, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 32, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 5, nestedDataSource -> com.mchange.v2.c3p0.DriverManagerDataSource@95119e66 [ description -> null, driverClass -> null, factoryClassLocation -> null, forceUseNamedDriverClass -> false, identityToken -> z8kfsxb71lu9trp1602o2g|684021fc, jdbcUrl -> jdbc:mysql://172.30.2.207:3306/demo?useSSL=false&allowPublicKeyRetrieval=true, properties -> {password=******, user=******} ], preferredTestQuery -> null, privilegeSpawnedThreads -> false, propertyCycle -> 0, statementCacheNumDeferredCloseThreads -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false; userOverrides: {} ], dataSourceName -> null, extensions -> {}, factoryClassLocation -> null, identityToken -> z8kfsxb71lu9trp1602o2g|786a8d22, numHelperThreads -> 3 ] (com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource:212)
[2024-12-17 02:07:39,715] INFO [mysql-sink-connector|task-0] HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration) (org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator:58)
[2024-12-17 02:07:39,717] INFO [mysql-sink-connector|task-0] Using dialect io.debezium.connector.jdbc.dialect.mysql.MySqlDatabaseDialect (io.debezium.connector.jdbc.dialect.DatabaseDialectResolver:44)
[2024-12-17 02:07:39,730] INFO [mysql-sink-connector|task-0] Database TimeZone: SYSTEM (global), SYSTEM (system) (io.debezium.connector.jdbc.dialect.GeneralDatabaseDialect:114)
[2024-12-17 02:07:39,732] INFO [mysql-sink-connector|task-0] Database version 8.0.0 (io.debezium.connector.jdbc.JdbcChangeEventSink:69)
[2024-12-17 02:07:39,732] INFO [mysql-sink-connector|task-0] WorkerSinkTask{id=mysql-sink-connector-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:325)
[2024-12-17 02:07:39,733] INFO [mysql-sink-connector|task-0] WorkerSinkTask{id=mysql-sink-connector-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:211)
[2024-12-17 02:07:39,746] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:07:39,747] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:937)
[2024-12-17 02:07:39,750] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:605)
[2024-12-17 02:07:39,755] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Request joining group due to: need to re-join with the given member-id: connector-consumer-mysql-sink-connector-0-0722c373-31a4-4bf9-ae1f-486d47a60869 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 02:07:39,755] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:605)
[2024-12-17 02:07:39,758] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-mysql-sink-connector-0-0722c373-31a4-4bf9-ae1f-486d47a60869', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:666)
[2024-12-17 02:07:39,759] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Finished assignment for group at generation 1: {connector-consumer-mysql-sink-connector-0-0722c373-31a4-4bf9-ae1f-486d47a60869=Assignment(partitions=[fullfillment.test.customers-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:664)
[2024-12-17 02:07:39,763] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-mysql-sink-connector-0-0722c373-31a4-4bf9-ae1f-486d47a60869', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:843)
[2024-12-17 02:07:39,764] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Notifying assignor about the new Assignment(partitions=[fullfillment.test.customers-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:324)
[2024-12-17 02:07:39,764] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Adding newly assigned partitions: fullfillment.test.customers-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:58)
[2024-12-17 02:07:39,768] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Found no committed offset for partition fullfillment.test.customers-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1508)
[2024-12-17 02:07:39,775] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Resetting offset for partition fullfillment.test.customers-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=6}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:07:39,910] ERROR [mysql-sink-connector|task-0] Failed to process record: Failed to process a sink record (io.debezium.connector.jdbc.JdbcSinkConnectorTask:136)
org.apache.kafka.connect.errors.ConnectException: Failed to process a sink record
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:207)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.execute(JdbcChangeEventSink.java:152)
	at io.debezium.connector.jdbc.JdbcSinkConnectorTask.put(JdbcSinkConnectorTask.java:127)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:606)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:345)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:247)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:216)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:226)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:281)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:238)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Cannot write to table mongodb_customers with no key fields defined.
	at io.debezium.connector.jdbc.JdbcChangeEventSink.getSqlStatement(JdbcChangeEventSink.java:361)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBuffer(JdbcChangeEventSink.java:222)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:198)
	... 14 more
[2024-12-17 02:07:49,499] ERROR [mysql-sink-connector|task-0] JDBC sink connector failure (io.debezium.connector.jdbc.JdbcSinkConnectorTask:119)
org.apache.kafka.connect.errors.ConnectException: Failed to process a sink record
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:207)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.execute(JdbcChangeEventSink.java:152)
	at io.debezium.connector.jdbc.JdbcSinkConnectorTask.put(JdbcSinkConnectorTask.java:127)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:606)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:345)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:247)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:216)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:226)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:281)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:238)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Cannot write to table mongodb_customers with no key fields defined.
	at io.debezium.connector.jdbc.JdbcChangeEventSink.getSqlStatement(JdbcChangeEventSink.java:361)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBuffer(JdbcChangeEventSink.java:222)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:198)
	... 14 more
[2024-12-17 02:07:49,502] ERROR [mysql-sink-connector|task-0] WorkerSinkTask{id=mysql-sink-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: JDBC sink connector failure (org.apache.kafka.connect.runtime.WorkerSinkTask:634)
org.apache.kafka.connect.errors.ConnectException: JDBC sink connector failure
	at io.debezium.connector.jdbc.JdbcSinkConnectorTask.put(JdbcSinkConnectorTask.java:120)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:606)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:345)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:247)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:216)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:226)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:281)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:238)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to process a sink record
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:207)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.execute(JdbcChangeEventSink.java:152)
	at io.debezium.connector.jdbc.JdbcSinkConnectorTask.put(JdbcSinkConnectorTask.java:127)
	... 12 more
Caused by: org.apache.kafka.connect.errors.ConnectException: Cannot write to table mongodb_customers with no key fields defined.
	at io.debezium.connector.jdbc.JdbcChangeEventSink.getSqlStatement(JdbcChangeEventSink.java:361)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBuffer(JdbcChangeEventSink.java:222)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:198)
	... 14 more
[2024-12-17 02:07:49,503] ERROR [mysql-sink-connector|task-0] WorkerSinkTask{id=mysql-sink-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:234)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:636)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:345)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:247)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:216)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:226)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:281)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:238)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: JDBC sink connector failure
	at io.debezium.connector.jdbc.JdbcSinkConnectorTask.put(JdbcSinkConnectorTask.java:120)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:606)
	... 11 more
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to process a sink record
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:207)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.execute(JdbcChangeEventSink.java:152)
	at io.debezium.connector.jdbc.JdbcSinkConnectorTask.put(JdbcSinkConnectorTask.java:127)
	... 12 more
Caused by: org.apache.kafka.connect.errors.ConnectException: Cannot write to table mongodb_customers with no key fields defined.
	at io.debezium.connector.jdbc.JdbcChangeEventSink.getSqlStatement(JdbcChangeEventSink.java:361)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBuffer(JdbcChangeEventSink.java:222)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:198)
	... 14 more
[2024-12-17 02:07:49,504] INFO [mysql-sink-connector|task-0] Closing session. (io.debezium.connector.jdbc.JdbcChangeEventSink:235)
[2024-12-17 02:07:49,511] INFO [mysql-sink-connector|task-0] Closing the session factory (io.debezium.connector.jdbc.JdbcSinkConnectorTask:186)
[2024-12-17 02:07:49,522] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Revoke previously assigned partitions fullfillment.test.customers-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:80)
[2024-12-17 02:07:49,526] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Member connector-consumer-mysql-sink-connector-0-0722c373-31a4-4bf9-ae1f-486d47a60869 sending LeaveGroup request to coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1174)
[2024-12-17 02:07:49,527] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2024-12-17 02:07:49,528] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 02:07:49,816] INFO [mysql-sink-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:07:49,816] INFO [mysql-sink-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:07:49,817] INFO [mysql-sink-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:07:49,817] INFO [mysql-sink-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:07:49,824] INFO [mysql-sink-connector|task-0] App info kafka.consumer for connector-consumer-mysql-sink-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:08:50,591] INFO 172.30.0.4 - - [16/Dec/2024:19:08:50 +0000] "GET /connectors/mysql-sink-connector/status HTTP/1.1" 200 2441 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36" 26 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 02:09:19,598] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2510)
[2024-12-17 02:09:19,601] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2510)
[2024-12-17 02:21:47,230] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:21:47,240] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 02:21:47,245] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:21:47,246] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:21:47,260] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=510, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:21:47,272] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=510, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:21:47,274] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 02:21:47,276] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 02:21:47,278] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 02:21:47,279] INFO [mysql-sink-connector|task-0] Stopping task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1048)
[2024-12-17 02:21:47,284] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 02:21:47,322] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 02:21:47,329] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 510 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', leaderUrl='http://172.30.2.207:8083/', offset=820, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:21:47,334] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 820 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:21:47,334] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:21:47,334] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:21:47,334] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:21:47,354] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=511, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:21:47,365] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=511, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:21:47,366] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 511 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', leaderUrl='http://172.30.2.207:8083/', offset=820, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:21:47,367] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 820 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:21:47,368] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:24:01,398] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:371)
[2024-12-17 02:24:01,466] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 02:24:01,474] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:24:01,475] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:24:01,482] INFO 172.30.2.207 - - [16/Dec/2024:19:24:01 +0000] "POST /connectors HTTP/1.1" 201 1260 "-" "curl/7.81.0" 120 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 02:24:01,490] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=512, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:24:01,500] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=512, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:24:01,501] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 512 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', leaderUrl='http://172.30.2.207:8083/', offset=821, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:24:01,502] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 821 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:24:01,504] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 02:24:01,505] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 02:24:01,507] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:24:01,514] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:24:01,515] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 02:24:01,516] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 02:24:01,517] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:24:01,528] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:24:01,531] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:24:01,568] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 02:24:01,569] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:24:01,570] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:24:01,574] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=513, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:24:01,579] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Tasks [] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 02:24:01,582] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=513, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:24:01,583] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 513 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', leaderUrl='http://172.30.2.207:8083/', offset=824, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:24:01,585] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 824 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:24:01,586] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 02:24:01,588] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 02:24:01,590] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 02:24:01,600] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:24:01,611] INFO [mysql-sink-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.jdbc.JdbcSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:371)
[2024-12-17 02:24:01,612] INFO [mysql-sink-connector|task-0] New InternalSinkRecord class found (io.debezium.connector.jdbc.JdbcSinkConnectorTask:74)
[2024-12-17 02:24:01,612] INFO [mysql-sink-connector|task-0] Instantiated task mysql-sink-connector-0 with version 3.0.4.Final of type io.debezium.connector.jdbc.JdbcSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:665)
[2024-12-17 02:24:01,613] INFO [mysql-sink-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:24:01,615] INFO [mysql-sink-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:24:01,616] INFO [mysql-sink-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:680)
[2024-12-17 02:24:01,616] INFO [mysql-sink-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:686)
[2024-12-17 02:24:01,628] INFO [mysql-sink-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-sink-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:691)
[2024-12-17 02:24:01,630] WARN [mysql-sink-connector|task-0] The deleted record handling configs "drop.tombstones" and "delete.handling.mode" have been deprecated, please use "delete.tombstone.handling.mode" instead. (io.debezium.transforms.AbstractExtractNewRecordState:110)
[2024-12-17 02:24:01,632] WARN [mysql-sink-connector|task-0] Configuration key blacklist is deprecated and may be removed in the future.  Please update your configuration to use exclude instead. (org.apache.kafka.common.utils.ConfigUtils:114)
[2024-12-17 02:24:01,633] INFO [mysql-sink-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{io.debezium.connector.mongodb.transforms.ExtractNewDocumentState, org.apache.kafka.connect.transforms.ReplaceField$Value} (org.apache.kafka.connect.runtime.Worker:1795)
[2024-12-17 02:24:01,635] INFO [mysql-sink-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:24:01,639] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:24:01,640] INFO [mysql-sink-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mysql-sink-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mysql-sink-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2024-12-17 02:24:01,641] INFO [mysql-sink-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:24:01,650] INFO [mysql-sink-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2024-12-17 02:24:01,650] INFO [mysql-sink-connector|task-0] Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:24:01,650] INFO [mysql-sink-connector|task-0] Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:24:01,651] INFO [mysql-sink-connector|task-0] Kafka startTimeMs: 1734377041650 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:24:01,652] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:24:01,653] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:24:01,653] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:24:01,656] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=514, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:24:01,659] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=514, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:24:01,660] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Subscribed to topic(s): fullfillment.test.customers (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:481)
[2024-12-17 02:24:01,661] INFO [mysql-sink-connector|task-0] Stopping task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1048)
[2024-12-17 02:24:01,662] INFO [mysql-sink-connector|task-0] Starting JdbcSinkConnectorConfig with configuration: (io.debezium.connector.jdbc.JdbcSinkConnectorTask:410)
[2024-12-17 02:24:01,662] INFO [mysql-sink-connector|task-0]    connector.class = io.debezium.connector.jdbc.JdbcSinkConnector (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,663] INFO [mysql-sink-connector|task-0]    connection.password = ******** (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,663] INFO [mysql-sink-connector|task-0]    tasks.max = 1 (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,663] INFO [mysql-sink-connector|task-0]    transforms = unwrap,dropFields (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,663] INFO [mysql-sink-connector|task-0]    transforms.dropFields.type = org.apache.kafka.connect.transforms.ReplaceField$Value (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,663] INFO [mysql-sink-connector|task-0]    collection.name.format = mongodb_customers (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,663] INFO [mysql-sink-connector|task-0]    schema.evolution = basic (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,663] INFO [mysql-sink-connector|task-0]    auto.evolve = false (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,664] INFO [mysql-sink-connector|task-0]    transforms.unwrap.drop.tombstones = false (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,664] INFO [mysql-sink-connector|task-0]    transforms.unwrap.type = io.debezium.connector.mongodb.transforms.ExtractNewDocumentState (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,664] INFO [mysql-sink-connector|task-0]    driver.class = com.mysql.cj.jdbc.Driver (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,664] INFO [mysql-sink-connector|task-0]    value.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,664] INFO [mysql-sink-connector|task-0]    insert.mode = upsert (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,664] INFO [mysql-sink-connector|task-0]    key.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,664] INFO [mysql-sink-connector|task-0]    transforms.dropFields.blacklist = __deleted (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,664] INFO [mysql-sink-connector|task-0]    primary.key.mode = record_key (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,664] INFO [mysql-sink-connector|task-0]    topics = fullfillment.test.customers (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,664] INFO [mysql-sink-connector|task-0]    batch.size = 1000 (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,664] INFO [mysql-sink-connector|task-0]    connection.username = phuc (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,664] INFO [mysql-sink-connector|task-0]    key.converter.schemas.enable = true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,664] INFO [mysql-sink-connector|task-0]    delete.enabled = true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,665] INFO [mysql-sink-connector|task-0]    task.class = io.debezium.connector.jdbc.JdbcSinkConnectorTask (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,665] INFO [mysql-sink-connector|task-0]    name = mysql-sink-connector (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,665] INFO [mysql-sink-connector|task-0]    value.converter.schemas.enable = true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,665] INFO [mysql-sink-connector|task-0]    primary.key.fields = _id (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,665] INFO [mysql-sink-connector|task-0]    auto.create = false (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,665] INFO [mysql-sink-connector|task-0]    connection.url = jdbc:mysql://172.30.2.207:3306/demo?useSSL=false&allowPublicKeyRetrieval=true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,665] INFO [mysql-sink-connector|task-0]    transforms.unwrap.handle.duplicate.fields = skip (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,665] INFO [mysql-sink-connector|task-0]    transforms.unwrap.operation.header = true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:24:01,676] INFO [mysql-sink-connector|task-0] HHH000026: Second-level cache disabled (org.hibernate.cache.internal.RegionFactoryInitiator:50)
[2024-12-17 02:24:01,682] INFO [mysql-sink-connector|task-0] HHH000130: Instantiating explicit connection provider: org.hibernate.c3p0.internal.C3P0ConnectionProvider (org.hibernate.engine.jdbc.connections.internal.ConnectionProviderInitiator:131)
[2024-12-17 02:24:01,683] INFO [mysql-sink-connector|task-0] HHH010002: C3P0 using driver: null at URL: jdbc:mysql://172.30.2.207:3306/demo?useSSL=false&allowPublicKeyRetrieval=true (org.hibernate.orm.connections.pooling.c3p0:124)
[2024-12-17 02:24:01,683] INFO [mysql-sink-connector|task-0] HHH10001001: Connection properties: {password=****, user=phuc} (org.hibernate.orm.connections.pooling.c3p0:125)
[2024-12-17 02:24:01,683] INFO [mysql-sink-connector|task-0] HHH10001003: Autocommit mode: false (org.hibernate.orm.connections.pooling.c3p0:128)
[2024-12-17 02:24:01,684] WARN [mysql-sink-connector|task-0] HHH10001006: No JDBC Driver class was specified by property `jakarta.persistence.jdbc.driver`, `hibernate.driver` or `javax.persistence.jdbc.driver` (org.hibernate.orm.connections.pooling.c3p0:131)
[2024-12-17 02:24:01,712] INFO [mysql-sink-connector|task-0] HHH10001007: JDBC isolation level: <unknown> (org.hibernate.orm.connections.pooling.c3p0:200)
[2024-12-17 02:24:01,715] INFO [mysql-sink-connector|task-0] Initializing c3p0 pool... com.mchange.v2.c3p0.PoolBackedDataSource@a04e1bf7 [ connectionPoolDataSource -> com.mchange.v2.c3p0.WrapperConnectionPoolDataSource@8bcb4380 [ acquireIncrement -> 32, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, contextClassLoaderSource -> caller, debugUnreturnedConnectionStackTraces -> false, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, forceSynchronousCheckins -> false, identityToken -> z8kfsxb71lu9trp1602o2g|2b11b068, idleConnectionTestPeriod -> 0, initialPoolSize -> 5, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 0, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 32, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 5, nestedDataSource -> com.mchange.v2.c3p0.DriverManagerDataSource@fcfcf817 [ description -> null, driverClass -> null, factoryClassLocation -> null, forceUseNamedDriverClass -> false, identityToken -> z8kfsxb71lu9trp1602o2g|4dc17a78, jdbcUrl -> jdbc:mysql://172.30.2.207:3306/demo?useSSL=false&allowPublicKeyRetrieval=true, properties -> {password=******, user=******} ], preferredTestQuery -> null, privilegeSpawnedThreads -> false, propertyCycle -> 0, statementCacheNumDeferredCloseThreads -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false; userOverrides: {} ], dataSourceName -> null, extensions -> {}, factoryClassLocation -> null, identityToken -> z8kfsxb71lu9trp1602o2g|7f9f6a57, numHelperThreads -> 3 ] (com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource:212)
[2024-12-17 02:24:01,824] INFO [mysql-sink-connector|task-0] HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration) (org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator:58)
[2024-12-17 02:24:01,826] INFO [mysql-sink-connector|task-0] Using dialect io.debezium.connector.jdbc.dialect.mysql.MySqlDatabaseDialect (io.debezium.connector.jdbc.dialect.DatabaseDialectResolver:44)
[2024-12-17 02:24:01,831] INFO [mysql-sink-connector|task-0] Database TimeZone: SYSTEM (global), SYSTEM (system) (io.debezium.connector.jdbc.dialect.GeneralDatabaseDialect:114)
[2024-12-17 02:24:01,832] INFO [mysql-sink-connector|task-0] Database version 8.0.0 (io.debezium.connector.jdbc.JdbcChangeEventSink:69)
[2024-12-17 02:24:01,832] INFO [mysql-sink-connector|task-0] WorkerSinkTask{id=mysql-sink-connector-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:325)
[2024-12-17 02:24:01,833] INFO [mysql-sink-connector|task-0] WorkerSinkTask{id=mysql-sink-connector-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:211)
[2024-12-17 02:24:01,834] INFO [mysql-sink-connector|task-0] Closing session. (io.debezium.connector.jdbc.JdbcChangeEventSink:235)
[2024-12-17 02:24:01,834] INFO [mysql-sink-connector|task-0] Closing the session factory (io.debezium.connector.jdbc.JdbcSinkConnectorTask:186)
[2024-12-17 02:24:01,836] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2024-12-17 02:24:01,837] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 02:24:01,838] INFO [mysql-sink-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:24:01,839] INFO [mysql-sink-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:24:01,839] INFO [mysql-sink-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:24:01,839] INFO [mysql-sink-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:24:01,841] INFO [mysql-sink-connector|task-0] App info kafka.consumer for connector-consumer-mysql-sink-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:24:01,844] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 02:24:01,844] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 02:24:01,845] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 514 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', leaderUrl='http://172.30.2.207:8083/', offset=825, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:24:01,846] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 825 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:24:01,846] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:24:01,846] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:24:01,847] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:24:01,854] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=515, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:24:01,860] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=515, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:24:01,862] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 515 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', leaderUrl='http://172.30.2.207:8083/', offset=825, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:24:01,863] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 825 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:24:01,864] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:25:49,384] INFO 172.30.0.4 - - [16/Dec/2024:19:25:49 +0000] "GET /connectors/mysql-sink-connector/status HTTP/1.1" 200 120 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36" 24 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 02:25:55,988] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:25:55,992] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 02:25:55,994] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:25:55,995] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:25:56,011] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=516, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:25:56,020] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=516, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:25:56,021] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 02:25:56,021] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 02:25:56,022] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 02:25:56,024] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 02:25:56,026] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 02:25:56,026] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 516 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', leaderUrl='http://172.30.2.207:8083/', offset=827, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:25:56,028] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 827 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:25:56,029] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:25:56,029] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:25:56,029] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:25:56,032] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=517, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:25:56,036] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=517, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:25:56,037] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 517 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', leaderUrl='http://172.30.2.207:8083/', offset=827, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:25:56,038] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 827 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:25:56,038] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:30:16,850] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:371)
[2024-12-17 02:30:16,885] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 02:30:16,888] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:30:16,894] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:30:16,896] INFO 172.30.2.207 - - [16/Dec/2024:19:30:16 +0000] "POST /connectors HTTP/1.1" 201 1260 "-" "curl/7.81.0" 90 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 02:30:16,906] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=518, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:30:16,917] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=518, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:30:16,918] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 518 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', leaderUrl='http://172.30.2.207:8083/', offset=828, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:30:16,918] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 828 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:30:16,919] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 02:30:16,920] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 02:30:16,921] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:30:16,923] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:30:16,925] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 02:30:16,926] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 02:30:16,926] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:30:16,931] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:30:16,934] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:30:16,958] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 02:30:16,971] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:30:16,971] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:30:16,976] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=519, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:30:16,980] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=519, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:30:16,981] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 519 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', leaderUrl='http://172.30.2.207:8083/', offset=830, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:30:16,981] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 830 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:30:16,982] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 02:30:16,983] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 02:30:16,984] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 02:30:16,986] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:30:16,986] INFO [mysql-sink-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.jdbc.JdbcSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:371)
[2024-12-17 02:30:16,989] INFO [mysql-sink-connector|task-0] New InternalSinkRecord class found (io.debezium.connector.jdbc.JdbcSinkConnectorTask:74)
[2024-12-17 02:30:16,989] INFO [mysql-sink-connector|task-0] Instantiated task mysql-sink-connector-0 with version 3.0.4.Final of type io.debezium.connector.jdbc.JdbcSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:665)
[2024-12-17 02:30:16,989] INFO [mysql-sink-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:30:16,990] INFO [mysql-sink-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:30:16,990] INFO [mysql-sink-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:680)
[2024-12-17 02:30:16,990] INFO [mysql-sink-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:686)
[2024-12-17 02:30:16,991] INFO [mysql-sink-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-sink-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:691)
[2024-12-17 02:30:16,993] WARN [mysql-sink-connector|task-0] The deleted record handling configs "drop.tombstones" and "delete.handling.mode" have been deprecated, please use "delete.tombstone.handling.mode" instead. (io.debezium.transforms.AbstractExtractNewRecordState:110)
[2024-12-17 02:30:16,994] WARN [mysql-sink-connector|task-0] Configuration key blacklist is deprecated and may be removed in the future.  Please update your configuration to use exclude instead. (org.apache.kafka.common.utils.ConfigUtils:114)
[2024-12-17 02:30:16,996] INFO [mysql-sink-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{io.debezium.connector.mongodb.transforms.ExtractNewDocumentState, org.apache.kafka.connect.transforms.ReplaceField$Value} (org.apache.kafka.connect.runtime.Worker:1795)
[2024-12-17 02:30:16,997] INFO [mysql-sink-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:30:16,999] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:30:17,000] INFO [mysql-sink-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mysql-sink-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mysql-sink-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2024-12-17 02:30:17,002] INFO [mysql-sink-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:30:17,014] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 02:30:17,022] INFO [mysql-sink-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2024-12-17 02:30:17,022] INFO [mysql-sink-connector|task-0] Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:30:17,022] INFO [mysql-sink-connector|task-0] Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:30:17,023] INFO [mysql-sink-connector|task-0] Kafka startTimeMs: 1734377417022 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:30:17,026] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:30:17,027] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Handling task config update by stopping tasks [mysql-sink-connector-0], which will be restarted after rebalance if still assigned to this worker (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2024-12-17 02:30:17,029] INFO [mysql-sink-connector|task-0] Stopping task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1048)
[2024-12-17 02:30:17,037] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2024-12-17 02:30:17,038] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 02:30:17,039] INFO [mysql-sink-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:30:17,040] INFO [mysql-sink-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:30:17,040] INFO [mysql-sink-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:30:17,040] INFO [mysql-sink-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:30:17,043] INFO [mysql-sink-connector|task-0] App info kafka.consumer for connector-consumer-mysql-sink-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:30:17,052] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:30:17,052] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:30:17,057] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=520, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:30:17,063] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=520, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:30:17,065] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 520 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', leaderUrl='http://172.30.2.207:8083/', offset=832, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:30:17,066] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 832 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:30:17,067] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 02:30:17,069] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 02:30:17,080] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 02:30:17,087] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:30:17,087] INFO [mysql-sink-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.jdbc.JdbcSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:371)
[2024-12-17 02:30:17,088] INFO [mysql-sink-connector|task-0] New InternalSinkRecord class found (io.debezium.connector.jdbc.JdbcSinkConnectorTask:74)
[2024-12-17 02:30:17,088] INFO [mysql-sink-connector|task-0] Instantiated task mysql-sink-connector-0 with version 3.0.4.Final of type io.debezium.connector.jdbc.JdbcSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:665)
[2024-12-17 02:30:17,088] INFO [mysql-sink-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:30:17,089] INFO [mysql-sink-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:30:17,089] INFO [mysql-sink-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:680)
[2024-12-17 02:30:17,089] INFO [mysql-sink-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:686)
[2024-12-17 02:30:17,089] INFO [mysql-sink-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-sink-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:691)
[2024-12-17 02:30:17,091] WARN [mysql-sink-connector|task-0] The deleted record handling configs "drop.tombstones" and "delete.handling.mode" have been deprecated, please use "delete.tombstone.handling.mode" instead. (io.debezium.transforms.AbstractExtractNewRecordState:110)
[2024-12-17 02:30:17,091] WARN [mysql-sink-connector|task-0] Configuration key blacklist is deprecated and may be removed in the future.  Please update your configuration to use exclude instead. (org.apache.kafka.common.utils.ConfigUtils:114)
[2024-12-17 02:30:17,092] INFO [mysql-sink-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{io.debezium.connector.mongodb.transforms.ExtractNewDocumentState, org.apache.kafka.connect.transforms.ReplaceField$Value} (org.apache.kafka.connect.runtime.Worker:1795)
[2024-12-17 02:30:17,094] INFO [mysql-sink-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:30:17,097] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:30:17,100] INFO [mysql-sink-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mysql-sink-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mysql-sink-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2024-12-17 02:30:17,101] INFO [mysql-sink-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:30:17,115] INFO [mysql-sink-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2024-12-17 02:30:17,115] INFO [mysql-sink-connector|task-0] Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:30:17,115] INFO [mysql-sink-connector|task-0] Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:30:17,115] INFO [mysql-sink-connector|task-0] Kafka startTimeMs: 1734377417115 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:30:17,117] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:30:17,122] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Subscribed to topic(s): fullfillment.test.customers (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:481)
[2024-12-17 02:30:17,128] INFO [mysql-sink-connector|task-0] Starting JdbcSinkConnectorConfig with configuration: (io.debezium.connector.jdbc.JdbcSinkConnectorTask:410)
[2024-12-17 02:30:17,129] INFO [mysql-sink-connector|task-0]    connector.class = io.debezium.connector.jdbc.JdbcSinkConnector (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,130] INFO [mysql-sink-connector|task-0]    connection.password = ******** (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,130] INFO [mysql-sink-connector|task-0]    tasks.max = 1 (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,130] INFO [mysql-sink-connector|task-0]    transforms = unwrap,dropFields (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,131] INFO [mysql-sink-connector|task-0]    transforms.dropFields.type = org.apache.kafka.connect.transforms.ReplaceField$Value (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,131] INFO [mysql-sink-connector|task-0]    collection.name.format = mongodb_customers (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,131] INFO [mysql-sink-connector|task-0]    schema.evolution = basic (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,132] INFO [mysql-sink-connector|task-0]    auto.evolve = false (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,132] INFO [mysql-sink-connector|task-0]    transforms.unwrap.drop.tombstones = false (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,133] INFO [mysql-sink-connector|task-0]    transforms.unwrap.type = io.debezium.connector.mongodb.transforms.ExtractNewDocumentState (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,133] INFO [mysql-sink-connector|task-0]    driver.class = com.mysql.cj.jdbc.Driver (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,133] INFO [mysql-sink-connector|task-0]    value.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,134] INFO [mysql-sink-connector|task-0]    insert.mode = upsert (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,134] INFO [mysql-sink-connector|task-0]    key.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,135] INFO [mysql-sink-connector|task-0]    transforms.dropFields.blacklist = __deleted (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,135] INFO [mysql-sink-connector|task-0]    primary.key.mode = record_key (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,135] INFO [mysql-sink-connector|task-0]    topics = fullfillment.test.customers (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,136] INFO [mysql-sink-connector|task-0]    batch.size = 1000 (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,137] INFO [mysql-sink-connector|task-0]    connection.username = phuc (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,137] INFO [mysql-sink-connector|task-0]    key.converter.schemas.enable = true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,137] INFO [mysql-sink-connector|task-0]    delete.enabled = true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,138] INFO [mysql-sink-connector|task-0]    task.class = io.debezium.connector.jdbc.JdbcSinkConnectorTask (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,138] INFO [mysql-sink-connector|task-0]    name = mysql-sink-connector (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,139] INFO [mysql-sink-connector|task-0]    value.converter.schemas.enable = true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,140] INFO [mysql-sink-connector|task-0]    primary.key.fields = _id (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,140] INFO [mysql-sink-connector|task-0]    auto.create = false (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,141] INFO [mysql-sink-connector|task-0]    connection.url = jdbc:mysql://172.30.2.207:3306/demo?useSSL=false&allowPublicKeyRetrieval=true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,141] INFO [mysql-sink-connector|task-0]    transforms.unwrap.handle.duplicate.fields = skip (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,141] INFO [mysql-sink-connector|task-0]    transforms.unwrap.operation.header = true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:30:17,166] INFO [mysql-sink-connector|task-0] HHH000026: Second-level cache disabled (org.hibernate.cache.internal.RegionFactoryInitiator:50)
[2024-12-17 02:30:17,172] INFO [mysql-sink-connector|task-0] HHH000130: Instantiating explicit connection provider: org.hibernate.c3p0.internal.C3P0ConnectionProvider (org.hibernate.engine.jdbc.connections.internal.ConnectionProviderInitiator:131)
[2024-12-17 02:30:17,172] INFO [mysql-sink-connector|task-0] HHH010002: C3P0 using driver: null at URL: jdbc:mysql://172.30.2.207:3306/demo?useSSL=false&allowPublicKeyRetrieval=true (org.hibernate.orm.connections.pooling.c3p0:124)
[2024-12-17 02:30:17,173] INFO [mysql-sink-connector|task-0] HHH10001001: Connection properties: {password=****, user=phuc} (org.hibernate.orm.connections.pooling.c3p0:125)
[2024-12-17 02:30:17,173] INFO [mysql-sink-connector|task-0] HHH10001003: Autocommit mode: false (org.hibernate.orm.connections.pooling.c3p0:128)
[2024-12-17 02:30:17,173] WARN [mysql-sink-connector|task-0] HHH10001006: No JDBC Driver class was specified by property `jakarta.persistence.jdbc.driver`, `hibernate.driver` or `javax.persistence.jdbc.driver` (org.hibernate.orm.connections.pooling.c3p0:131)
[2024-12-17 02:30:17,206] INFO [mysql-sink-connector|task-0] HHH10001007: JDBC isolation level: <unknown> (org.hibernate.orm.connections.pooling.c3p0:200)
[2024-12-17 02:30:17,209] INFO [mysql-sink-connector|task-0] Initializing c3p0 pool... com.mchange.v2.c3p0.PoolBackedDataSource@c0c8bb18 [ connectionPoolDataSource -> com.mchange.v2.c3p0.WrapperConnectionPoolDataSource@90ed94dd [ acquireIncrement -> 32, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, contextClassLoaderSource -> caller, debugUnreturnedConnectionStackTraces -> false, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, forceSynchronousCheckins -> false, identityToken -> z8kfsxb71lu9trp1602o2g|189ed7fc, idleConnectionTestPeriod -> 0, initialPoolSize -> 5, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 0, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 32, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 5, nestedDataSource -> com.mchange.v2.c3p0.DriverManagerDataSource@81237981 [ description -> null, driverClass -> null, factoryClassLocation -> null, forceUseNamedDriverClass -> false, identityToken -> z8kfsxb71lu9trp1602o2g|af1a2ee, jdbcUrl -> jdbc:mysql://172.30.2.207:3306/demo?useSSL=false&allowPublicKeyRetrieval=true, properties -> {password=******, user=******} ], preferredTestQuery -> null, privilegeSpawnedThreads -> false, propertyCycle -> 0, statementCacheNumDeferredCloseThreads -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false; userOverrides: {} ], dataSourceName -> null, extensions -> {}, factoryClassLocation -> null, identityToken -> z8kfsxb71lu9trp1602o2g|7dde5a8f, numHelperThreads -> 3 ] (com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource:212)
[2024-12-17 02:30:17,321] INFO [mysql-sink-connector|task-0] HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration) (org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator:58)
[2024-12-17 02:30:17,323] INFO [mysql-sink-connector|task-0] Using dialect io.debezium.connector.jdbc.dialect.mysql.MySqlDatabaseDialect (io.debezium.connector.jdbc.dialect.DatabaseDialectResolver:44)
[2024-12-17 02:30:17,341] INFO [mysql-sink-connector|task-0] Database TimeZone: SYSTEM (global), SYSTEM (system) (io.debezium.connector.jdbc.dialect.GeneralDatabaseDialect:114)
[2024-12-17 02:30:17,343] INFO [mysql-sink-connector|task-0] Database version 8.0.0 (io.debezium.connector.jdbc.JdbcChangeEventSink:69)
[2024-12-17 02:30:17,343] INFO [mysql-sink-connector|task-0] WorkerSinkTask{id=mysql-sink-connector-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:325)
[2024-12-17 02:30:17,344] INFO [mysql-sink-connector|task-0] WorkerSinkTask{id=mysql-sink-connector-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:211)
[2024-12-17 02:30:17,361] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:30:17,362] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:937)
[2024-12-17 02:30:17,363] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:605)
[2024-12-17 02:30:17,374] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Request joining group due to: need to re-join with the given member-id: connector-consumer-mysql-sink-connector-0-b5176ddc-05cc-4655-b63c-25d88f706066 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 02:30:17,374] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:605)
[2024-12-17 02:30:17,378] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-mysql-sink-connector-0-b5176ddc-05cc-4655-b63c-25d88f706066', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:666)
[2024-12-17 02:30:17,379] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Finished assignment for group at generation 1: {connector-consumer-mysql-sink-connector-0-b5176ddc-05cc-4655-b63c-25d88f706066=Assignment(partitions=[fullfillment.test.customers-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:664)
[2024-12-17 02:30:17,382] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-mysql-sink-connector-0-b5176ddc-05cc-4655-b63c-25d88f706066', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:843)
[2024-12-17 02:30:17,383] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Notifying assignor about the new Assignment(partitions=[fullfillment.test.customers-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:324)
[2024-12-17 02:30:17,384] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Adding newly assigned partitions: fullfillment.test.customers-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:58)
[2024-12-17 02:30:17,388] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Found no committed offset for partition fullfillment.test.customers-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1508)
[2024-12-17 02:30:17,403] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Resetting offset for partition fullfillment.test.customers-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=6}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:30:17,455] WARN [mysql-sink-connector|task-0] SQL Error: 1060, SQLState: 42S21 (org.hibernate.engine.jdbc.spi.SqlExceptionHelper:145)
[2024-12-17 02:30:17,455] ERROR [mysql-sink-connector|task-0] Duplicate column name 'createdAt' (org.hibernate.engine.jdbc.spi.SqlExceptionHelper:150)
[2024-12-17 02:30:17,456] ERROR [mysql-sink-connector|task-0] Failed to process record: Failed to process a sink record (io.debezium.connector.jdbc.JdbcSinkConnectorTask:136)
org.apache.kafka.connect.errors.ConnectException: Failed to process a sink record
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:207)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.execute(JdbcChangeEventSink.java:152)
	at io.debezium.connector.jdbc.JdbcSinkConnectorTask.put(JdbcSinkConnectorTask.java:127)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:606)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:345)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:247)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:216)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:226)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:281)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:238)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.hibernate.exception.SQLGrammarException: JDBC exception executing SQL [ALTER TABLE mongodb_customers ADD COLUMN ( createdAt datetime(6) NULL)] [Duplicate column name 'createdAt'] [n/a]
	at org.hibernate.exception.internal.SQLExceptionTypeDelegate.convert(SQLExceptionTypeDelegate.java:66)
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:58)
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:108)
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:94)
	at org.hibernate.sql.exec.internal.StandardJdbcMutationExecutor.execute(StandardJdbcMutationExecutor.java:101)
	at org.hibernate.query.sql.internal.NativeNonSelectQueryPlanImpl.executeUpdate(NativeNonSelectQueryPlanImpl.java:76)
	at org.hibernate.query.sql.internal.NativeQueryImpl.doExecuteUpdate(NativeQueryImpl.java:833)
	at org.hibernate.query.spi.AbstractQuery.executeUpdate(AbstractQuery.java:650)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.alterTableIfNeeded(JdbcChangeEventSink.java:343)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.checkAndApplyTableChangesIfNeeded(JdbcChangeEventSink.java:265)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBuffer(JdbcChangeEventSink.java:220)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:198)
	... 14 more
Caused by: java.sql.SQLSyntaxErrorException: Duplicate column name 'createdAt'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:112)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:988)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1166)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1101)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeLargeUpdate(ClientPreparedStatement.java:1467)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdate(ClientPreparedStatement.java:1084)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.executeUpdate(NewProxyPreparedStatement.java:1502)
	at org.hibernate.sql.exec.internal.StandardJdbcMutationExecutor.execute(StandardJdbcMutationExecutor.java:87)
	... 21 more
[2024-12-17 02:30:27,117] ERROR [mysql-sink-connector|task-0] JDBC sink connector failure (io.debezium.connector.jdbc.JdbcSinkConnectorTask:119)
org.apache.kafka.connect.errors.ConnectException: Failed to process a sink record
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:207)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.execute(JdbcChangeEventSink.java:152)
	at io.debezium.connector.jdbc.JdbcSinkConnectorTask.put(JdbcSinkConnectorTask.java:127)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:606)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:345)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:247)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:216)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:226)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:281)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:238)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.hibernate.exception.SQLGrammarException: JDBC exception executing SQL [ALTER TABLE mongodb_customers ADD COLUMN ( createdAt datetime(6) NULL)] [Duplicate column name 'createdAt'] [n/a]
	at org.hibernate.exception.internal.SQLExceptionTypeDelegate.convert(SQLExceptionTypeDelegate.java:66)
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:58)
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:108)
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:94)
	at org.hibernate.sql.exec.internal.StandardJdbcMutationExecutor.execute(StandardJdbcMutationExecutor.java:101)
	at org.hibernate.query.sql.internal.NativeNonSelectQueryPlanImpl.executeUpdate(NativeNonSelectQueryPlanImpl.java:76)
	at org.hibernate.query.sql.internal.NativeQueryImpl.doExecuteUpdate(NativeQueryImpl.java:833)
	at org.hibernate.query.spi.AbstractQuery.executeUpdate(AbstractQuery.java:650)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.alterTableIfNeeded(JdbcChangeEventSink.java:343)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.checkAndApplyTableChangesIfNeeded(JdbcChangeEventSink.java:265)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBuffer(JdbcChangeEventSink.java:220)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:198)
	... 14 more
Caused by: java.sql.SQLSyntaxErrorException: Duplicate column name 'createdAt'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:112)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:988)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1166)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1101)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeLargeUpdate(ClientPreparedStatement.java:1467)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdate(ClientPreparedStatement.java:1084)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.executeUpdate(NewProxyPreparedStatement.java:1502)
	at org.hibernate.sql.exec.internal.StandardJdbcMutationExecutor.execute(StandardJdbcMutationExecutor.java:87)
	... 21 more
[2024-12-17 02:30:27,119] ERROR [mysql-sink-connector|task-0] WorkerSinkTask{id=mysql-sink-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: JDBC sink connector failure (org.apache.kafka.connect.runtime.WorkerSinkTask:634)
org.apache.kafka.connect.errors.ConnectException: JDBC sink connector failure
	at io.debezium.connector.jdbc.JdbcSinkConnectorTask.put(JdbcSinkConnectorTask.java:120)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:606)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:345)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:247)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:216)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:226)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:281)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:238)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to process a sink record
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:207)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.execute(JdbcChangeEventSink.java:152)
	at io.debezium.connector.jdbc.JdbcSinkConnectorTask.put(JdbcSinkConnectorTask.java:127)
	... 12 more
Caused by: org.hibernate.exception.SQLGrammarException: JDBC exception executing SQL [ALTER TABLE mongodb_customers ADD COLUMN ( createdAt datetime(6) NULL)] [Duplicate column name 'createdAt'] [n/a]
	at org.hibernate.exception.internal.SQLExceptionTypeDelegate.convert(SQLExceptionTypeDelegate.java:66)
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:58)
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:108)
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:94)
	at org.hibernate.sql.exec.internal.StandardJdbcMutationExecutor.execute(StandardJdbcMutationExecutor.java:101)
	at org.hibernate.query.sql.internal.NativeNonSelectQueryPlanImpl.executeUpdate(NativeNonSelectQueryPlanImpl.java:76)
	at org.hibernate.query.sql.internal.NativeQueryImpl.doExecuteUpdate(NativeQueryImpl.java:833)
	at org.hibernate.query.spi.AbstractQuery.executeUpdate(AbstractQuery.java:650)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.alterTableIfNeeded(JdbcChangeEventSink.java:343)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.checkAndApplyTableChangesIfNeeded(JdbcChangeEventSink.java:265)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBuffer(JdbcChangeEventSink.java:220)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:198)
	... 14 more
Caused by: java.sql.SQLSyntaxErrorException: Duplicate column name 'createdAt'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:112)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:988)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1166)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1101)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeLargeUpdate(ClientPreparedStatement.java:1467)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdate(ClientPreparedStatement.java:1084)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.executeUpdate(NewProxyPreparedStatement.java:1502)
	at org.hibernate.sql.exec.internal.StandardJdbcMutationExecutor.execute(StandardJdbcMutationExecutor.java:87)
	... 21 more
[2024-12-17 02:30:27,126] ERROR [mysql-sink-connector|task-0] WorkerSinkTask{id=mysql-sink-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:234)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:636)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:345)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:247)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:216)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:226)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:281)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:238)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: JDBC sink connector failure
	at io.debezium.connector.jdbc.JdbcSinkConnectorTask.put(JdbcSinkConnectorTask.java:120)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:606)
	... 11 more
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to process a sink record
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:207)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.execute(JdbcChangeEventSink.java:152)
	at io.debezium.connector.jdbc.JdbcSinkConnectorTask.put(JdbcSinkConnectorTask.java:127)
	... 12 more
Caused by: org.hibernate.exception.SQLGrammarException: JDBC exception executing SQL [ALTER TABLE mongodb_customers ADD COLUMN ( createdAt datetime(6) NULL)] [Duplicate column name 'createdAt'] [n/a]
	at org.hibernate.exception.internal.SQLExceptionTypeDelegate.convert(SQLExceptionTypeDelegate.java:66)
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:58)
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:108)
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:94)
	at org.hibernate.sql.exec.internal.StandardJdbcMutationExecutor.execute(StandardJdbcMutationExecutor.java:101)
	at org.hibernate.query.sql.internal.NativeNonSelectQueryPlanImpl.executeUpdate(NativeNonSelectQueryPlanImpl.java:76)
	at org.hibernate.query.sql.internal.NativeQueryImpl.doExecuteUpdate(NativeQueryImpl.java:833)
	at org.hibernate.query.spi.AbstractQuery.executeUpdate(AbstractQuery.java:650)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.alterTableIfNeeded(JdbcChangeEventSink.java:343)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.checkAndApplyTableChangesIfNeeded(JdbcChangeEventSink.java:265)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBuffer(JdbcChangeEventSink.java:220)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:198)
	... 14 more
Caused by: java.sql.SQLSyntaxErrorException: Duplicate column name 'createdAt'
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:112)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:988)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1166)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1101)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeLargeUpdate(ClientPreparedStatement.java:1467)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdate(ClientPreparedStatement.java:1084)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.executeUpdate(NewProxyPreparedStatement.java:1502)
	at org.hibernate.sql.exec.internal.StandardJdbcMutationExecutor.execute(StandardJdbcMutationExecutor.java:87)
	... 21 more
[2024-12-17 02:30:27,128] INFO [mysql-sink-connector|task-0] Closing session. (io.debezium.connector.jdbc.JdbcChangeEventSink:235)
[2024-12-17 02:30:27,129] INFO [mysql-sink-connector|task-0] Closing the session factory (io.debezium.connector.jdbc.JdbcSinkConnectorTask:186)
[2024-12-17 02:30:27,139] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Revoke previously assigned partitions fullfillment.test.customers-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:80)
[2024-12-17 02:30:27,141] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Member connector-consumer-mysql-sink-connector-0-b5176ddc-05cc-4655-b63c-25d88f706066 sending LeaveGroup request to coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1174)
[2024-12-17 02:30:27,142] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2024-12-17 02:30:27,143] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 02:30:27,435] INFO [mysql-sink-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:30:27,435] INFO [mysql-sink-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:30:27,436] INFO [mysql-sink-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:30:27,436] INFO [mysql-sink-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:30:27,446] INFO [mysql-sink-connector|task-0] App info kafka.consumer for connector-consumer-mysql-sink-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:30:31,553] INFO 172.30.0.4 - - [16/Dec/2024:19:30:31 +0000] "GET /connectors/mysql-sink-connector/status HTTP/1.1" 200 4461 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36" 14 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 02:32:39,865] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:32:39,867] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 02:32:39,877] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:32:39,877] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:32:39,895] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=521, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:32:39,920] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=521, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:32:39,923] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 02:32:39,924] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 02:32:39,926] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 02:32:39,931] INFO [mysql-sink-connector|task-0] Stopping task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1048)
[2024-12-17 02:32:39,945] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 02:32:39,950] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 02:32:39,951] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 521 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', leaderUrl='http://172.30.2.207:8083/', offset=834, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:32:39,957] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 834 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:32:39,958] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:32:39,959] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:32:39,959] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:32:39,964] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=522, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:32:39,969] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=522, memberId='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:32:39,969] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 522 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168', leaderUrl='http://172.30.2.207:8083/', offset=834, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:32:39,970] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 834 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:32:39,976] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:35:13,981] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:371)
[2024-12-17 02:35:14,011] INFO 172.30.2.207 - - [16/Dec/2024:19:35:13 +0000] "POST /connectors HTTP/1.1" 400 404 "-" "curl/7.81.0" 77 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 02:35:47,356] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:87)
[2024-12-17 02:35:47,362] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:358)
[2024-12-17 02:35:47,410] INFO Stopped http_0.0.0.08083@532d74e0{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2024-12-17 02:35:47,412] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2024-12-17 02:35:47,444] INFO Stopped o.e.j.s.ServletContextHandler@184326f2{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2024-12-17 02:35:47,446] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:387)
[2024-12-17 02:35:47,446] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:851)
[2024-12-17 02:35:47,448] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:808)
[2024-12-17 02:35:47,448] INFO [mongodb-source-connector|worker] Stopping connector mongodb-source-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 02:35:47,449] INFO [mongodb-source-connector|worker] Scheduled shutdown for WorkerConnector{id=mongodb-source-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 02:35:47,450] INFO [mongodb-source-connector|worker] Stopping MongoDB connector (io.debezium.connector.mongodb.MongoDbConnector:82)
[2024-12-17 02:35:47,451] INFO [mongodb-source-connector|worker] Stopped MongoDB connector (io.debezium.connector.mongodb.MongoDbConnector:86)
[2024-12-17 02:35:47,455] INFO [mongodb-source-connector|worker] Completed shutdown for WorkerConnector{id=mongodb-source-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 02:35:47,458] INFO [mongodb-source-connector|task-0] Stopping task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.Worker:1048)
[2024-12-17 02:35:47,461] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:317)
[2024-12-17 02:35:47,464] INFO [Producer clientId=mysql-sink-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2024-12-17 02:35:47,481] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:35:47,482] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:47,482] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:47,482] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:35:47,484] INFO App info kafka.producer for mysql-sink-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:35:47,485] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2024-12-17 02:35:47,485] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 02:35:47,491] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Node 0 sent an invalid full fetch response with extraIds=(BvVnx0t_SlGXkZscTz3wEQ), response=() (org.apache.kafka.clients.FetchSessionHandler:556)
[2024-12-17 02:35:47,492] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:35:47,493] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:47,493] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:47,493] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:35:47,499] INFO App info kafka.consumer for mysql-sink-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:35:47,499] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:341)
[2024-12-17 02:35:47,500] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:407)
[2024-12-17 02:35:47,501] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:317)
[2024-12-17 02:35:47,502] INFO [Producer clientId=mysql-sink-cluster-configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2024-12-17 02:35:47,508] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:35:47,509] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:47,510] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:47,510] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:35:47,517] INFO App info kafka.producer for mysql-sink-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:35:47,518] INFO [Consumer clientId=mysql-sink-cluster-configs, groupId=mysql-sink-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2024-12-17 02:35:47,518] INFO [Consumer clientId=mysql-sink-cluster-configs, groupId=mysql-sink-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 02:35:47,522] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:35:47,522] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:47,523] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:47,524] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:35:47,528] INFO App info kafka.consumer for mysql-sink-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:35:47,529] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:341)
[2024-12-17 02:35:47,530] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:412)
[2024-12-17 02:35:47,530] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:250)
[2024-12-17 02:35:47,535] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:261)
[2024-12-17 02:35:47,535] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:317)
[2024-12-17 02:35:47,537] INFO [Producer clientId=mysql-sink-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2024-12-17 02:35:47,543] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:35:47,544] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:47,544] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:47,544] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:35:47,545] INFO App info kafka.producer for mysql-sink-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:35:47,545] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2024-12-17 02:35:47,545] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 02:35:47,568] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:35:47,569] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:47,570] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:47,570] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:35:47,576] INFO App info kafka.consumer for mysql-sink-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:35:47,576] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:341)
[2024-12-17 02:35:47,576] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:263)
[2024-12-17 02:35:47,577] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:35:47,577] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:47,578] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:35:47,578] INFO App info kafka.connect for 172.30.2.207:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:35:47,579] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:271)
[2024-12-17 02:35:47,584] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Member connect-172.30.2.207:8083-a6bac13d-b906-4c63-93ee-b9af4e575168 sending LeaveGroup request to coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1174)
[2024-12-17 02:35:47,585] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1056)
[2024-12-17 02:35:47,585] WARN [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1141)
[2024-12-17 02:35:47,586] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:35:47,586] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:47,586] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:35:47,592] INFO App info kafka.connect for connect-172.30.2.207:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:35:47,597] INFO App info kafka.admin.client for mysql-sink-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:35:47,601] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:35:47,602] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:35:47,602] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:35:47,603] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:394)
[2024-12-17 02:35:47,610] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:858)
[2024-12-17 02:35:47,610] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:92)
[2024-12-17 02:35:49,955] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2024-12-17 02:35:49,965] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/opt/kafka/bin/../logs, -Dlog4j.configuration=file:/opt/kafka/bin/../config/connect-log4j.properties
	jvm.spec = Ubuntu, OpenJDK 64-Bit Server VM, 17.0.13, 17.0.13+11-Ubuntu-2ubuntu122.04
	jvm.classpath = /opt/kafka/plugins/debezium-connector-jdbc/waffle-jna-3.2.0.jar:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-core-4.0.2.jar:/opt/kafka/plugins/debezium-connector-jdbc/txw2-4.0.2.jar:/opt/kafka/plugins/debezium-connector-jdbc/ojdbc11-21.15.0.0.jar:/opt/kafka/plugins/debezium-connector-jdbc/c3p0-0.9.5.5.jar:/opt/kafka/plugins/debezium-connector-jdbc/angus-activation-2.0.0.jar:/opt/kafka/plugins/debezium-connector-jdbc/jandex-3.1.2.jar:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-c3p0-6.4.8.Final.jar:/opt/kafka/plugins/debezium-connector-jdbc/mysql-connector-j-9.1.0.jar:/opt/kafka/plugins/debezium-connector-jdbc/error_prone_annotations-2.10.0.jar:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.activation-api-2.1.0.jar:/opt/kafka/plugins/debezium-connector-jdbc/byte-buddy-1.14.11.jar:/opt/kafka/plugins/debezium-connector-jdbc/istack-commons-runtime-4.1.1.jar:/opt/kafka/plugins/debezium-connector-jdbc/mssql-jdbc-12.4.2.jre8.jar:/opt/kafka/plugins/debezium-connector-jdbc/mchange-commons-java-0.2.19.jar:/opt/kafka/plugins/debezium-connector-jdbc/caffeine-2.9.3.jar:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-runtime-4.0.2.jar:/opt/kafka/plugins/debezium-connector-jdbc/jboss-logging-3.5.0.Final.jar:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.persistence-api-3.1.0.jar:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.xml.bind-api-4.0.0.jar:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.inject-api-2.0.1.jar:/opt/kafka/plugins/debezium-connector-jdbc/mariadb-java-client-3.2.0.jar:/opt/kafka/plugins/debezium-connector-jdbc/jna-platform-5.12.1.jar:/opt/kafka/plugins/debezium-connector-jdbc/antlr4-runtime-4.10.1.jar:/opt/kafka/plugins/debezium-connector-jdbc/jcl-over-slf4j-1.7.36.jar:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-commons-annotations-6.0.6.Final.jar:/opt/kafka/plugins/debezium-connector-jdbc/postgresql-42.6.1.jar:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.transaction-api-2.0.1.jar:/opt/kafka/plugins/debezium-connector-jdbc/debezium-sink-3.0.4.Final.jar:/opt/kafka/plugins/debezium-connector-jdbc/debezium-api-3.0.4.Final.jar:/opt/kafka/plugins/debezium-connector-jdbc/classmate-1.5.1.jar:/opt/kafka/plugins/debezium-connector-jdbc/debezium-connector-jdbc-3.0.4.Final.jar:/opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar:/opt/kafka/plugins/debezium-connector-jdbc/jna-5.12.1.jar:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-core-6.4.8.Final.jar:/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.12.0.jar:/opt/kafka/bin/../libs/caffeine-2.9.3.jar:/opt/kafka/bin/../libs/commons-beanutils-1.9.4.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-collections-3.2.2.jar:/opt/kafka/bin/../libs/commons-digester-2.1.jar:/opt/kafka/bin/../libs/commons-io-2.14.0.jar:/opt/kafka/bin/../libs/commons-lang3-3.12.0.jar:/opt/kafka/bin/../libs/commons-logging-1.2.jar:/opt/kafka/bin/../libs/commons-validator-1.7.jar:/opt/kafka/bin/../libs/connect-api-3.9.0.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-3.9.0.jar:/opt/kafka/bin/../libs/connect-json-3.9.0.jar:/opt/kafka/bin/../libs/connect-mirror-3.9.0.jar:/opt/kafka/bin/../libs/connect-mirror-client-3.9.0.jar:/opt/kafka/bin/../libs/connect-runtime-3.9.0.jar:/opt/kafka/bin/../libs/connect-transforms-3.9.0.jar:/opt/kafka/bin/../libs/error_prone_annotations-2.10.0.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.16.2.jar:/opt/kafka/bin/../libs/jackson-core-2.16.2.jar:/opt/kafka/bin/../libs/jackson-databind-2.16.2.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/opt/kafka/bin/../libs/jackson-module-afterburner-2.16.2.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.2.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/opt/kafka/bin/../libs/javassist-3.29.2-GA.jar:/opt/kafka/bin/../libs/javax.activation-api-1.2.0.jar:/opt/kafka/bin/../libs/javax.annotation-api-1.3.2.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.1.jar:/opt/kafka/bin/../libs/jersey-client-2.39.1.jar:/opt/kafka/bin/../libs/jersey-common-2.39.1.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.39.1.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/opt/kafka/bin/../libs/jersey-hk2-2.39.1.jar:/opt/kafka/bin/../libs/jersey-server-2.39.1.jar:/opt/kafka/bin/../libs/jetty-client-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-http-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-io-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-security-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-server-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-util-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jline-3.25.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/jose4j-0.9.4.jar:/opt/kafka/bin/../libs/jsr305-3.0.2.jar:/opt/kafka/bin/../libs/kafka-clients-3.9.0.jar:/opt/kafka/bin/../libs/kafka-group-coordinator-3.9.0.jar:/opt/kafka/bin/../libs/kafka-group-coordinator-api-3.9.0.jar:/opt/kafka/bin/../libs/kafka-metadata-3.9.0.jar:/opt/kafka/bin/../libs/kafka-raft-3.9.0.jar:/opt/kafka/bin/../libs/kafka-server-3.9.0.jar:/opt/kafka/bin/../libs/kafka-server-common-3.9.0.jar:/opt/kafka/bin/../libs/kafka-shell-3.9.0.jar:/opt/kafka/bin/../libs/kafka-storage-3.9.0.jar:/opt/kafka/bin/../libs/kafka-storage-api-3.9.0.jar:/opt/kafka/bin/../libs/kafka-streams-3.9.0.jar:/opt/kafka/bin/../libs/kafka-streams-examples-3.9.0.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-3.9.0.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-3.9.0.jar:/opt/kafka/bin/../libs/kafka-tools-3.9.0.jar:/opt/kafka/bin/../libs/kafka-tools-api-3.9.0.jar:/opt/kafka/bin/../libs/kafka-transaction-coordinator-3.9.0.jar:/opt/kafka/bin/../libs/kafka_2.13-3.9.0.jar:/opt/kafka/bin/../libs/lz4-java-1.8.0.jar:/opt/kafka/bin/../libs/maven-artifact-3.9.6.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-transport-classes-epoll-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.111.Final.jar:/opt/kafka/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/pcollections-4.0.1.jar:/opt/kafka/bin/../libs/plexus-utils-3.5.1.jar:/opt/kafka/bin/../libs/protobuf-java-3.25.5.jar:/opt/kafka/bin/../libs/reflections-0.10.2.jar:/opt/kafka/bin/../libs/reload4j-1.2.25.jar:/opt/kafka/bin/../libs/rocksdbjni-7.9.2.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/opt/kafka/bin/../libs/scala-library-2.13.14.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.5.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.14.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.36.jar:/opt/kafka/bin/../libs/slf4j-reload4j-1.7.36.jar:/opt/kafka/bin/../libs/snappy-java-1.1.10.5.jar:/opt/kafka/bin/../libs/swagger-annotations-2.2.8.jar:/opt/kafka/bin/../libs/trogdor-3.9.0.jar:/opt/kafka/bin/../libs/zookeeper-3.8.4.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.8.4.jar:/opt/kafka/bin/../libs/zstd-jni-1.5.6-4.jar
	os.spec = Linux, amd64, 5.15.0-125-generic
	os.vcpus = 2
 (org.apache.kafka.connect.runtime.WorkerInfo:72)
[2024-12-17 02:35:49,969] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2024-12-17 02:35:50,022] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:50,147] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 02:35:50,636] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:50,899] INFO Loading plugin from: /opt/kafka/plugins/hibernate-core-6.4.1.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:50,920] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 02:35:50,979] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/hibernate-core-6.4.1.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,017] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,060] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 02:35:51,172] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,347] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/waffle-jna-3.2.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,370] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/waffle-jna-3.2.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,393] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jaxb-core-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,410] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-core-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,427] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/txw2-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,440] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/txw2-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,457] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/ojdbc11-21.15.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,467] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/ojdbc11-21.15.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,524] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/c3p0-0.9.5.5.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,537] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/c3p0-0.9.5.5.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,556] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/angus-activation-2.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,566] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/angus-activation-2.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,582] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jandex-3.1.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,592] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jandex-3.1.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,611] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-c3p0-6.4.8.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,620] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-c3p0-6.4.8.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,634] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mysql-connector-j-9.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,643] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mysql-connector-j-9.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,660] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/error_prone_annotations-2.10.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,674] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/error_prone_annotations-2.10.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,687] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.activation-api-2.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,696] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.activation-api-2.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,710] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/byte-buddy-1.14.11.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,719] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/byte-buddy-1.14.11.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,732] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/istack-commons-runtime-4.1.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,753] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/istack-commons-runtime-4.1.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,764] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mssql-jdbc-12.4.2.jre8.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,774] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mssql-jdbc-12.4.2.jre8.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,822] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mchange-commons-java-0.2.19.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,834] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mchange-commons-java-0.2.19.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,848] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/caffeine-2.9.3.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,859] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/caffeine-2.9.3.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,871] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jaxb-runtime-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,883] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-runtime-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,895] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jboss-logging-3.5.0.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,907] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jboss-logging-3.5.0.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,919] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.persistence-api-3.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,932] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.persistence-api-3.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,940] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.xml.bind-api-4.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,948] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.xml.bind-api-4.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,956] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.inject-api-2.0.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,963] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.inject-api-2.0.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,971] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mariadb-java-client-3.2.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,979] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mariadb-java-client-3.2.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:51,989] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jna-platform-5.12.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:51,999] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jna-platform-5.12.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,006] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/antlr4-runtime-4.10.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,015] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/antlr4-runtime-4.10.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,022] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jcl-over-slf4j-1.7.36.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,030] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jcl-over-slf4j-1.7.36.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,037] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-commons-annotations-6.0.6.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,049] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-commons-annotations-6.0.6.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,061] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/postgresql-42.6.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,076] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/postgresql-42.6.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,087] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.transaction-api-2.0.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,096] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.transaction-api-2.0.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,107] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-sink-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,117] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-sink-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,129] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-api-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,144] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-api-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,158] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/classmate-1.5.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,167] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/classmate-1.5.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,177] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-connector-jdbc-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,192] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-connector-jdbc-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,201] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,208] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 02:35:52,249] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,260] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jna-5.12.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,270] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jna-5.12.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,280] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-core-6.4.8.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,294] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-core-6.4.8.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,305] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-sync-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,313] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-sync-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,321] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,325] ERROR Failed to discover SourceConnector in /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar: Plugin class has a dependency which is missing or invalid (org.apache.kafka.connect.runtime.isolation.PluginScanner:139)
java.util.ServiceConfigurationError: org.apache.kafka.connect.source.SourceConnector: io.debezium.connector.mongodb.MongoDbConnector Unable to get public no-arg constructor
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:586)
	at java.base/java.util.ServiceLoader.getConstructor(ServiceLoader.java:679)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1240)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:177)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:133)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:60)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:84)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.lang.NoClassDefFoundError: com/mongodb/MongoException
	at java.base/java.lang.Class.getDeclaredConstructors0(Native Method)
	at java.base/java.lang.Class.privateGetDeclaredConstructors(Class.java:3373)
	at java.base/java.lang.Class.getConstructor0(Class.java:3578)
	at java.base/java.lang.Class.getConstructor(Class.java:2271)
	at java.base/java.util.ServiceLoader$1.run(ServiceLoader.java:666)
	at java.base/java.util.ServiceLoader$1.run(ServiceLoader.java:663)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)
	at java.base/java.util.ServiceLoader.getConstructor(ServiceLoader.java:674)
	... 15 more
Caused by: java.lang.ClassNotFoundException: com.mongodb.MongoException
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 23 more
[2024-12-17 02:35:52,341] ERROR Failed to discover Transformation in /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar: Plugin class has a dependency which is missing or invalid (org.apache.kafka.connect.runtime.isolation.PluginScanner:139)
java.util.ServiceConfigurationError: org.apache.kafka.connect.transforms.Transformation: io.debezium.connector.mongodb.transforms.ExtractNewDocumentState Unable to get public no-arg constructor
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:586)
	at java.base/java.util.ServiceLoader.getConstructor(ServiceLoader.java:679)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1240)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:177)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:133)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.getTransformationPluginDesc(ServiceLoaderScanner.java:78)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:63)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:84)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.lang.NoClassDefFoundError: org/bson/BsonValue
	at java.base/java.lang.Class.getDeclaredConstructors0(Native Method)
	at java.base/java.lang.Class.privateGetDeclaredConstructors(Class.java:3373)
	at java.base/java.lang.Class.getConstructor0(Class.java:3578)
	at java.base/java.lang.Class.getConstructor(Class.java:2271)
	at java.base/java.util.ServiceLoader$1.run(ServiceLoader.java:666)
	at java.base/java.util.ServiceLoader$1.run(ServiceLoader.java:663)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)
	at java.base/java.util.ServiceLoader.getConstructor(ServiceLoader.java:674)
	... 16 more
Caused by: java.lang.ClassNotFoundException: org.bson.BsonValue
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 24 more
[2024-12-17 02:35:52,344] ERROR Failed to discover Transformation in /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar: Plugin class has a dependency which is missing or invalid (org.apache.kafka.connect.runtime.isolation.PluginScanner:139)
java.util.ServiceConfigurationError: org.apache.kafka.connect.transforms.Transformation: Provider io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter could not be instantiated
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:586)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:813)
	at java.base/java.util.ServiceLoader$ProviderImpl.get(ServiceLoader.java:729)
	at java.base/java.util.ServiceLoader$3.next(ServiceLoader.java:1403)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:177)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.getTransformationPluginDesc(ServiceLoaderScanner.java:78)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:63)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:84)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.lang.NoClassDefFoundError: org/bson/json/JsonWriterSettings
	at io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter.<init>(MongoEventRouter.java:47)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:789)
	... 14 more
Caused by: java.lang.ClassNotFoundException: org.bson.json.JsonWriterSettings
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 21 more
[2024-12-17 02:35:52,360] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,372] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/bson-record-codec-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,386] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/bson-record-codec-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,394] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/bson-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,404] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/bson-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,415] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-core-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,429] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-core-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,440] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-sink-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,450] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-sink-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,460] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-api-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,471] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-api-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,483] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,492] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 02:35:52,556] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,565] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:52,586] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:52,591] INFO Scanning plugins with ServiceLoaderScanner took 2571 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:71)
[2024-12-17 02:35:52,600] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:53,248] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:53,257] INFO Loading plugin from: /opt/kafka/plugins/hibernate-core-6.4.1.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:54,400] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/hibernate-core-6.4.1.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:54,409] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:56,573] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:56,590] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/waffle-jna-3.2.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:56,598] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/waffle-jna-3.2.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:56,605] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jaxb-core-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:56,622] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-core-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:56,631] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/txw2-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:56,639] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/txw2-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:56,646] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/ojdbc11-21.15.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:56,953] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/ojdbc11-21.15.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:56,962] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/c3p0-0.9.5.5.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,006] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/c3p0-0.9.5.5.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,015] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/angus-activation-2.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,019] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/angus-activation-2.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,024] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jandex-3.1.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,045] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jandex-3.1.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,057] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-c3p0-6.4.8.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,068] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-c3p0-6.4.8.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,079] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mysql-connector-j-9.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,214] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mysql-connector-j-9.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,221] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/error_prone_annotations-2.10.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,224] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/error_prone_annotations-2.10.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,230] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.activation-api-2.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,236] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.activation-api-2.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,241] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/byte-buddy-1.14.11.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,475] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/byte-buddy-1.14.11.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,481] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/istack-commons-runtime-4.1.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,484] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/istack-commons-runtime-4.1.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,489] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mssql-jdbc-12.4.2.jre8.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,570] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mssql-jdbc-12.4.2.jre8.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,580] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mchange-commons-java-0.2.19.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,619] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mchange-commons-java-0.2.19.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,625] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/caffeine-2.9.3.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,670] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/caffeine-2.9.3.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,678] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jaxb-runtime-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,728] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-runtime-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,734] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jboss-logging-3.5.0.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,739] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jboss-logging-3.5.0.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,744] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.persistence-api-3.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,753] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.persistence-api-3.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,768] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.xml.bind-api-4.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,776] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.xml.bind-api-4.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,782] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.inject-api-2.0.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,783] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.inject-api-2.0.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,788] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mariadb-java-client-3.2.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,821] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mariadb-java-client-3.2.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,827] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jna-platform-5.12.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,905] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jna-platform-5.12.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,911] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/antlr4-runtime-4.10.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,932] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/antlr4-runtime-4.10.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,937] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jcl-over-slf4j-1.7.36.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,941] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jcl-over-slf4j-1.7.36.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,946] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-commons-annotations-6.0.6.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:57,952] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-commons-annotations-6.0.6.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:57,957] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/postgresql-42.6.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:58,006] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/postgresql-42.6.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:58,012] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.transaction-api-2.0.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:58,015] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.transaction-api-2.0.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:58,021] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-sink-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:58,034] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-sink-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:58,040] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-api-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:58,045] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-api-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:58,051] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/classmate-1.5.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:58,057] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/classmate-1.5.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:58,062] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-connector-jdbc-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:58,077] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-connector-jdbc-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:58,083] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:58,164] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:58,171] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jna-5.12.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:58,185] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jna-5.12.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:58,190] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-core-6.4.8.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:58,965] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-core-6.4.8.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:58,973] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-sync-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:58,986] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-sync-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:58,992] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:59,029] ERROR Failed to discover SourceConnector in /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar: Unable to instantiate MongoDbConnector: Plugin class has a dependency which is missing or invalid (org.apache.kafka.connect.runtime.isolation.ReflectionScanner:139)
java.lang.NoClassDefFoundError: com/mongodb/MongoException
	at java.base/java.lang.Class.getDeclaredConstructors0(Native Method)
	at java.base/java.lang.Class.privateGetDeclaredConstructors(Class.java:3373)
	at java.base/java.lang.Class.getConstructor0(Class.java:3578)
	at java.base/java.lang.Class.getDeclaredConstructor(Class.java:2754)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.versionFor(ReflectionScanner.java:74)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.getPluginDesc(ReflectionScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.scanPlugins(ReflectionScanner.java:89)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:92)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.lang.ClassNotFoundException: com.mongodb.MongoException
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 15 more
[2024-12-17 02:35:59,033] ERROR Failed to discover Transformation in /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar: Unable to instantiate MongoEventRouter: Failed to invoke plugin constructor (org.apache.kafka.connect.runtime.isolation.ReflectionScanner:139)
java.lang.reflect.InvocationTargetException
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.versionFor(ReflectionScanner.java:74)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.getPluginDesc(ReflectionScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.getTransformationPluginDesc(ReflectionScanner.java:107)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.scanPlugins(ReflectionScanner.java:92)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:92)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.lang.NoClassDefFoundError: org/bson/json/JsonWriterSettings
	at io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter.<init>(MongoEventRouter.java:47)
	... 17 more
Caused by: java.lang.ClassNotFoundException: org.bson.json.JsonWriterSettings
	... 18 more
[2024-12-17 02:35:59,036] ERROR Failed to discover Transformation in /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar: Unable to instantiate ExtractNewDocumentState: Plugin class has a dependency which is missing or invalid (org.apache.kafka.connect.runtime.isolation.ReflectionScanner:139)
java.lang.NoClassDefFoundError: org/bson/BsonValue
	at java.base/java.lang.Class.getDeclaredConstructors0(Native Method)
	at java.base/java.lang.Class.privateGetDeclaredConstructors(Class.java:3373)
	at java.base/java.lang.Class.getConstructor0(Class.java:3578)
	at java.base/java.lang.Class.getDeclaredConstructor(Class.java:2754)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.versionFor(ReflectionScanner.java:74)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.getPluginDesc(ReflectionScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.getTransformationPluginDesc(ReflectionScanner.java:107)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.scanPlugins(ReflectionScanner.java:92)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:92)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.lang.ClassNotFoundException: org.bson.BsonValue
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 16 more
[2024-12-17 02:35:59,041] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:59,047] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/bson-record-codec-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:59,050] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/bson-record-codec-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:59,056] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/bson-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:59,089] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/bson-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:59,095] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-core-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:59,213] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-core-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:59,219] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-sink-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:59,223] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-sink-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:59,231] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-api-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:59,236] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-api-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:59,246] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:35:59,455] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:35:59,465] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:36:03,549] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:36:03,562] INFO Scanning plugins with ReflectionScanner took 10962 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:71)
[2024-12-17 02:36:03,594] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/opt/kafka/plugins/debezium-connector-mongodb/	io.debezium.connector.mongodb.MongoDbSinkConnector	sink	3.0.4.Final
file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar	io.debezium.connector.mongodb.MongoDbSinkConnector	sink	3.0.4.Final
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:123)
[2024-12-17 02:36:03,596] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,596] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,596] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,596] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,597] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,597] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,597] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,597] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,598] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,598] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,598] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,598] INFO Added plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,599] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,600] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,600] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,601] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,601] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,601] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,601] INFO Added plugin 'io.debezium.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,602] INFO Added plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,602] INFO Added plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,602] INFO Added plugin 'io.debezium.connector.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,602] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,603] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,604] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,605] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,605] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,605] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,605] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,606] INFO Added plugin 'io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,606] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,606] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,607] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,607] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,607] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,607] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,608] INFO Added plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,608] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,608] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,611] INFO Added plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,612] INFO Added plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,612] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,612] INFO Added plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,613] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,613] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,613] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,613] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,614] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,614] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,614] INFO Added plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,615] INFO Added plugin 'io.debezium.connector.jdbc.transforms.ConvertCloudEventToSaveableForm' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,624] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,624] INFO Added plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,624] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,625] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,625] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,625] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,625] INFO Added plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,625] INFO Added plugin 'io.debezium.connector.mongodb.transforms.ExtractNewDocumentState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,625] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,625] INFO Added plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,625] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,625] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,625] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,625] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,625] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,625] INFO Added plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,625] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,625] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:36:03,629] INFO Added alias 'ExtractNewDocumentState' to plugin 'io.debezium.connector.mongodb.transforms.ExtractNewDocumentState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,630] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,630] INFO Added alias 'CloudEventsConverter' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,630] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,630] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,630] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,631] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,631] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,631] INFO Added alias 'HeaderToValue' to plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,631] INFO Added alias 'PartitionRouting' to plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,632] INFO Added alias 'MongoDbSink' to plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,632] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,632] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,632] INFO Added alias 'MongoDbConnector' to plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,632] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,632] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,632] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,632] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,632] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,632] INFO Added alias 'ExtractSchemaToNewRecord' to plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,633] INFO Added alias 'BinaryData' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,633] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,634] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,634] INFO Added alias 'CloudEvents' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,634] INFO Added alias 'TimezoneConverter' to plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,634] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,634] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,634] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,634] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,634] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,634] INFO Added alias 'DebeziumMongoDb' to plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,634] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,634] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,634] INFO Added alias 'DebeziumMongoDbConnectRestExtension' to plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,634] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,634] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,634] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,634] INFO Added alias 'ExtractChangedRecordState' to plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,634] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,634] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,635] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,635] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,635] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,635] INFO Added alias 'JdbcSinkConnector' to plugin 'io.debezium.connector.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,635] INFO Added alias 'JdbcSink' to plugin 'io.debezium.connector.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,635] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,635] INFO Added alias 'MongoDbSinkConnector' to plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,635] INFO Added alias 'MongoDb' to plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,635] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,635] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,635] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,635] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,635] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,635] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,635] INFO Added alias 'SchemaChangeEventFilter' to plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,635] INFO Added alias 'ConvertCloudEventToSaveableForm' to plugin 'io.debezium.connector.jdbc.transforms.ConvertCloudEventToSaveableForm' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,636] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,636] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,636] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,636] INFO Added alias 'ActivateTracingSpan' to plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,636] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,636] INFO Added alias 'BinaryDataConverter' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,636] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,636] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,636] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,636] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,636] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,637] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,637] INFO Added alias 'MongoEventRouter' to plugin 'io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,637] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,637] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:36:03,677] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = mysql-sink-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [HTTP://0.0.0.0:8083]
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [/opt/kafka/plugins, /opt/kafka/plugins/debezium-connector-jdbc, /opt/kafka/plugins/debezium-connector-mongodb]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = 172.30.2.207
	rest.advertised.listener = null
	rest.advertised.port = 8083
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:371)
[2024-12-17 02:36:03,678] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:281)
[2024-12-17 02:36:03,681] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:371)
[2024-12-17 02:36:03,795] INFO These configurations '[config.storage.topic, listeners, rest.advertised.host.name, status.storage.topic, group.id, rest.advertised.port, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2024-12-17 02:36:03,796] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:03,796] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:03,796] INFO Kafka startTimeMs: 1734377763795 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:04,310] INFO Kafka cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.connect.runtime.WorkerConfig:298)
[2024-12-17 02:36:04,311] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:36:04,318] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:36:04,318] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:36:04,319] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:36:04,325] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [HTTP://0.0.0.0:8083]
	response.http.headers.config = 
	rest.advertised.host.name = 172.30.2.207
	rest.advertised.listener = null
	rest.advertised.port = 8083
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:371)
[2024-12-17 02:36:04,338] INFO Logging initialized @15407ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2024-12-17 02:36:04,386] INFO Added connector for HTTP://0.0.0.0:8083 (org.apache.kafka.connect.runtime.rest.RestServer:125)
[2024-12-17 02:36:04,386] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:196)
[2024-12-17 02:36:04,416] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 17.0.13+11-Ubuntu-2ubuntu122.04 (org.eclipse.jetty.server.Server:375)
[2024-12-17 02:36:04,444] INFO Started http_0.0.0.08083@1a912cc7{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2024-12-17 02:36:04,444] INFO Started @15513ms (org.eclipse.jetty.server.Server:415)
[2024-12-17 02:36:04,465] INFO Advertised URI: http://172.30.2.207:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2024-12-17 02:36:04,466] INFO REST server listening at http://0.0.0.0:8083/, advertising URL http://172.30.2.207:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:216)
[2024-12-17 02:36:04,466] INFO Advertised URI: http://172.30.2.207:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2024-12-17 02:36:04,466] INFO REST admin endpoints at http://172.30.2.207:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2024-12-17 02:36:04,467] INFO Advertised URI: http://172.30.2.207:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2024-12-17 02:36:04,467] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:45)
[2024-12-17 02:36:04,473] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:36:04,490] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:04,490] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:04,491] INFO Kafka startTimeMs: 1734377764490 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:04,498] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:36:04,499] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:36:04,517] INFO Advertised URI: http://172.30.2.207:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2024-12-17 02:36:04,549] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:04,549] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:04,549] INFO Kafka startTimeMs: 1734377764549 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:04,554] INFO Kafka Connect worker initialization took 14593ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2024-12-17 02:36:04,554] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:67)
[2024-12-17 02:36:04,557] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2024-12-17 02:36:04,565] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:375)
[2024-12-17 02:36:04,569] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:233)
[2024-12-17 02:36:04,573] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:232)
[2024-12-17 02:36:04,573] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:254)
[2024-12-17 02:36:04,574] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = mysql-sink-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:371)
[2024-12-17 02:36:04,589] INFO These configurations '[config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, group.id, rest.advertised.port, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2024-12-17 02:36:04,596] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:04,596] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:04,596] INFO Kafka startTimeMs: 1734377764590 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:04,646] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:238)
[2024-12-17 02:36:04,664] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = mysql-sink-cluster-offsets
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-17 02:36:04,751] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:36:04,828] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2024-12-17 02:36:04,832] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2024-12-17 02:36:04,837] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2024-12-17 02:36:04,868] INFO These configurations '[group.id, rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-17 02:36:04,869] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:04,869] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:04,869] INFO Kafka startTimeMs: 1734377764869 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:04,878] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = mysql-sink-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-sink-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2024-12-17 02:36:04,913] INFO [Producer clientId=mysql-sink-cluster-offsets] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:36:04,919] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:36:04,991] INFO These configurations '[rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2024-12-17 02:36:04,991] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:04,992] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:04,992] INFO Kafka startTimeMs: 1734377764991 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:05,003] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:36:05,017] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:579)
[2024-12-17 02:36:05,020] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,021] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,021] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,022] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,022] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,022] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,022] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,023] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,023] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,023] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,024] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,024] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,024] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,024] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,025] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,025] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,028] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,029] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,032] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,032] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,033] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,033] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,033] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,034] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,034] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,077] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,078] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,078] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,078] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,079] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,079] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,079] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,079] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,080] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,080] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,080] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,081] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,081] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,081] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,082] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,082] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,082] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,082] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,083] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,083] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,083] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,084] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,084] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,084] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,085] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,212] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:311)
[2024-12-17 02:36:05,212] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:313)
[2024-12-17 02:36:05,212] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:249)
[2024-12-17 02:36:05,214] INFO Worker started (org.apache.kafka.connect.runtime.Worker:243)
[2024-12-17 02:36:05,214] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:254)
[2024-12-17 02:36:05,223] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = mysql-sink-cluster-statuses
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-17 02:36:05,228] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:36:05,246] INFO These configurations '[group.id, rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-17 02:36:05,247] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:05,247] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:05,247] INFO Kafka startTimeMs: 1734377765247 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:05,249] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = mysql-sink-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-sink-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2024-12-17 02:36:05,256] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:36:05,262] INFO These configurations '[rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2024-12-17 02:36:05,264] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:05,264] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:05,265] INFO Kafka startTimeMs: 1734377765264 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:05,265] INFO [Producer clientId=mysql-sink-cluster-statuses] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:36:05,274] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:36:05,278] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:579)
[2024-12-17 02:36:05,278] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,280] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,281] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,281] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,281] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,305] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,306] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,306] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,306] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,306] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,512] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:311)
[2024-12-17 02:36:05,512] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:313)
[2024-12-17 02:36:05,515] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:378)
[2024-12-17 02:36:05,515] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:254)
[2024-12-17 02:36:05,525] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = mysql-sink-cluster-configs
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-17 02:36:05,532] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:36:05,543] INFO These configurations '[group.id, rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-17 02:36:05,544] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:05,544] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:05,544] INFO Kafka startTimeMs: 1734377765544 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:05,545] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = mysql-sink-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-sink-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2024-12-17 02:36:05,552] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:36:05,563] INFO These configurations '[rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2024-12-17 02:36:05,566] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:05,567] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:05,568] INFO Kafka startTimeMs: 1734377765566 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:05,576] INFO [Producer clientId=mysql-sink-cluster-configs] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:36:05,579] INFO [Consumer clientId=mysql-sink-cluster-configs, groupId=mysql-sink-cluster] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:36:05,581] INFO [Consumer clientId=mysql-sink-cluster-configs, groupId=mysql-sink-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:579)
[2024-12-17 02:36:05,584] INFO [Consumer clientId=mysql-sink-cluster-configs, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:36:05,597] INFO [Consumer clientId=mysql-sink-cluster-configs, groupId=mysql-sink-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:36:05,610] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,611] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,611] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,612] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,620] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,622] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,622] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,623] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,624] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,624] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,625] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,625] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,626] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,627] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,627] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,627] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,628] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,628] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,629] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,631] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,632] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,632] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,633] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,635] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,636] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,636] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,638] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,639] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,640] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,640] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,641] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,644] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,644] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,645] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,646] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,647] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,647] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,648] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,649] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,649] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,650] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,651] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,651] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,652] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,652] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,653] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,657] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,660] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,661] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,661] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,662] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,662] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,662] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,666] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,666] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,667] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,667] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,667] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,668] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,671] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,672] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,673] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,673] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,675] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,675] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,677] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,678] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,681] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,688] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,688] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,689] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,690] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,690] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,691] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,691] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,692] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,697] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,697] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,698] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,699] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,699] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,700] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,700] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,700] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,701] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,702] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,702] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,703] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,703] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,706] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,706] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,707] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,707] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,708] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,708] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,712] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,712] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,713] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,713] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,714] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,714] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,715] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,715] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,717] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,718] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,718] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,718] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,719] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,719] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,720] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,722] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,722] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,722] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,723] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,726] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:36:05,727] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:311)
[2024-12-17 02:36:05,727] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:313)
[2024-12-17 02:36:05,727] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:402)
[2024-12-17 02:36:05,740] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:36:05,741] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 02:36:05,744] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:36:05,745] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:36:05,762] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:36:05,773] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=524, memberId='connect-172.30.2.207:8083-6061cedc-4ca6-4a0d-b3ee-927c48b558ee', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:36:05,810] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=524, memberId='connect-172.30.2.207:8083-6061cedc-4ca6-4a0d-b3ee-927c48b558ee', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:36:05,810] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 524 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-6061cedc-4ca6-4a0d-b3ee-927c48b558ee', leaderUrl='http://172.30.2.207:8083/', offset=834, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:36:05,812] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:387)
[2024-12-17 02:36:05,812] WARN [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1811)
[2024-12-17 02:36:05,812] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Current config state offset -1 is behind group assignment 834, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1884)
[2024-12-17 02:36:05,817] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 834 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1911)
[2024-12-17 02:36:05,817] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 834 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:36:05,825] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connector mongodb-source-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 02:36:05,827] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 02:36:05,830] INFO Started o.e.j.s.ServletContextHandler@46ccdd87{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2024-12-17 02:36:05,830] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:303)
[2024-12-17 02:36:05,830] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:77)
[2024-12-17 02:36:05,834] INFO [mongodb-source-connector|worker] Creating connector mongodb-source-connector of type io.debezium.connector.mongodb.MongoDbConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 02:36:05,838] INFO [mongodb-source-connector|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-17 02:36:05,843] INFO [mongodb-source-connector|task-0] Creating task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 02:36:05,845] INFO [mongodb-source-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 02:36:05,848] INFO [mongodb-source-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:36:05,853] INFO [mongodb-source-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:36:05,859] INFO [mongodb-source-connector|worker] Instantiated connector mongodb-source-connector with version 3.0.4.Final of type class io.debezium.connector.mongodb.MongoDbConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 02:36:05,860] INFO [mongodb-source-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.MongoDbConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:371)
[2024-12-17 02:36:05,864] INFO [mongodb-source-connector|task-0] Instantiated task mongodb-source-connector-0 with version 3.0.4.Final of type io.debezium.connector.mongodb.MongoDbConnectorTask (org.apache.kafka.connect.runtime.Worker:665)
[2024-12-17 02:36:05,864] INFO [mongodb-source-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:36:05,865] INFO [mongodb-source-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:36:05,865] INFO [mongodb-source-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-source-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:680)
[2024-12-17 02:36:05,865] INFO [mongodb-source-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-source-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:686)
[2024-12-17 02:36:05,865] INFO [mongodb-source-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mongodb-source-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:691)
[2024-12-17 02:36:05,868] INFO [mongodb-source-connector|worker] Finished creating connector mongodb-source-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 02:36:05,874] WARN [mongodb-source-connector|task-0] The deleted record handling configs "drop.tombstones" and "delete.handling.mode" have been deprecated, please use "delete.tombstone.handling.mode" instead. (io.debezium.transforms.AbstractExtractNewRecordState:110)
[2024-12-17 02:36:05,892] WARN [mongodb-source-connector|task-0] Configuration key whitelist is deprecated and may be removed in the future.  Please update your configuration to use include instead. (org.apache.kafka.common.utils.ConfigUtils:114)
[2024-12-17 02:36:05,894] INFO [mongodb-source-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{io.debezium.connector.mongodb.transforms.ExtractNewDocumentState, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.TimestampConverter$Value} (org.apache.kafka.connect.runtime.Worker:1795)
[2024-12-17 02:36:05,895] INFO [mongodb-source-connector|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-17 02:36:05,900] INFO [mongodb-source-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:36:05,906] INFO [mongodb-source-connector|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-mongodb-source-connector-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-17 02:36:05,917] INFO [mongodb-source-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:36:05,920] INFO [mongodb-source-connector|worker] Successfully started MongoDB connector (io.debezium.connector.mongodb.MongoDbConnector:67)
[2024-12-17 02:36:05,942] INFO [mongodb-source-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-17 02:36:05,942] INFO [mongodb-source-connector|task-0] Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:36:05,942] INFO [mongodb-source-connector|task-0] Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:36:05,942] INFO [mongodb-source-connector|task-0] Kafka startTimeMs: 1734377765942 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:36:05,958] INFO [mongodb-source-connector|task-0] [Producer clientId=connector-producer-mongodb-source-connector-0] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:36:05,968] INFO [mongodb-source-connector|task-0] Starting MongoDbConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:245)
[2024-12-17 02:36:05,970] INFO [mongodb-source-connector|task-0]    connector.class = io.debezium.connector.mongodb.MongoDbConnector (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,970] INFO [mongodb-source-connector|task-0]    collection.include.list = test.customers (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,970] INFO [mongodb-source-connector|task-0]    transforms.unwrap.delete.handling.mode = drop (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,970] INFO [mongodb-source-connector|task-0]    transforms.unwrap.array.encoding = array (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,970] INFO [mongodb-source-connector|task-0]    mongodb.connection.string = ******** (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,970] INFO [mongodb-source-connector|task-0]    tasks.max = 1 (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,970] INFO [mongodb-source-connector|task-0]    transforms = unwrap,extractNew,convertDate (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,970] INFO [mongodb-source-connector|task-0]    transforms.unwrap.add.source.fields = db,collection (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,970] INFO [mongodb-source-connector|task-0]    topic.prefix = fullfillment (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,970] INFO [mongodb-source-connector|task-0]    transforms.convertDate.format = yyyy-MM-dd HH:mm:ss (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,970] INFO [mongodb-source-connector|task-0]    mongodb.server.selection.timeout.ms = 10000 (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,971] INFO [mongodb-source-connector|task-0]    transforms.unwrap.drop.tombstones = false (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,971] INFO [mongodb-source-connector|task-0]    transforms.unwrap.type = io.debezium.connector.mongodb.transforms.ExtractNewDocumentState (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,971] INFO [mongodb-source-connector|task-0]    value.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,971] INFO [mongodb-source-connector|task-0]    mongodb.connect.timeout.ms = 10000 (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,971] INFO [mongodb-source-connector|task-0]    mongodb.auth.source = admin (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,971] INFO [mongodb-source-connector|task-0]    key.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,971] INFO [mongodb-source-connector|task-0]    transforms.convertDate.type = org.apache.kafka.connect.transforms.TimestampConverter$Value (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,971] INFO [mongodb-source-connector|task-0]    transforms.extractNew.type = org.apache.kafka.connect.transforms.ReplaceField$Value (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,971] INFO [mongodb-source-connector|task-0]    key.converter.schemas.enable = true (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,971] INFO [mongodb-source-connector|task-0]    transforms.extractNew.whitelist = _id,name,email,age,createdAt (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,971] INFO [mongodb-source-connector|task-0]    task.class = io.debezium.connector.mongodb.MongoDbConnectorTask (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,971] INFO [mongodb-source-connector|task-0]    transforms.convertDate.field = createdAt (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,971] INFO [mongodb-source-connector|task-0]    value.converter.schemas.enable = true (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,971] INFO [mongodb-source-connector|task-0]    name = mongodb-source-connector (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,971] INFO [mongodb-source-connector|task-0]    transforms.convertDate.target.type = string (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,971] INFO [mongodb-source-connector|task-0]    database.include.list = test (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,971] INFO [mongodb-source-connector|task-0]    snapshot.mode = initial (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,971] INFO [mongodb-source-connector|task-0]    transforms.unwrap.operation.header = true (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:36:05,975] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:05,976] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:36:05,979] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-17 02:36:05,980] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:36:05,995] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:06,000] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:06,003] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:06,010] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:06,014] INFO [mongodb-source-connector|task-0] Loading the custom topic naming strategy plugin: io.debezium.schema.DefaultTopicNamingStrategy (io.debezium.config.CommonConnectorConfig:1401)
[2024-12-17 02:36:06,015] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:06,017] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:06,021] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:06,188] INFO [mongodb-source-connector|task-0] Found previous partition offset MongoDbPartition [sourcePartition={server_id=fullfillment}]: {sec=1734365014, ord=1, resume_token=zQAAAAJfZGF0YQC9AAAAODI2NzYwNEY1NjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNEY1NjQ5NkY2QjQ1OTk5NjQwMzcwMDAwMDQAAA==} (io.debezium.connector.common.BaseSourceTask:527)
[2024-12-17 02:36:06,206] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = fullfillment named = SignalProcessor (io.debezium.util.Threads:270)
[2024-12-17 02:36:06,228] WARN [mongodb-source-connector|task-0] Found a not connector specific implementation io.debezium.snapshot.lock.NoLockingSupport for lock mode no_locking_support (io.debezium.snapshot.SnapshotLockProvider:82)
[2024-12-17 02:36:06,249] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:06,251] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:06,254] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:06,257] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:36:06,259] INFO [mongodb-source-connector|task-0] Found existing offset for at {sec=1734365014, ord=1, resume_token=zQAAAAJfZGF0YQC9AAAAODI2NzYwNEY1NjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNEY1NjQ5NkY2QjQ1OTk5NjQwMzcwMDAwMDQAAA==} (io.debezium.connector.mongodb.connection.MongoDbConnection:202)
[2024-12-17 02:36:06,314] INFO [mongodb-source-connector|task-0] Adding discovered server 172.30.2.147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:06,417] INFO [mongodb-source-connector|task-0] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.11.0"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-125-generic"}, "platform": "Java/Ubuntu/17.0.13+11-Ubuntu-2ubuntu122.04"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@14fd801c, com.mongodb.Jep395RecordCodecProvider@62829206, com.mongodb.KotlinCodecProvider@744a1cbc]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[172.30.2.147:27017], srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='rs0', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='10000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=javax.net.ssl.SSLContext@6938280e}, applicationName='null', compressorList=[], uuidRepresentation=STANDARD, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null} (org.mongodb.driver.client:71)
[2024-12-17 02:36:06,459] INFO [mongodb-source-connector|task-0] Effective change stream pipeline: [{"$replaceRoot": {"newRoot": {"event": "$$ROOT", "namespace": {"$concat": ["$ns.db", ".", "$ns.coll"]}}}}, {"$match": {"$and": [{"$and": [{"event.ns.db": {"$regularExpression": {"pattern": "test", "options": "i"}}}, {"namespace": {"$regularExpression": {"pattern": "test.customers", "options": "i"}}}]}, {"event.operationType": {"$in": ["insert", "update", "replace", "delete"]}}]}}, {"$replaceRoot": {"newRoot": "$event"}}] (io.debezium.connector.mongodb.ChangeStreamPipelineFactory:56)
[2024-12-17 02:36:06,467] INFO [mongodb-source-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=172.30.2.147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=27313754, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Tue Dec 17 02:35:59 ICT 2024, lastUpdateTimeNanos=84577294243824} (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:06,483] INFO [mongodb-source-connector|task-0] Adding discovered server linux-ip-147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:06,488] INFO [mongodb-source-connector|task-0] Server 172.30.2.147:27017 is no longer a member of the replica set.  Removing from client view of cluster. (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:06,490] INFO [mongodb-source-connector|task-0] Discovered replica set primary 172.30.2.147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:06,492] INFO [mongodb-source-connector|task-0] Exception in monitor thread while connecting to server linux-ip-147:27017 (org.mongodb.driver.cluster:76)
com.mongodb.MongoSocketException: linux-ip-147: Temporary failure in name resolution
	at com.mongodb.ServerAddress.getSocketAddresses(ServerAddress.java:221)
	at com.mongodb.internal.connection.ServerAddressWithResolver.getSocketAddresses(ServerAddressWithResolver.java:68)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:78)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:211)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.lookupServerDescription(DefaultServerMonitor.java:196)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:156)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.net.UnknownHostException: linux-ip-147: Temporary failure in name resolution
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.ServerAddress.getSocketAddresses(ServerAddress.java:213)
	... 7 more
[2024-12-17 02:36:06,549] INFO [mongodb-source-connector|task-0] No server chosen by ReadPreferenceServerSelector{readPreference=primary} from cluster description ClusterDescription{type=REPLICA_SET, connectionMode=MULTIPLE, serverDescriptions=[ServerDescription{address=linux-ip-147:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: linux-ip-147: Temporary failure in name resolution}, caused by {java.net.UnknownHostException: linux-ip-147: Temporary failure in name resolution}}]}. Waiting for 10000 ms before timing out (org.mongodb.driver.cluster:71)
[2024-12-17 02:36:06,996] INFO [mongodb-source-connector|task-0] Exception in monitor thread while connecting to server linux-ip-147:27017 (org.mongodb.driver.cluster:76)
com.mongodb.MongoSocketException: linux-ip-147
	at com.mongodb.ServerAddress.getSocketAddresses(ServerAddress.java:221)
	at com.mongodb.internal.connection.ServerAddressWithResolver.getSocketAddresses(ServerAddressWithResolver.java:68)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:78)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:211)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.lookupServerDescription(DefaultServerMonitor.java:196)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:156)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.net.UnknownHostException: linux-ip-147
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.ServerAddress.getSocketAddresses(ServerAddress.java:213)
	... 7 more
[2024-12-17 02:36:15,969] INFO [mongodb-source-connector|task-0|offsets] Couldn't commit processed log positions with the source database due to a concurrent connector shutdown or restart (io.debezium.connector.common.BaseSourceTask:499)
[2024-12-17 02:36:16,553] ERROR [mongodb-source-connector|task-0] Error while attempting to Checking change stream: Timed out after 10000 ms while waiting for a server that matches ReadPreferenceServerSelector{readPreference=primary}. Client view of cluster state is {type=REPLICA_SET, servers=[{address=linux-ip-147:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: linux-ip-147}, caused by {java.net.UnknownHostException: linux-ip-147}}] (io.debezium.connector.mongodb.connection.MongoDbConnections:52)
com.mongodb.MongoTimeoutException: Timed out after 10000 ms while waiting for a server that matches ReadPreferenceServerSelector{readPreference=primary}. Client view of cluster state is {type=REPLICA_SET, servers=[{address=linux-ip-147:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: linux-ip-147}, caused by {java.net.UnknownHostException: linux-ip-147}}]
	at com.mongodb.internal.connection.BaseCluster.createTimeoutException(BaseCluster.java:380)
	at com.mongodb.internal.connection.BaseCluster.selectServer(BaseCluster.java:125)
	at com.mongodb.internal.connection.AbstractMultiServerCluster.selectServer(AbstractMultiServerCluster.java:54)
	at com.mongodb.internal.binding.ClusterBinding.getReadConnectionSource(ClusterBinding.java:116)
	at com.mongodb.client.internal.ClientSessionBinding.getConnectionSource(ClientSessionBinding.java:128)
	at com.mongodb.client.internal.ClientSessionBinding.getReadConnectionSource(ClientSessionBinding.java:92)
	at com.mongodb.internal.operation.SyncOperationHelper.withReadConnectionSource(SyncOperationHelper.java:97)
	at com.mongodb.internal.operation.ChangeStreamOperation.execute(ChangeStreamOperation.java:185)
	at com.mongodb.internal.operation.ChangeStreamOperation.execute(ChangeStreamOperation.java:54)
	at com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.execute(MongoClientDelegate.java:153)
	at com.mongodb.client.internal.ChangeStreamIterableImpl.execute(ChangeStreamIterableImpl.java:212)
	at com.mongodb.client.internal.ChangeStreamIterableImpl.cursor(ChangeStreamIterableImpl.java:187)
	at io.debezium.connector.mongodb.connection.MongoDbConnection.lambda$isValidResumeToken$10(MongoDbConnection.java:219)
	at io.debezium.connector.mongodb.connection.MongoDbConnection.execute(MongoDbConnection.java:105)
	at io.debezium.connector.mongodb.connection.MongoDbConnection.isValidResumeToken(MongoDbConnection.java:215)
	at io.debezium.connector.mongodb.connection.MongoDbConnection.validateLogPosition(MongoDbConnection.java:205)
	at io.debezium.connector.mongodb.MongoDbConnectorTask.validate(MongoDbConnectorTask.java:292)
	at io.debezium.connector.mongodb.MongoDbConnectorTask.start(MongoDbConnectorTask.java:137)
	at io.debezium.connector.common.BaseSourceTask.start(BaseSourceTask.java:251)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.initializeAndStart(AbstractWorkerSourceTask.java:279)
	at org.apache.kafka.connect.runtime.WorkerTask.doStart(WorkerTask.java:176)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:281)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:79)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:238)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-17 02:36:16,557] ERROR [mongodb-source-connector|task-0] WorkerSourceTask{id=mongodb-source-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:234)
io.debezium.DebeziumException: Error while attempting to Checking change stream
	at io.debezium.connector.mongodb.connection.MongoDbConnections.lambda$eventSourcingErrorHandler$1(MongoDbConnections.java:53)
	at io.debezium.connector.mongodb.connection.MongoDbConnection.execute(MongoDbConnection.java:111)
	at io.debezium.connector.mongodb.connection.MongoDbConnection.isValidResumeToken(MongoDbConnection.java:215)
	at io.debezium.connector.mongodb.connection.MongoDbConnection.validateLogPosition(MongoDbConnection.java:205)
	at io.debezium.connector.mongodb.MongoDbConnectorTask.validate(MongoDbConnectorTask.java:292)
	at io.debezium.connector.mongodb.MongoDbConnectorTask.start(MongoDbConnectorTask.java:137)
	at io.debezium.connector.common.BaseSourceTask.start(BaseSourceTask.java:251)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.initializeAndStart(AbstractWorkerSourceTask.java:279)
	at org.apache.kafka.connect.runtime.WorkerTask.doStart(WorkerTask.java:176)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:281)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:79)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:238)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoTimeoutException: Timed out after 10000 ms while waiting for a server that matches ReadPreferenceServerSelector{readPreference=primary}. Client view of cluster state is {type=REPLICA_SET, servers=[{address=linux-ip-147:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: linux-ip-147}, caused by {java.net.UnknownHostException: linux-ip-147}}]
	at com.mongodb.internal.connection.BaseCluster.createTimeoutException(BaseCluster.java:380)
	at com.mongodb.internal.connection.BaseCluster.selectServer(BaseCluster.java:125)
	at com.mongodb.internal.connection.AbstractMultiServerCluster.selectServer(AbstractMultiServerCluster.java:54)
	at com.mongodb.internal.binding.ClusterBinding.getReadConnectionSource(ClusterBinding.java:116)
	at com.mongodb.client.internal.ClientSessionBinding.getConnectionSource(ClientSessionBinding.java:128)
	at com.mongodb.client.internal.ClientSessionBinding.getReadConnectionSource(ClientSessionBinding.java:92)
	at com.mongodb.internal.operation.SyncOperationHelper.withReadConnectionSource(SyncOperationHelper.java:97)
	at com.mongodb.internal.operation.ChangeStreamOperation.execute(ChangeStreamOperation.java:185)
	at com.mongodb.internal.operation.ChangeStreamOperation.execute(ChangeStreamOperation.java:54)
	at com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.execute(MongoClientDelegate.java:153)
	at com.mongodb.client.internal.ChangeStreamIterableImpl.execute(ChangeStreamIterableImpl.java:212)
	at com.mongodb.client.internal.ChangeStreamIterableImpl.cursor(ChangeStreamIterableImpl.java:187)
	at io.debezium.connector.mongodb.connection.MongoDbConnection.lambda$isValidResumeToken$10(MongoDbConnection.java:219)
	at io.debezium.connector.mongodb.connection.MongoDbConnection.execute(MongoDbConnection.java:105)
	... 16 more
[2024-12-17 02:36:16,559] INFO [mongodb-source-connector|task-0] Stopping down connector (io.debezium.connector.common.BaseSourceTask:432)
[2024-12-17 02:36:16,560] INFO [mongodb-source-connector|task-0] [Producer clientId=connector-producer-mongodb-source-connector-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2024-12-17 02:36:16,589] INFO [mongodb-source-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:36:16,589] INFO [mongodb-source-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:36:16,589] INFO [mongodb-source-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:36:16,589] INFO [mongodb-source-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:36:16,593] INFO [mongodb-source-connector|task-0] App info kafka.producer for connector-producer-mongodb-source-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:39:01,470] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:371)
[2024-12-17 02:39:01,546] INFO 172.30.2.207 - - [16/Dec/2024:19:39:01 +0000] "POST /connectors HTTP/1.1" 400 404 "-" "curl/7.81.0" 439 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 02:40:16,118] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:87)
[2024-12-17 02:40:16,120] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:358)
[2024-12-17 02:40:16,156] INFO Stopped http_0.0.0.08083@1a912cc7{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2024-12-17 02:40:16,158] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2024-12-17 02:40:16,196] INFO Stopped o.e.j.s.ServletContextHandler@46ccdd87{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2024-12-17 02:40:16,197] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:387)
[2024-12-17 02:40:16,197] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:851)
[2024-12-17 02:40:16,198] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:808)
[2024-12-17 02:40:16,198] INFO [mongodb-source-connector|worker] Stopping connector mongodb-source-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 02:40:16,199] INFO [mongodb-source-connector|worker] Scheduled shutdown for WorkerConnector{id=mongodb-source-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 02:40:16,200] INFO [mongodb-source-connector|worker] Stopping MongoDB connector (io.debezium.connector.mongodb.MongoDbConnector:82)
[2024-12-17 02:40:16,200] INFO [mongodb-source-connector|worker] Stopped MongoDB connector (io.debezium.connector.mongodb.MongoDbConnector:86)
[2024-12-17 02:40:16,201] INFO [mongodb-source-connector|worker] Completed shutdown for WorkerConnector{id=mongodb-source-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 02:40:16,204] INFO [mongodb-source-connector|task-0] Stopping task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.Worker:1048)
[2024-12-17 02:40:16,211] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:317)
[2024-12-17 02:40:16,214] INFO [Producer clientId=mysql-sink-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2024-12-17 02:40:16,238] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:40:16,238] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:40:16,239] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:40:16,239] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:40:16,240] INFO App info kafka.producer for mysql-sink-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:40:16,337] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2024-12-17 02:40:16,337] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 02:40:16,673] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:40:16,673] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:40:16,673] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:40:16,673] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:40:16,719] INFO App info kafka.consumer for mysql-sink-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:40:16,721] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:341)
[2024-12-17 02:40:16,722] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:407)
[2024-12-17 02:40:16,723] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:317)
[2024-12-17 02:40:16,725] INFO [Producer clientId=mysql-sink-cluster-configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2024-12-17 02:40:16,738] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:40:16,739] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:40:16,739] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:40:16,740] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:40:16,741] INFO App info kafka.producer for mysql-sink-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:40:16,742] INFO [Consumer clientId=mysql-sink-cluster-configs, groupId=mysql-sink-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2024-12-17 02:40:16,743] INFO [Consumer clientId=mysql-sink-cluster-configs, groupId=mysql-sink-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 02:40:17,172] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:40:17,174] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:40:17,175] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:40:17,176] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:40:17,193] INFO App info kafka.consumer for mysql-sink-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:40:17,194] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:341)
[2024-12-17 02:40:17,194] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:412)
[2024-12-17 02:40:17,195] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:250)
[2024-12-17 02:40:17,199] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:261)
[2024-12-17 02:40:17,200] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:317)
[2024-12-17 02:40:17,201] INFO [Producer clientId=mysql-sink-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2024-12-17 02:40:17,217] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:40:17,220] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:40:17,221] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:40:17,222] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:40:17,223] INFO App info kafka.producer for mysql-sink-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:40:17,224] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2024-12-17 02:40:17,225] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 02:40:17,678] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:40:17,679] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:40:17,679] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:40:17,680] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:40:17,697] INFO App info kafka.consumer for mysql-sink-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:40:17,697] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:341)
[2024-12-17 02:40:17,697] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:263)
[2024-12-17 02:40:17,697] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:40:17,697] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:40:17,698] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:40:17,698] INFO App info kafka.connect for 172.30.2.207:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:40:17,699] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:271)
[2024-12-17 02:40:17,721] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Member connect-172.30.2.207:8083-6061cedc-4ca6-4a0d-b3ee-927c48b558ee sending LeaveGroup request to coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1174)
[2024-12-17 02:40:17,725] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1056)
[2024-12-17 02:40:17,726] WARN [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1141)
[2024-12-17 02:40:17,727] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:40:17,728] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:40:17,733] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:40:17,738] INFO App info kafka.connect for connect-172.30.2.207:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:40:17,744] INFO App info kafka.admin.client for mysql-sink-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:40:17,748] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:40:17,748] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:40:17,748] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:40:17,749] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:394)
[2024-12-17 02:40:17,751] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:858)
[2024-12-17 02:40:17,752] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:92)
[2024-12-17 02:40:19,991] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2024-12-17 02:40:20,014] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/opt/kafka/bin/../logs, -Dlog4j.configuration=file:/opt/kafka/bin/../config/connect-log4j.properties
	jvm.spec = Ubuntu, OpenJDK 64-Bit Server VM, 17.0.13, 17.0.13+11-Ubuntu-2ubuntu122.04
	jvm.classpath = /opt/kafka/plugins/debezium-connector-jdbc/waffle-jna-3.2.0.jar:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-core-4.0.2.jar:/opt/kafka/plugins/debezium-connector-jdbc/txw2-4.0.2.jar:/opt/kafka/plugins/debezium-connector-jdbc/ojdbc11-21.15.0.0.jar:/opt/kafka/plugins/debezium-connector-jdbc/c3p0-0.9.5.5.jar:/opt/kafka/plugins/debezium-connector-jdbc/angus-activation-2.0.0.jar:/opt/kafka/plugins/debezium-connector-jdbc/jandex-3.1.2.jar:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-c3p0-6.4.8.Final.jar:/opt/kafka/plugins/debezium-connector-jdbc/mysql-connector-j-9.1.0.jar:/opt/kafka/plugins/debezium-connector-jdbc/error_prone_annotations-2.10.0.jar:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.activation-api-2.1.0.jar:/opt/kafka/plugins/debezium-connector-jdbc/byte-buddy-1.14.11.jar:/opt/kafka/plugins/debezium-connector-jdbc/istack-commons-runtime-4.1.1.jar:/opt/kafka/plugins/debezium-connector-jdbc/mssql-jdbc-12.4.2.jre8.jar:/opt/kafka/plugins/debezium-connector-jdbc/mchange-commons-java-0.2.19.jar:/opt/kafka/plugins/debezium-connector-jdbc/caffeine-2.9.3.jar:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-runtime-4.0.2.jar:/opt/kafka/plugins/debezium-connector-jdbc/jboss-logging-3.5.0.Final.jar:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.persistence-api-3.1.0.jar:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.xml.bind-api-4.0.0.jar:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.inject-api-2.0.1.jar:/opt/kafka/plugins/debezium-connector-jdbc/mariadb-java-client-3.2.0.jar:/opt/kafka/plugins/debezium-connector-jdbc/jna-platform-5.12.1.jar:/opt/kafka/plugins/debezium-connector-jdbc/antlr4-runtime-4.10.1.jar:/opt/kafka/plugins/debezium-connector-jdbc/jcl-over-slf4j-1.7.36.jar:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-commons-annotations-6.0.6.Final.jar:/opt/kafka/plugins/debezium-connector-jdbc/postgresql-42.6.1.jar:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.transaction-api-2.0.1.jar:/opt/kafka/plugins/debezium-connector-jdbc/debezium-sink-3.0.4.Final.jar:/opt/kafka/plugins/debezium-connector-jdbc/debezium-api-3.0.4.Final.jar:/opt/kafka/plugins/debezium-connector-jdbc/classmate-1.5.1.jar:/opt/kafka/plugins/debezium-connector-jdbc/debezium-connector-jdbc-3.0.4.Final.jar:/opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar:/opt/kafka/plugins/debezium-connector-jdbc/jna-5.12.1.jar:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-core-6.4.8.Final.jar:/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.12.0.jar:/opt/kafka/bin/../libs/caffeine-2.9.3.jar:/opt/kafka/bin/../libs/commons-beanutils-1.9.4.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-collections-3.2.2.jar:/opt/kafka/bin/../libs/commons-digester-2.1.jar:/opt/kafka/bin/../libs/commons-io-2.14.0.jar:/opt/kafka/bin/../libs/commons-lang3-3.12.0.jar:/opt/kafka/bin/../libs/commons-logging-1.2.jar:/opt/kafka/bin/../libs/commons-validator-1.7.jar:/opt/kafka/bin/../libs/connect-api-3.9.0.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-3.9.0.jar:/opt/kafka/bin/../libs/connect-json-3.9.0.jar:/opt/kafka/bin/../libs/connect-mirror-3.9.0.jar:/opt/kafka/bin/../libs/connect-mirror-client-3.9.0.jar:/opt/kafka/bin/../libs/connect-runtime-3.9.0.jar:/opt/kafka/bin/../libs/connect-transforms-3.9.0.jar:/opt/kafka/bin/../libs/error_prone_annotations-2.10.0.jar:/opt/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/kafka/bin/../libs/jackson-annotations-2.16.2.jar:/opt/kafka/bin/../libs/jackson-core-2.16.2.jar:/opt/kafka/bin/../libs/jackson-databind-2.16.2.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/opt/kafka/bin/../libs/jackson-module-afterburner-2.16.2.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.2.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/opt/kafka/bin/../libs/javassist-3.29.2-GA.jar:/opt/kafka/bin/../libs/javax.activation-api-1.2.0.jar:/opt/kafka/bin/../libs/javax.annotation-api-1.3.2.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.1.jar:/opt/kafka/bin/../libs/jersey-client-2.39.1.jar:/opt/kafka/bin/../libs/jersey-common-2.39.1.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.39.1.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/opt/kafka/bin/../libs/jersey-hk2-2.39.1.jar:/opt/kafka/bin/../libs/jersey-server-2.39.1.jar:/opt/kafka/bin/../libs/jetty-client-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-http-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-io-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-security-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-server-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-util-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/opt/kafka/bin/../libs/jline-3.25.1.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/jose4j-0.9.4.jar:/opt/kafka/bin/../libs/jsr305-3.0.2.jar:/opt/kafka/bin/../libs/kafka-clients-3.9.0.jar:/opt/kafka/bin/../libs/kafka-group-coordinator-3.9.0.jar:/opt/kafka/bin/../libs/kafka-group-coordinator-api-3.9.0.jar:/opt/kafka/bin/../libs/kafka-metadata-3.9.0.jar:/opt/kafka/bin/../libs/kafka-raft-3.9.0.jar:/opt/kafka/bin/../libs/kafka-server-3.9.0.jar:/opt/kafka/bin/../libs/kafka-server-common-3.9.0.jar:/opt/kafka/bin/../libs/kafka-shell-3.9.0.jar:/opt/kafka/bin/../libs/kafka-storage-3.9.0.jar:/opt/kafka/bin/../libs/kafka-storage-api-3.9.0.jar:/opt/kafka/bin/../libs/kafka-streams-3.9.0.jar:/opt/kafka/bin/../libs/kafka-streams-examples-3.9.0.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.13-3.9.0.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-3.9.0.jar:/opt/kafka/bin/../libs/kafka-tools-3.9.0.jar:/opt/kafka/bin/../libs/kafka-tools-api-3.9.0.jar:/opt/kafka/bin/../libs/kafka-transaction-coordinator-3.9.0.jar:/opt/kafka/bin/../libs/kafka_2.13-3.9.0.jar:/opt/kafka/bin/../libs/lz4-java-1.8.0.jar:/opt/kafka/bin/../libs/maven-artifact-3.9.6.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-transport-classes-epoll-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.111.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.111.Final.jar:/opt/kafka/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/pcollections-4.0.1.jar:/opt/kafka/bin/../libs/plexus-utils-3.5.1.jar:/opt/kafka/bin/../libs/protobuf-java-3.25.5.jar:/opt/kafka/bin/../libs/reflections-0.10.2.jar:/opt/kafka/bin/../libs/reload4j-1.2.25.jar:/opt/kafka/bin/../libs/rocksdbjni-7.9.2.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/opt/kafka/bin/../libs/scala-library-2.13.14.jar:/opt/kafka/bin/../libs/scala-logging_2.13-3.9.5.jar:/opt/kafka/bin/../libs/scala-reflect-2.13.14.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.36.jar:/opt/kafka/bin/../libs/slf4j-reload4j-1.7.36.jar:/opt/kafka/bin/../libs/snappy-java-1.1.10.5.jar:/opt/kafka/bin/../libs/swagger-annotations-2.2.8.jar:/opt/kafka/bin/../libs/trogdor-3.9.0.jar:/opt/kafka/bin/../libs/zookeeper-3.8.4.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.8.4.jar:/opt/kafka/bin/../libs/zstd-jni-1.5.6-4.jar
	os.spec = Linux, amd64, 5.15.0-125-generic
	os.vcpus = 2
 (org.apache.kafka.connect.runtime.WorkerInfo:72)
[2024-12-17 02:40:20,016] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2024-12-17 02:40:20,100] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:20,187] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 02:40:20,608] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:20,971] INFO Loading plugin from: /opt/kafka/plugins/hibernate-core-6.4.1.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:20,988] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 02:40:21,057] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/hibernate-core-6.4.1.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,087] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,122] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 02:40:21,216] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,332] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/waffle-jna-3.2.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,349] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/waffle-jna-3.2.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,368] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jaxb-core-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,385] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-core-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,399] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/txw2-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,410] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/txw2-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,427] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/ojdbc11-21.15.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,445] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/ojdbc11-21.15.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,530] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/c3p0-0.9.5.5.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,557] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/c3p0-0.9.5.5.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,577] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/angus-activation-2.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,594] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/angus-activation-2.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,613] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jandex-3.1.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,631] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jandex-3.1.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,655] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-c3p0-6.4.8.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,677] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-c3p0-6.4.8.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,693] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mysql-connector-j-9.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,705] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mysql-connector-j-9.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,723] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/error_prone_annotations-2.10.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,734] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/error_prone_annotations-2.10.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,746] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.activation-api-2.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,758] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.activation-api-2.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,770] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/byte-buddy-1.14.11.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,782] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/byte-buddy-1.14.11.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,796] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/istack-commons-runtime-4.1.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,818] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/istack-commons-runtime-4.1.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,826] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mssql-jdbc-12.4.2.jre8.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,836] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mssql-jdbc-12.4.2.jre8.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,873] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mchange-commons-java-0.2.19.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,883] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mchange-commons-java-0.2.19.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,892] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/caffeine-2.9.3.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,903] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/caffeine-2.9.3.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,914] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jaxb-runtime-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,924] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-runtime-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,936] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jboss-logging-3.5.0.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,947] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jboss-logging-3.5.0.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,958] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.persistence-api-3.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,969] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.persistence-api-3.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:21,980] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.xml.bind-api-4.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:21,990] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.xml.bind-api-4.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,001] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.inject-api-2.0.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,011] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.inject-api-2.0.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,022] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mariadb-java-client-3.2.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,032] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mariadb-java-client-3.2.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,044] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jna-platform-5.12.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,054] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jna-platform-5.12.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,065] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/antlr4-runtime-4.10.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,075] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/antlr4-runtime-4.10.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,085] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jcl-over-slf4j-1.7.36.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,095] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jcl-over-slf4j-1.7.36.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,105] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-commons-annotations-6.0.6.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,114] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-commons-annotations-6.0.6.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,124] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/postgresql-42.6.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,134] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/postgresql-42.6.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,147] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.transaction-api-2.0.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,157] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.transaction-api-2.0.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,166] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-sink-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,176] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-sink-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,187] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-api-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,197] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-api-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,206] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/classmate-1.5.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,216] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/classmate-1.5.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,224] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-connector-jdbc-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,236] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-connector-jdbc-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,243] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,250] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 02:40:22,287] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,294] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jna-5.12.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,301] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jna-5.12.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,311] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-core-6.4.8.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,319] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-core-6.4.8.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,326] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-sync-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,333] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-sync-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,340] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,343] ERROR Failed to discover SourceConnector in /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar: Plugin class has a dependency which is missing or invalid (org.apache.kafka.connect.runtime.isolation.PluginScanner:139)
java.util.ServiceConfigurationError: org.apache.kafka.connect.source.SourceConnector: io.debezium.connector.mongodb.MongoDbConnector Unable to get public no-arg constructor
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:586)
	at java.base/java.util.ServiceLoader.getConstructor(ServiceLoader.java:679)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1240)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:177)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:133)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:60)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:84)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.lang.NoClassDefFoundError: com/mongodb/MongoException
	at java.base/java.lang.Class.getDeclaredConstructors0(Native Method)
	at java.base/java.lang.Class.privateGetDeclaredConstructors(Class.java:3373)
	at java.base/java.lang.Class.getConstructor0(Class.java:3578)
	at java.base/java.lang.Class.getConstructor(Class.java:2271)
	at java.base/java.util.ServiceLoader$1.run(ServiceLoader.java:666)
	at java.base/java.util.ServiceLoader$1.run(ServiceLoader.java:663)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)
	at java.base/java.util.ServiceLoader.getConstructor(ServiceLoader.java:674)
	... 15 more
Caused by: java.lang.ClassNotFoundException: com.mongodb.MongoException
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 23 more
[2024-12-17 02:40:22,355] ERROR Failed to discover Transformation in /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar: Plugin class has a dependency which is missing or invalid (org.apache.kafka.connect.runtime.isolation.PluginScanner:139)
java.util.ServiceConfigurationError: org.apache.kafka.connect.transforms.Transformation: io.debezium.connector.mongodb.transforms.ExtractNewDocumentState Unable to get public no-arg constructor
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:586)
	at java.base/java.util.ServiceLoader.getConstructor(ServiceLoader.java:679)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1240)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1273)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1309)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1393)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:177)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:133)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.getTransformationPluginDesc(ServiceLoaderScanner.java:78)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:63)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:84)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.lang.NoClassDefFoundError: org/bson/BsonValue
	at java.base/java.lang.Class.getDeclaredConstructors0(Native Method)
	at java.base/java.lang.Class.privateGetDeclaredConstructors(Class.java:3373)
	at java.base/java.lang.Class.getConstructor0(Class.java:3578)
	at java.base/java.lang.Class.getConstructor(Class.java:2271)
	at java.base/java.util.ServiceLoader$1.run(ServiceLoader.java:666)
	at java.base/java.util.ServiceLoader$1.run(ServiceLoader.java:663)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:569)
	at java.base/java.util.ServiceLoader.getConstructor(ServiceLoader.java:674)
	... 16 more
Caused by: java.lang.ClassNotFoundException: org.bson.BsonValue
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 24 more
[2024-12-17 02:40:22,362] ERROR Failed to discover Transformation in /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar: Plugin class has a dependency which is missing or invalid (org.apache.kafka.connect.runtime.isolation.PluginScanner:139)
java.util.ServiceConfigurationError: org.apache.kafka.connect.transforms.Transformation: Provider io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter could not be instantiated
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:586)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:813)
	at java.base/java.util.ServiceLoader$ProviderImpl.get(ServiceLoader.java:729)
	at java.base/java.util.ServiceLoader$3.next(ServiceLoader.java:1403)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.handleLinkageError(PluginScanner.java:177)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.getServiceLoaderPluginDesc(PluginScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.getTransformationPluginDesc(ServiceLoaderScanner.java:78)
	at org.apache.kafka.connect.runtime.isolation.ServiceLoaderScanner.scanPlugins(ServiceLoaderScanner.java:63)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:84)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.lang.NoClassDefFoundError: org/bson/json/JsonWriterSettings
	at io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter.<init>(MongoEventRouter.java:47)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at java.base/java.util.ServiceLoader$ProviderImpl.newInstance(ServiceLoader.java:789)
	... 14 more
Caused by: java.lang.ClassNotFoundException: org.bson.json.JsonWriterSettings
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 21 more
[2024-12-17 02:40:22,370] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,377] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/bson-record-codec-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,384] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/bson-record-codec-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,391] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/bson-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,399] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/bson-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,406] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-core-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,413] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-core-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,419] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-sink-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,427] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-sink-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,434] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-api-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,442] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-api-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,449] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,457] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2024-12-17 02:40:22,493] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,499] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:22,507] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:22,513] INFO Scanning plugins with ServiceLoaderScanner took 2415 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:71)
[2024-12-17 02:40:22,515] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:23,038] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:23,045] INFO Loading plugin from: /opt/kafka/plugins/hibernate-core-6.4.1.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:24,337] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/hibernate-core-6.4.1.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:24,347] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:27,616] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:27,634] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/waffle-jna-3.2.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:27,644] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/waffle-jna-3.2.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:27,652] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jaxb-core-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:27,667] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-core-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:27,675] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/txw2-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:27,686] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/txw2-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:27,694] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/ojdbc11-21.15.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:28,133] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/ojdbc11-21.15.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:28,144] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/c3p0-0.9.5.5.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:28,190] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/c3p0-0.9.5.5.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:28,198] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/angus-activation-2.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:28,202] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/angus-activation-2.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:28,208] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jandex-3.1.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:28,233] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jandex-3.1.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:28,240] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-c3p0-6.4.8.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:28,248] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-c3p0-6.4.8.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:28,254] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mysql-connector-j-9.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:28,515] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mysql-connector-j-9.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:28,523] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/error_prone_annotations-2.10.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:28,526] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/error_prone_annotations-2.10.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:28,532] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.activation-api-2.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:28,539] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.activation-api-2.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:28,545] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/byte-buddy-1.14.11.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:28,824] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/byte-buddy-1.14.11.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:28,831] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/istack-commons-runtime-4.1.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:28,836] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/istack-commons-runtime-4.1.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:28,841] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mssql-jdbc-12.4.2.jre8.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:28,942] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mssql-jdbc-12.4.2.jre8.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:28,954] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mchange-commons-java-0.2.19.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,007] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mchange-commons-java-0.2.19.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,014] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/caffeine-2.9.3.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,072] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/caffeine-2.9.3.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,080] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jaxb-runtime-4.0.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,144] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jaxb-runtime-4.0.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,151] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jboss-logging-3.5.0.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,158] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jboss-logging-3.5.0.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,171] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.persistence-api-3.1.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,184] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.persistence-api-3.1.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,196] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.xml.bind-api-4.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,206] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.xml.bind-api-4.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,212] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.inject-api-2.0.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,215] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.inject-api-2.0.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,221] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/mariadb-java-client-3.2.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,256] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/mariadb-java-client-3.2.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,262] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jna-platform-5.12.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,349] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jna-platform-5.12.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,356] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/antlr4-runtime-4.10.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,389] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/antlr4-runtime-4.10.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,397] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jcl-over-slf4j-1.7.36.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,401] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jcl-over-slf4j-1.7.36.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,410] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-commons-annotations-6.0.6.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,419] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-commons-annotations-6.0.6.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,429] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/postgresql-42.6.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,502] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/postgresql-42.6.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,516] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jakarta.transaction-api-2.0.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,521] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jakarta.transaction-api-2.0.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,528] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-sink-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,535] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-sink-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,544] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-api-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,550] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-api-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,566] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/classmate-1.5.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,577] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/classmate-1.5.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,589] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-connector-jdbc-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,612] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-connector-jdbc-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,621] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,747] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/debezium-core-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,756] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/jna-5.12.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:29,777] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/jna-5.12.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:29,789] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-jdbc/hibernate-core-6.4.8.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:30,706] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-jdbc/hibernate-core-6.4.8.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:30,712] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-sync-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:30,724] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-sync-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:30,729] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:30,763] ERROR Failed to discover SourceConnector in /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar: Unable to instantiate MongoDbConnector: Plugin class has a dependency which is missing or invalid (org.apache.kafka.connect.runtime.isolation.ReflectionScanner:139)
java.lang.NoClassDefFoundError: com/mongodb/MongoException
	at java.base/java.lang.Class.getDeclaredConstructors0(Native Method)
	at java.base/java.lang.Class.privateGetDeclaredConstructors(Class.java:3373)
	at java.base/java.lang.Class.getConstructor0(Class.java:3578)
	at java.base/java.lang.Class.getDeclaredConstructor(Class.java:2754)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.versionFor(ReflectionScanner.java:74)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.getPluginDesc(ReflectionScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.scanPlugins(ReflectionScanner.java:89)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:92)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.lang.ClassNotFoundException: com.mongodb.MongoException
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 15 more
[2024-12-17 02:40:30,764] ERROR Failed to discover Transformation in /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar: Unable to instantiate MongoEventRouter: Failed to invoke plugin constructor (org.apache.kafka.connect.runtime.isolation.ReflectionScanner:139)
java.lang.reflect.InvocationTargetException
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:500)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:481)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.versionFor(ReflectionScanner.java:74)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.getPluginDesc(ReflectionScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.getTransformationPluginDesc(ReflectionScanner.java:107)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.scanPlugins(ReflectionScanner.java:92)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:92)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.lang.NoClassDefFoundError: org/bson/json/JsonWriterSettings
	at io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter.<init>(MongoEventRouter.java:47)
	... 17 more
Caused by: java.lang.ClassNotFoundException: org.bson.json.JsonWriterSettings
	... 18 more
[2024-12-17 02:40:30,765] ERROR Failed to discover Transformation in /opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar: Unable to instantiate ExtractNewDocumentState: Plugin class has a dependency which is missing or invalid (org.apache.kafka.connect.runtime.isolation.ReflectionScanner:139)
java.lang.NoClassDefFoundError: org/bson/BsonValue
	at java.base/java.lang.Class.getDeclaredConstructors0(Native Method)
	at java.base/java.lang.Class.privateGetDeclaredConstructors(Class.java:3373)
	at java.base/java.lang.Class.getConstructor0(Class.java:3578)
	at java.base/java.lang.Class.getDeclaredConstructor(Class.java:2754)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.versionFor(ReflectionScanner.java:74)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.getPluginDesc(ReflectionScanner.java:137)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.getTransformationPluginDesc(ReflectionScanner.java:107)
	at org.apache.kafka.connect.runtime.isolation.ReflectionScanner.scanPlugins(ReflectionScanner.java:92)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.scanUrlsAndAddPlugins(PluginScanner.java:80)
	at org.apache.kafka.connect.runtime.isolation.PluginScanner.discoverPlugins(PluginScanner.java:68)
	at org.apache.kafka.connect.runtime.isolation.Plugins.initLoaders(Plugins.java:92)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:76)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:65)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:95)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:112)
Caused by: java.lang.ClassNotFoundException: org.bson.BsonValue
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:592)
	at org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass(PluginClassLoader.java:124)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 16 more
[2024-12-17 02:40:30,767] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:30,781] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/bson-record-codec-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:30,786] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/bson-record-codec-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:30,792] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/bson-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:30,831] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/bson-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:30,837] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-core-4.11.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:30,954] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/mongodb-driver-core-4.11.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:30,967] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-sink-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:30,971] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-sink-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:30,984] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-api-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:30,989] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-api-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:30,996] INFO Loading plugin from: /opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:31,096] INFO Registered loader: PluginClassLoader{pluginLocation=file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-core-3.0.4.Final.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:31,102] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2024-12-17 02:40:35,321] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2024-12-17 02:40:35,330] INFO Scanning plugins with ReflectionScanner took 12815 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:71)
[2024-12-17 02:40:35,336] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/opt/kafka/plugins/debezium-connector-mongodb/	io.debezium.connector.mongodb.MongoDbSinkConnector	sink	3.0.4.Final
file:/opt/kafka/plugins/debezium-connector-mongodb/debezium-connector-mongodb-3.0.4.Final.jar	io.debezium.connector.mongodb.MongoDbSinkConnector	sink	3.0.4.Final
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:123)
[2024-12-17 02:40:35,338] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,339] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,339] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,339] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,340] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,340] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,340] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,340] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,341] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,341] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,341] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,341] INFO Added plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,342] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,342] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,342] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,343] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,343] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,343] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,344] INFO Added plugin 'io.debezium.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,344] INFO Added plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,344] INFO Added plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,352] INFO Added plugin 'io.debezium.connector.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,352] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,352] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,352] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,352] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,352] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,353] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,353] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,353] INFO Added plugin 'io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,353] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,353] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,353] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,353] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,353] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,353] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,355] INFO Added plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,355] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,355] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,355] INFO Added plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,356] INFO Added plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,356] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,356] INFO Added plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,356] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,357] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,357] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,357] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,357] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,357] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,357] INFO Added plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,357] INFO Added plugin 'io.debezium.connector.jdbc.transforms.ConvertCloudEventToSaveableForm' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,357] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,357] INFO Added plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,357] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,357] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,359] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,360] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,360] INFO Added plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,360] INFO Added plugin 'io.debezium.connector.mongodb.transforms.ExtractNewDocumentState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,360] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,361] INFO Added plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,361] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,361] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,361] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,362] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,362] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,362] INFO Added plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,363] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,363] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-12-17 02:40:35,367] INFO Added alias 'ExtractNewDocumentState' to plugin 'io.debezium.connector.mongodb.transforms.ExtractNewDocumentState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,367] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,367] INFO Added alias 'CloudEventsConverter' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,368] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,368] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,369] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,369] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,369] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,369] INFO Added alias 'HeaderToValue' to plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,370] INFO Added alias 'PartitionRouting' to plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,370] INFO Added alias 'MongoDbSink' to plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,370] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,370] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,371] INFO Added alias 'MongoDbConnector' to plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,371] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,371] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,371] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,372] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,372] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,372] INFO Added alias 'ExtractSchemaToNewRecord' to plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,373] INFO Added alias 'BinaryData' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,373] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,373] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,373] INFO Added alias 'CloudEvents' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,374] INFO Added alias 'TimezoneConverter' to plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,374] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,374] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,375] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,375] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,375] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,375] INFO Added alias 'DebeziumMongoDb' to plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,376] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,376] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,376] INFO Added alias 'DebeziumMongoDbConnectRestExtension' to plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,376] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,377] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,377] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,377] INFO Added alias 'ExtractChangedRecordState' to plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,378] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,378] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,378] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,378] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,379] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,379] INFO Added alias 'JdbcSinkConnector' to plugin 'io.debezium.connector.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,379] INFO Added alias 'JdbcSink' to plugin 'io.debezium.connector.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,379] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,380] INFO Added alias 'MongoDbSinkConnector' to plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,380] INFO Added alias 'MongoDb' to plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,380] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,380] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,381] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,381] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,381] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,381] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,382] INFO Added alias 'SchemaChangeEventFilter' to plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,382] INFO Added alias 'ConvertCloudEventToSaveableForm' to plugin 'io.debezium.connector.jdbc.transforms.ConvertCloudEventToSaveableForm' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,382] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,383] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,383] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,383] INFO Added alias 'ActivateTracingSpan' to plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,383] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,384] INFO Added alias 'BinaryDataConverter' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,384] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,384] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,385] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,385] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,385] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,385] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,386] INFO Added alias 'MongoEventRouter' to plugin 'io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,386] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,386] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-12-17 02:40:35,441] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = mysql-sink-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [HTTP://0.0.0.0:8083]
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [/opt/kafka/plugins, /opt/kafka/plugins/debezium-connector-jdbc, /opt/kafka/plugins/debezium-connector-mongodb]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = 172.30.2.207
	rest.advertised.listener = null
	rest.advertised.port = 8083
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:371)
[2024-12-17 02:40:35,449] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:281)
[2024-12-17 02:40:35,452] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:371)
[2024-12-17 02:40:35,547] INFO These configurations '[config.storage.topic, listeners, rest.advertised.host.name, status.storage.topic, group.id, rest.advertised.port, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2024-12-17 02:40:35,549] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:40:35,549] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:40:35,549] INFO Kafka startTimeMs: 1734378035548 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:40:36,039] INFO Kafka cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.connect.runtime.WorkerConfig:298)
[2024-12-17 02:40:36,040] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:40:36,061] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:40:36,062] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:40:36,062] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:40:36,071] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [HTTP://0.0.0.0:8083]
	response.http.headers.config = 
	rest.advertised.host.name = 172.30.2.207
	rest.advertised.listener = null
	rest.advertised.port = 8083
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:371)
[2024-12-17 02:40:36,083] INFO Logging initialized @17162ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2024-12-17 02:40:36,123] INFO Added connector for HTTP://0.0.0.0:8083 (org.apache.kafka.connect.runtime.rest.RestServer:125)
[2024-12-17 02:40:36,123] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:196)
[2024-12-17 02:40:36,149] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 17.0.13+11-Ubuntu-2ubuntu122.04 (org.eclipse.jetty.server.Server:375)
[2024-12-17 02:40:36,173] INFO Started http_0.0.0.08083@2706a89c{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2024-12-17 02:40:36,174] INFO Started @17253ms (org.eclipse.jetty.server.Server:415)
[2024-12-17 02:40:36,208] INFO Advertised URI: http://172.30.2.207:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2024-12-17 02:40:36,208] INFO REST server listening at http://0.0.0.0:8083/, advertising URL http://172.30.2.207:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:216)
[2024-12-17 02:40:36,209] INFO Advertised URI: http://172.30.2.207:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2024-12-17 02:40:36,209] INFO REST admin endpoints at http://172.30.2.207:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2024-12-17 02:40:36,210] INFO Advertised URI: http://172.30.2.207:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2024-12-17 02:40:36,210] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:45)
[2024-12-17 02:40:36,224] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:40:36,254] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:40:36,254] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:40:36,255] INFO Kafka startTimeMs: 1734378036254 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:40:36,269] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:40:36,270] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:40:36,301] INFO Advertised URI: http://172.30.2.207:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2024-12-17 02:40:36,332] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:40:36,332] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:40:36,332] INFO Kafka startTimeMs: 1734378036332 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:40:36,335] INFO Kafka Connect worker initialization took 16334ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2024-12-17 02:40:36,335] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:67)
[2024-12-17 02:40:36,338] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2024-12-17 02:40:36,340] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:375)
[2024-12-17 02:40:36,344] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:233)
[2024-12-17 02:40:36,344] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:232)
[2024-12-17 02:40:36,345] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:254)
[2024-12-17 02:40:36,349] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = mysql-sink-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:371)
[2024-12-17 02:40:36,369] INFO These configurations '[config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, group.id, rest.advertised.port, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2024-12-17 02:40:36,376] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:40:36,377] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:40:36,377] INFO Kafka startTimeMs: 1734378036376 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:40:36,378] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:238)
[2024-12-17 02:40:36,478] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = mysql-sink-cluster-offsets
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-17 02:40:36,539] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2024-12-17 02:40:36,539] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2024-12-17 02:40:36,540] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2024-12-17 02:40:36,580] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:40:36,696] INFO These configurations '[group.id, rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-17 02:40:36,696] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:40:36,697] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:40:36,697] INFO Kafka startTimeMs: 1734378036696 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:40:36,706] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = mysql-sink-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-sink-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2024-12-17 02:40:36,749] INFO [Producer clientId=mysql-sink-cluster-offsets] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:40:36,761] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:40:36,827] INFO These configurations '[rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2024-12-17 02:40:36,827] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:40:36,827] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:40:36,828] INFO Kafka startTimeMs: 1734378036827 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:40:36,843] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:40:36,858] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:579)
[2024-12-17 02:40:36,864] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,866] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,868] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,869] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,869] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,870] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,870] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,870] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,871] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,872] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,873] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,873] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,874] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,875] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,875] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,877] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,878] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,878] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,879] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,882] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,882] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,882] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,884] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,884] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,886] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:36,975] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,978] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,978] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,979] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,979] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,980] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,980] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,980] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,981] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,981] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,981] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,982] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,982] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,983] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,983] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,983] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,984] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,986] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,987] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,987] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,987] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,988] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,988] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,989] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:36,989] INFO [Consumer clientId=mysql-sink-cluster-offsets, groupId=mysql-sink-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:37,157] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:311)
[2024-12-17 02:40:37,158] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:313)
[2024-12-17 02:40:37,158] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:249)
[2024-12-17 02:40:37,160] INFO Worker started (org.apache.kafka.connect.runtime.Worker:243)
[2024-12-17 02:40:37,160] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:254)
[2024-12-17 02:40:37,177] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = mysql-sink-cluster-statuses
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-17 02:40:37,186] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:40:37,215] INFO These configurations '[group.id, rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-17 02:40:37,215] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:40:37,215] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:40:37,215] INFO Kafka startTimeMs: 1734378037215 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:40:37,216] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = mysql-sink-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-sink-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2024-12-17 02:40:37,225] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:40:37,244] INFO [Producer clientId=mysql-sink-cluster-statuses] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:40:37,245] INFO These configurations '[rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2024-12-17 02:40:37,246] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:40:37,246] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:40:37,246] INFO Kafka startTimeMs: 1734378037245 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:40:37,272] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:40:37,273] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:579)
[2024-12-17 02:40:37,274] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:37,274] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:37,274] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:37,274] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:37,274] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:37,303] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:37,303] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:37,304] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:37,304] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:37,304] INFO [Consumer clientId=mysql-sink-cluster-statuses, groupId=mysql-sink-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:37,490] INFO Started o.e.j.s.ServletContextHandler@1fdcd359{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2024-12-17 02:40:37,493] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:303)
[2024-12-17 02:40:37,493] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:77)
[2024-12-17 02:40:37,541] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:311)
[2024-12-17 02:40:37,541] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:313)
[2024-12-17 02:40:37,544] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:378)
[2024-12-17 02:40:37,545] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:254)
[2024-12-17 02:40:37,575] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = mysql-sink-cluster-configs
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-17 02:40:37,575] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:40:37,585] INFO These configurations '[group.id, rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-17 02:40:37,585] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:40:37,585] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:40:37,585] INFO Kafka startTimeMs: 1734378037585 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:40:37,586] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = mysql-sink-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-sink-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2024-12-17 02:40:37,587] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:40:37,615] INFO These configurations '[rest.advertised.port, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, listeners, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2024-12-17 02:40:37,617] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:40:37,617] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:40:37,617] INFO Kafka startTimeMs: 1734378037617 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:40:37,619] INFO [Producer clientId=mysql-sink-cluster-configs] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:40:37,627] INFO [Consumer clientId=mysql-sink-cluster-configs, groupId=mysql-sink-cluster] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:40:37,629] INFO [Consumer clientId=mysql-sink-cluster-configs, groupId=mysql-sink-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:579)
[2024-12-17 02:40:37,629] INFO [Consumer clientId=mysql-sink-cluster-configs, groupId=mysql-sink-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2024-12-17 02:40:37,643] INFO [Consumer clientId=mysql-sink-cluster-configs, groupId=mysql-sink-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=8}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:40:37,654] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,655] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,656] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,657] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,658] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,659] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,660] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,661] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,662] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,663] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,663] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,664] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,665] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,666] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,666] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,667] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,668] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,668] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,669] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,670] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,670] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,671] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,672] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,672] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,673] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,674] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,674] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,675] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,676] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,677] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,677] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,678] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,679] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,679] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,680] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,681] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,681] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,682] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,683] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,684] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,684] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,685] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,686] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,686] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,687] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,688] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,688] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,689] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,690] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,690] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,691] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,692] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,693] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,694] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,695] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,695] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,696] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,697] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,698] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,698] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,699] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,699] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,700] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,701] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,701] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,702] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,703] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,707] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,707] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,708] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,709] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,710] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,710] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,711] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,712] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,712] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,713] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,713] INFO Successfully processed removal of connector 'mongodb-source-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,714] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,715] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,715] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,716] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,716] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,717] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,718] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,718] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,719] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,719] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,720] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,721] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,721] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,722] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,723] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,723] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,724] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,725] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,725] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,726] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,726] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,727] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,728] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,728] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,729] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,729] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,730] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,730] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,731] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,731] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,732] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,732] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,733] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,733] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,734] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,735] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,735] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:40:37,736] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:311)
[2024-12-17 02:40:37,736] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:313)
[2024-12-17 02:40:37,744] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:402)
[2024-12-17 02:40:37,756] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:40:37,757] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2024-12-17 02:40:37,764] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:40:37,764] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:40:37,775] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:40:37,778] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=526, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:40:37,810] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=526, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:40:37,811] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 526 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', leaderUrl='http://172.30.2.207:8083/', offset=834, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:40:37,813] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:387)
[2024-12-17 02:40:37,813] WARN [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1811)
[2024-12-17 02:40:37,814] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Current config state offset -1 is behind group assignment 834, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1884)
[2024-12-17 02:40:37,819] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 834 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1911)
[2024-12-17 02:40:37,820] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 834 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:40:37,822] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connector mongodb-source-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 02:40:37,827] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 02:40:37,835] INFO [mongodb-source-connector|worker] Creating connector mongodb-source-connector of type io.debezium.connector.mongodb.MongoDbConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 02:40:37,838] INFO [mongodb-source-connector|task-0] Creating task mongodb-source-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 02:40:37,840] INFO [mongodb-source-connector|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-17 02:40:37,846] INFO [mongodb-source-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 02:40:37,852] INFO [mongodb-source-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:40:37,857] INFO [mongodb-source-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mongodb.MongoDbConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:371)
[2024-12-17 02:40:37,859] INFO [mongodb-source-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:40:37,862] INFO [mongodb-source-connector|task-0] Instantiated task mongodb-source-connector-0 with version 3.0.4.Final of type io.debezium.connector.mongodb.MongoDbConnectorTask (org.apache.kafka.connect.runtime.Worker:665)
[2024-12-17 02:40:37,865] INFO [mongodb-source-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:40:37,866] INFO [mongodb-source-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:40:37,866] INFO [mongodb-source-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-source-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:680)
[2024-12-17 02:40:37,866] INFO [mongodb-source-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-source-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:686)
[2024-12-17 02:40:37,866] INFO [mongodb-source-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mongodb-source-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:691)
[2024-12-17 02:40:37,878] INFO [mongodb-source-connector|worker] Instantiated connector mongodb-source-connector with version 3.0.4.Final of type class io.debezium.connector.mongodb.MongoDbConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 02:40:37,879] INFO [mongodb-source-connector|worker] Finished creating connector mongodb-source-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 02:40:37,879] WARN [mongodb-source-connector|task-0] The deleted record handling configs "drop.tombstones" and "delete.handling.mode" have been deprecated, please use "delete.tombstone.handling.mode" instead. (io.debezium.transforms.AbstractExtractNewRecordState:110)
[2024-12-17 02:40:37,905] WARN [mongodb-source-connector|task-0] Configuration key whitelist is deprecated and may be removed in the future.  Please update your configuration to use include instead. (org.apache.kafka.common.utils.ConfigUtils:114)
[2024-12-17 02:40:37,909] INFO [mongodb-source-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{io.debezium.connector.mongodb.transforms.ExtractNewDocumentState, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.TimestampConverter$Value} (org.apache.kafka.connect.runtime.Worker:1795)
[2024-12-17 02:40:37,910] INFO [mongodb-source-connector|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-17 02:40:37,914] INFO [mongodb-source-connector|worker] Successfully started MongoDB connector (io.debezium.connector.mongodb.MongoDbConnector:67)
[2024-12-17 02:40:37,919] INFO [mongodb-source-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:40:37,925] INFO [mongodb-source-connector|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-mongodb-source-connector-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2024-12-17 02:40:37,938] INFO [mongodb-source-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:40:37,943] INFO [mongodb-source-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2024-12-17 02:40:37,944] INFO [mongodb-source-connector|task-0] Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:40:37,944] INFO [mongodb-source-connector|task-0] Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:40:37,944] INFO [mongodb-source-connector|task-0] Kafka startTimeMs: 1734378037944 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:40:37,962] INFO [mongodb-source-connector|task-0] [Producer clientId=connector-producer-mongodb-source-connector-0] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:40:37,975] INFO [mongodb-source-connector|task-0] Starting MongoDbConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:245)
[2024-12-17 02:40:37,979] INFO [mongodb-source-connector|task-0]    connector.class = io.debezium.connector.mongodb.MongoDbConnector (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:37,982] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:40:37,986] INFO [mongodb-source-connector|task-0]    collection.include.list = test.customers (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:37,989] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2024-12-17 02:40:37,994] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mongodb.MongoDbConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mongodb-source-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap, extractNew, convertDate]
	transforms.convertDate.field = createdAt
	transforms.convertDate.format = yyyy-MM-dd HH:mm:ss
	transforms.convertDate.negate = false
	transforms.convertDate.predicate = null
	transforms.convertDate.replace.null.with.default = true
	transforms.convertDate.target.type = string
	transforms.convertDate.type = class org.apache.kafka.connect.transforms.TimestampConverter$Value
	transforms.convertDate.unix.precision = milliseconds
	transforms.extractNew.blacklist = null
	transforms.extractNew.exclude = []
	transforms.extractNew.include = []
	transforms.extractNew.negate = false
	transforms.extractNew.predicate = null
	transforms.extractNew.renames = []
	transforms.extractNew.replace.null.with.default = true
	transforms.extractNew.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.extractNew.whitelist = [_id, name, email, age, createdAt]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:40:37,992] INFO [mongodb-source-connector|task-0]    transforms.unwrap.delete.handling.mode = drop (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:37,998] INFO [mongodb-source-connector|task-0]    transforms.unwrap.array.encoding = array (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:37,998] INFO [mongodb-source-connector|task-0]    mongodb.connection.string = ******** (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:37,999] INFO [mongodb-source-connector|task-0]    tasks.max = 1 (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:37,999] INFO [mongodb-source-connector|task-0]    transforms = unwrap,extractNew,convertDate (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:37,999] INFO [mongodb-source-connector|task-0]    transforms.unwrap.add.source.fields = db,collection (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:37,999] INFO [mongodb-source-connector|task-0]    topic.prefix = fullfillment (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:37,999] INFO [mongodb-source-connector|task-0]    transforms.convertDate.format = yyyy-MM-dd HH:mm:ss (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:37,999] INFO [mongodb-source-connector|task-0]    mongodb.server.selection.timeout.ms = 10000 (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:37,999] INFO [mongodb-source-connector|task-0]    transforms.unwrap.drop.tombstones = false (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:37,999] INFO [mongodb-source-connector|task-0]    transforms.unwrap.type = io.debezium.connector.mongodb.transforms.ExtractNewDocumentState (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:37,999] INFO [mongodb-source-connector|task-0]    value.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:38,000] INFO [mongodb-source-connector|task-0]    mongodb.connect.timeout.ms = 10000 (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:38,000] INFO [mongodb-source-connector|task-0]    mongodb.auth.source = admin (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:38,000] INFO [mongodb-source-connector|task-0]    key.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:38,000] INFO [mongodb-source-connector|task-0]    transforms.convertDate.type = org.apache.kafka.connect.transforms.TimestampConverter$Value (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:38,000] INFO [mongodb-source-connector|task-0]    transforms.extractNew.type = org.apache.kafka.connect.transforms.ReplaceField$Value (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:38,000] INFO [mongodb-source-connector|task-0]    key.converter.schemas.enable = true (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:38,000] INFO [mongodb-source-connector|task-0]    transforms.extractNew.whitelist = _id,name,email,age,createdAt (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:38,000] INFO [mongodb-source-connector|task-0]    task.class = io.debezium.connector.mongodb.MongoDbConnectorTask (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:38,000] INFO [mongodb-source-connector|task-0]    transforms.convertDate.field = createdAt (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:38,000] INFO [mongodb-source-connector|task-0]    value.converter.schemas.enable = true (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:38,000] INFO [mongodb-source-connector|task-0]    name = mongodb-source-connector (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:38,000] INFO [mongodb-source-connector|task-0]    transforms.convertDate.target.type = string (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:38,000] INFO [mongodb-source-connector|task-0]    database.include.list = test (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:38,001] INFO [mongodb-source-connector|task-0]    snapshot.mode = initial (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:38,001] INFO [mongodb-source-connector|task-0]    transforms.unwrap.operation.header = true (io.debezium.connector.common.BaseSourceTask:247)
[2024-12-17 02:40:38,008] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:40:38,013] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:40:38,014] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:40:38,016] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:40:38,023] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:40:38,026] INFO [mongodb-source-connector|task-0] Loading the custom topic naming strategy plugin: io.debezium.schema.DefaultTopicNamingStrategy (io.debezium.config.CommonConnectorConfig:1401)
[2024-12-17 02:40:38,026] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:40:38,028] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:40:38,028] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:40:38,175] INFO [mongodb-source-connector|task-0] Found previous partition offset MongoDbPartition [sourcePartition={server_id=fullfillment}]: {sec=1734365014, ord=1, resume_token=zQAAAAJfZGF0YQC9AAAAODI2NzYwNEY1NjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNEY1NjQ5NkY2QjQ1OTk5NjQwMzcwMDAwMDQAAA==} (io.debezium.connector.common.BaseSourceTask:527)
[2024-12-17 02:40:38,191] INFO [mongodb-source-connector|task-0] Requested thread factory for component MongoDbConnector, id = fullfillment named = SignalProcessor (io.debezium.util.Threads:270)
[2024-12-17 02:40:38,212] WARN [mongodb-source-connector|task-0] Found a not connector specific implementation io.debezium.snapshot.lock.NoLockingSupport for lock mode no_locking_support (io.debezium.snapshot.SnapshotLockProvider:82)
[2024-12-17 02:40:38,224] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:40:38,225] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:40:38,225] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:40:38,227] INFO [mongodb-source-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mongodb.MongoDbSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2024-12-17 02:40:38,227] INFO [mongodb-source-connector|task-0] Found existing offset for at {sec=1734365014, ord=1, resume_token=zQAAAAJfZGF0YQC9AAAAODI2NzYwNEY1NjAwMDAwMDAxMkIwNDJDMDEwMDI5NkU1QTEwMDRGNTNEREUwQzM0RkQ0QzE4QjFFNkYzMjIyREI2OTI3NTQ2M0M2RjcwNjU3MjYxNzQ2OTZGNkU1NDc5NzA2NTAwM0M2OTZFNzM2NTcyNzQwMDQ2NjQ2RjYzNzU2RDY1NkU3NDRCNjU3OTAwNDY2NDVGNjk2NDAwNjQ2NzYwNEY1NjQ5NkY2QjQ1OTk5NjQwMzcwMDAwMDQAAA==} (io.debezium.connector.mongodb.connection.MongoDbConnection:202)
[2024-12-17 02:40:38,253] INFO [mongodb-source-connector|task-0] Adding discovered server 172.30.2.147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-17 02:40:38,313] INFO [mongodb-source-connector|task-0] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.11.0"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-125-generic"}, "platform": "Java/Ubuntu/17.0.13+11-Ubuntu-2ubuntu122.04"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@1c733c29, com.mongodb.Jep395RecordCodecProvider@63e6c603, com.mongodb.KotlinCodecProvider@354d2291]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[172.30.2.147:27017], srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='rs0', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='10000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=javax.net.ssl.SSLContext@4c8021ac}, applicationName='null', compressorList=[], uuidRepresentation=STANDARD, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null} (org.mongodb.driver.client:71)
[2024-12-17 02:40:38,352] INFO [mongodb-source-connector|task-0] Effective change stream pipeline: [{"$replaceRoot": {"newRoot": {"event": "$$ROOT", "namespace": {"$concat": ["$ns.db", ".", "$ns.coll"]}}}}, {"$match": {"$and": [{"$and": [{"event.ns.db": {"$regularExpression": {"pattern": "test", "options": "i"}}}, {"namespace": {"$regularExpression": {"pattern": "test.customers", "options": "i"}}}]}, {"event.operationType": {"$in": ["insert", "update", "replace", "delete"]}}]}}, {"$replaceRoot": {"newRoot": "$event"}}] (io.debezium.connector.mongodb.ChangeStreamPipelineFactory:56)
[2024-12-17 02:40:38,390] INFO [mongodb-source-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=172.30.2.147:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=21, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=17026697, setName='rs0', canonicalAddress=linux-ip-147:27017, hosts=[linux-ip-147:27017], passives=[], arbiters=[], primary='linux-ip-147:27017', tagSet=TagSet{[]}, electionId=7fffffff0000000000000004, setVersion=1, topologyVersion=TopologyVersion{processId=675f36d97bcf1da49879e510, counter=6}, lastWriteDate=Tue Dec 17 02:40:29 ICT 2024, lastUpdateTimeNanos=84849198955003} (org.mongodb.driver.cluster:71)
[2024-12-17 02:40:38,404] INFO [mongodb-source-connector|task-0] Adding discovered server linux-ip-147:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2024-12-17 02:40:38,411] INFO [mongodb-source-connector|task-0] Server 172.30.2.147:27017 is no longer a member of the replica set.  Removing from client view of cluster. (org.mongodb.driver.cluster:71)
[2024-12-17 02:40:38,414] INFO [mongodb-source-connector|task-0] Discovered replica set primary 172.30.2.147:27017 with max election id 7fffffff0000000000000004 and max set version 1 (org.mongodb.driver.cluster:71)
[2024-12-17 02:40:38,416] INFO [mongodb-source-connector|task-0] Exception in monitor thread while connecting to server linux-ip-147:27017 (org.mongodb.driver.cluster:76)
com.mongodb.MongoSocketException: linux-ip-147
	at com.mongodb.ServerAddress.getSocketAddresses(ServerAddress.java:221)
	at com.mongodb.internal.connection.ServerAddressWithResolver.getSocketAddresses(ServerAddressWithResolver.java:68)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:78)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:211)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.lookupServerDescription(DefaultServerMonitor.java:196)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:156)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.net.UnknownHostException: linux-ip-147
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.ServerAddress.getSocketAddresses(ServerAddress.java:213)
	... 7 more
[2024-12-17 02:40:38,445] INFO [mongodb-source-connector|task-0] No server chosen by ReadPreferenceServerSelector{readPreference=primary} from cluster description ClusterDescription{type=REPLICA_SET, connectionMode=MULTIPLE, serverDescriptions=[ServerDescription{address=linux-ip-147:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: linux-ip-147}, caused by {java.net.UnknownHostException: linux-ip-147}}]}. Waiting for 10000 ms before timing out (org.mongodb.driver.cluster:71)
[2024-12-17 02:40:47,969] INFO [mongodb-source-connector|task-0|offsets] Couldn't commit processed log positions with the source database due to a concurrent connector shutdown or restart (io.debezium.connector.common.BaseSourceTask:499)
[2024-12-17 02:40:48,450] ERROR [mongodb-source-connector|task-0] Error while attempting to Checking change stream: Timed out after 10000 ms while waiting for a server that matches ReadPreferenceServerSelector{readPreference=primary}. Client view of cluster state is {type=REPLICA_SET, servers=[{address=linux-ip-147:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: linux-ip-147}, caused by {java.net.UnknownHostException: linux-ip-147}}] (io.debezium.connector.mongodb.connection.MongoDbConnections:52)
com.mongodb.MongoTimeoutException: Timed out after 10000 ms while waiting for a server that matches ReadPreferenceServerSelector{readPreference=primary}. Client view of cluster state is {type=REPLICA_SET, servers=[{address=linux-ip-147:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: linux-ip-147}, caused by {java.net.UnknownHostException: linux-ip-147}}]
	at com.mongodb.internal.connection.BaseCluster.createTimeoutException(BaseCluster.java:380)
	at com.mongodb.internal.connection.BaseCluster.selectServer(BaseCluster.java:125)
	at com.mongodb.internal.connection.AbstractMultiServerCluster.selectServer(AbstractMultiServerCluster.java:54)
	at com.mongodb.internal.binding.ClusterBinding.getReadConnectionSource(ClusterBinding.java:116)
	at com.mongodb.client.internal.ClientSessionBinding.getConnectionSource(ClientSessionBinding.java:128)
	at com.mongodb.client.internal.ClientSessionBinding.getReadConnectionSource(ClientSessionBinding.java:92)
	at com.mongodb.internal.operation.SyncOperationHelper.withReadConnectionSource(SyncOperationHelper.java:97)
	at com.mongodb.internal.operation.ChangeStreamOperation.execute(ChangeStreamOperation.java:185)
	at com.mongodb.internal.operation.ChangeStreamOperation.execute(ChangeStreamOperation.java:54)
	at com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.execute(MongoClientDelegate.java:153)
	at com.mongodb.client.internal.ChangeStreamIterableImpl.execute(ChangeStreamIterableImpl.java:212)
	at com.mongodb.client.internal.ChangeStreamIterableImpl.cursor(ChangeStreamIterableImpl.java:187)
	at io.debezium.connector.mongodb.connection.MongoDbConnection.lambda$isValidResumeToken$10(MongoDbConnection.java:219)
	at io.debezium.connector.mongodb.connection.MongoDbConnection.execute(MongoDbConnection.java:105)
	at io.debezium.connector.mongodb.connection.MongoDbConnection.isValidResumeToken(MongoDbConnection.java:215)
	at io.debezium.connector.mongodb.connection.MongoDbConnection.validateLogPosition(MongoDbConnection.java:205)
	at io.debezium.connector.mongodb.MongoDbConnectorTask.validate(MongoDbConnectorTask.java:292)
	at io.debezium.connector.mongodb.MongoDbConnectorTask.start(MongoDbConnectorTask.java:137)
	at io.debezium.connector.common.BaseSourceTask.start(BaseSourceTask.java:251)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.initializeAndStart(AbstractWorkerSourceTask.java:279)
	at org.apache.kafka.connect.runtime.WorkerTask.doStart(WorkerTask.java:176)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:281)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:79)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:238)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-17 02:40:48,459] ERROR [mongodb-source-connector|task-0] WorkerSourceTask{id=mongodb-source-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:234)
io.debezium.DebeziumException: Error while attempting to Checking change stream
	at io.debezium.connector.mongodb.connection.MongoDbConnections.lambda$eventSourcingErrorHandler$1(MongoDbConnections.java:53)
	at io.debezium.connector.mongodb.connection.MongoDbConnection.execute(MongoDbConnection.java:111)
	at io.debezium.connector.mongodb.connection.MongoDbConnection.isValidResumeToken(MongoDbConnection.java:215)
	at io.debezium.connector.mongodb.connection.MongoDbConnection.validateLogPosition(MongoDbConnection.java:205)
	at io.debezium.connector.mongodb.MongoDbConnectorTask.validate(MongoDbConnectorTask.java:292)
	at io.debezium.connector.mongodb.MongoDbConnectorTask.start(MongoDbConnectorTask.java:137)
	at io.debezium.connector.common.BaseSourceTask.start(BaseSourceTask.java:251)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.initializeAndStart(AbstractWorkerSourceTask.java:279)
	at org.apache.kafka.connect.runtime.WorkerTask.doStart(WorkerTask.java:176)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:281)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:79)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:238)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoTimeoutException: Timed out after 10000 ms while waiting for a server that matches ReadPreferenceServerSelector{readPreference=primary}. Client view of cluster state is {type=REPLICA_SET, servers=[{address=linux-ip-147:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: linux-ip-147}, caused by {java.net.UnknownHostException: linux-ip-147}}]
	at com.mongodb.internal.connection.BaseCluster.createTimeoutException(BaseCluster.java:380)
	at com.mongodb.internal.connection.BaseCluster.selectServer(BaseCluster.java:125)
	at com.mongodb.internal.connection.AbstractMultiServerCluster.selectServer(AbstractMultiServerCluster.java:54)
	at com.mongodb.internal.binding.ClusterBinding.getReadConnectionSource(ClusterBinding.java:116)
	at com.mongodb.client.internal.ClientSessionBinding.getConnectionSource(ClientSessionBinding.java:128)
	at com.mongodb.client.internal.ClientSessionBinding.getReadConnectionSource(ClientSessionBinding.java:92)
	at com.mongodb.internal.operation.SyncOperationHelper.withReadConnectionSource(SyncOperationHelper.java:97)
	at com.mongodb.internal.operation.ChangeStreamOperation.execute(ChangeStreamOperation.java:185)
	at com.mongodb.internal.operation.ChangeStreamOperation.execute(ChangeStreamOperation.java:54)
	at com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.execute(MongoClientDelegate.java:153)
	at com.mongodb.client.internal.ChangeStreamIterableImpl.execute(ChangeStreamIterableImpl.java:212)
	at com.mongodb.client.internal.ChangeStreamIterableImpl.cursor(ChangeStreamIterableImpl.java:187)
	at io.debezium.connector.mongodb.connection.MongoDbConnection.lambda$isValidResumeToken$10(MongoDbConnection.java:219)
	at io.debezium.connector.mongodb.connection.MongoDbConnection.execute(MongoDbConnection.java:105)
	... 16 more
[2024-12-17 02:40:48,469] INFO [mongodb-source-connector|task-0] Stopping down connector (io.debezium.connector.common.BaseSourceTask:432)
[2024-12-17 02:40:48,475] INFO [mongodb-source-connector|task-0] [Producer clientId=connector-producer-mongodb-source-connector-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2024-12-17 02:40:48,491] INFO [mongodb-source-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:40:48,492] INFO [mongodb-source-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:40:48,493] INFO [mongodb-source-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:40:48,494] INFO [mongodb-source-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:40:48,496] INFO [mongodb-source-connector|task-0] App info kafka.producer for connector-producer-mongodb-source-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:41:43,133] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:371)
[2024-12-17 02:41:43,166] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 02:41:43,172] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:41:43,179] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:41:43,194] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=527, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:41:43,209] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=527, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:41:43,212] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 527 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', leaderUrl='http://172.30.2.207:8083/', offset=835, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:41:43,213] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 835 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:41:43,232] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 02:41:43,233] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 02:41:43,234] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:41:43,236] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted, createdAt]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:41:43,237] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 02:41:43,241] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 02:41:43,242] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:41:43,243] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:41:43,245] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted, createdAt]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:41:43,284] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 02:41:43,290] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:41:43,290] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:41:43,292] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=528, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:41:43,295] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=528, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:41:43,295] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 528 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', leaderUrl='http://172.30.2.207:8083/', offset=837, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:41:43,296] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 837 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:41:43,303] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 02:41:43,305] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 02:41:43,313] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 02:41:43,316] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted, createdAt]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:41:43,318] INFO [mysql-sink-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.jdbc.JdbcSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:371)
[2024-12-17 02:41:43,321] INFO [mysql-sink-connector|task-0] New InternalSinkRecord class found (io.debezium.connector.jdbc.JdbcSinkConnectorTask:74)
[2024-12-17 02:41:43,324] INFO [mysql-sink-connector|task-0] Instantiated task mysql-sink-connector-0 with version 3.0.4.Final of type io.debezium.connector.jdbc.JdbcSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:665)
[2024-12-17 02:41:43,325] INFO [mysql-sink-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:41:43,326] INFO [mysql-sink-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:41:43,326] INFO [mysql-sink-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:680)
[2024-12-17 02:41:43,326] INFO [mysql-sink-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:686)
[2024-12-17 02:41:43,326] INFO [mysql-sink-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-sink-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:691)
[2024-12-17 02:41:43,330] WARN [mysql-sink-connector|task-0] The deleted record handling configs "drop.tombstones" and "delete.handling.mode" have been deprecated, please use "delete.tombstone.handling.mode" instead. (io.debezium.transforms.AbstractExtractNewRecordState:110)
[2024-12-17 02:41:43,331] WARN [mysql-sink-connector|task-0] Configuration key blacklist is deprecated and may be removed in the future.  Please update your configuration to use exclude instead. (org.apache.kafka.common.utils.ConfigUtils:114)
[2024-12-17 02:41:43,331] INFO [mysql-sink-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{io.debezium.connector.mongodb.transforms.ExtractNewDocumentState, org.apache.kafka.connect.transforms.ReplaceField$Value} (org.apache.kafka.connect.runtime.Worker:1795)
[2024-12-17 02:41:43,332] INFO [mysql-sink-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:41:43,336] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 02:41:43,343] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted, createdAt]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:41:43,346] INFO [mysql-sink-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mysql-sink-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mysql-sink-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2024-12-17 02:41:43,349] INFO [mysql-sink-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:41:43,372] INFO [mysql-sink-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2024-12-17 02:41:43,373] INFO [mysql-sink-connector|task-0] Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:41:43,373] INFO [mysql-sink-connector|task-0] Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:41:43,373] INFO [mysql-sink-connector|task-0] Kafka startTimeMs: 1734378103373 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:41:43,390] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:41:43,390] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Handling task config update by stopping tasks [mysql-sink-connector-0], which will be restarted after rebalance if still assigned to this worker (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2024-12-17 02:41:43,390] INFO [mysql-sink-connector|task-0] Stopping task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1048)
[2024-12-17 02:41:43,391] INFO 172.30.2.207 - - [16/Dec/2024:19:41:42 +0000] "POST /connectors HTTP/1.1" 201 1270 "-" "curl/7.81.0" 658 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 02:41:43,393] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2024-12-17 02:41:43,394] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 02:41:43,398] INFO [mysql-sink-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:41:43,398] INFO [mysql-sink-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:41:43,399] INFO [mysql-sink-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:41:43,399] INFO [mysql-sink-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:41:43,404] INFO [mysql-sink-connector|task-0] App info kafka.consumer for connector-consumer-mysql-sink-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:41:43,416] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:41:43,416] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:41:43,419] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=529, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:41:43,426] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=529, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:41:43,427] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 529 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', leaderUrl='http://172.30.2.207:8083/', offset=839, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mysql-sink-connector-0, mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:41:43,428] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 839 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:41:43,429] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2024-12-17 02:41:43,430] INFO [mysql-sink-connector|task-0] Creating task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2024-12-17 02:41:43,431] INFO [mysql-sink-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2024-12-17 02:41:43,437] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted, createdAt]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:41:43,440] INFO [mysql-sink-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.jdbc.JdbcSinkConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:371)
[2024-12-17 02:41:43,441] INFO [mysql-sink-connector|task-0] New InternalSinkRecord class found (io.debezium.connector.jdbc.JdbcSinkConnectorTask:74)
[2024-12-17 02:41:43,442] INFO [mysql-sink-connector|task-0] Instantiated task mysql-sink-connector-0 with version 3.0.4.Final of type io.debezium.connector.jdbc.JdbcSinkConnectorTask (org.apache.kafka.connect.runtime.Worker:665)
[2024-12-17 02:41:43,442] INFO [mysql-sink-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:41:43,444] INFO [mysql-sink-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2024-12-17 02:41:43,445] INFO [mysql-sink-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:680)
[2024-12-17 02:41:43,446] INFO [mysql-sink-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-connector-0 using the connector config (org.apache.kafka.connect.runtime.Worker:686)
[2024-12-17 02:41:43,446] INFO [mysql-sink-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-sink-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:691)
[2024-12-17 02:41:43,448] WARN [mysql-sink-connector|task-0] The deleted record handling configs "drop.tombstones" and "delete.handling.mode" have been deprecated, please use "delete.tombstone.handling.mode" instead. (io.debezium.transforms.AbstractExtractNewRecordState:110)
[2024-12-17 02:41:43,449] WARN [mysql-sink-connector|task-0] Configuration key blacklist is deprecated and may be removed in the future.  Please update your configuration to use exclude instead. (org.apache.kafka.common.utils.ConfigUtils:114)
[2024-12-17 02:41:43,449] INFO [mysql-sink-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{io.debezium.connector.mongodb.transforms.ExtractNewDocumentState, org.apache.kafka.connect.transforms.ReplaceField$Value} (org.apache.kafka.connect.runtime.Worker:1795)
[2024-12-17 02:41:43,450] INFO [mysql-sink-connector|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:41:43,454] INFO [mysql-sink-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted, createdAt]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:41:43,464] INFO [mysql-sink-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [172.30.2.207:9092, 172.30.2.147:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mysql-sink-connector-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mysql-sink-connector
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2024-12-17 02:41:43,471] INFO [mysql-sink-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2024-12-17 02:41:43,480] INFO [mysql-sink-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2024-12-17 02:41:43,480] INFO [mysql-sink-connector|task-0] Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-12-17 02:41:43,480] INFO [mysql-sink-connector|task-0] Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-12-17 02:41:43,480] INFO [mysql-sink-connector|task-0] Kafka startTimeMs: 1734378103480 (org.apache.kafka.common.utils.AppInfoParser:127)
[2024-12-17 02:41:43,486] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Subscribed to topic(s): fullfillment.test.customers (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:481)
[2024-12-17 02:41:43,490] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:41:43,500] INFO [mysql-sink-connector|task-0] Starting JdbcSinkConnectorConfig with configuration: (io.debezium.connector.jdbc.JdbcSinkConnectorTask:410)
[2024-12-17 02:41:43,503] INFO [mysql-sink-connector|task-0]    connector.class = io.debezium.connector.jdbc.JdbcSinkConnector (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,503] INFO [mysql-sink-connector|task-0]    connection.password = ******** (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,504] INFO [mysql-sink-connector|task-0]    tasks.max = 1 (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,504] INFO [mysql-sink-connector|task-0]    transforms = unwrap,dropFields (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,504] INFO [mysql-sink-connector|task-0]    collection.name.format = mongodb_customers (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,504] INFO [mysql-sink-connector|task-0]    transforms.dropFields.type = org.apache.kafka.connect.transforms.ReplaceField$Value (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,505] INFO [mysql-sink-connector|task-0]    schema.evolution = basic (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,505] INFO [mysql-sink-connector|task-0]    auto.evolve = false (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,506] INFO [mysql-sink-connector|task-0]    transforms.unwrap.drop.tombstones = false (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,506] INFO [mysql-sink-connector|task-0]    transforms.unwrap.type = io.debezium.connector.mongodb.transforms.ExtractNewDocumentState (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,506] INFO [mysql-sink-connector|task-0]    driver.class = com.mysql.cj.jdbc.Driver (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,506] INFO [mysql-sink-connector|task-0]    value.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,507] INFO [mysql-sink-connector|task-0]    insert.mode = upsert (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,507] INFO [mysql-sink-connector|task-0]    key.converter = org.apache.kafka.connect.json.JsonConverter (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,507] INFO [mysql-sink-connector|task-0]    transforms.dropFields.blacklist = __deleted,createdAt (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,508] INFO [mysql-sink-connector|task-0]    primary.key.mode = record_key (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,508] INFO [mysql-sink-connector|task-0]    topics = fullfillment.test.customers (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,508] INFO [mysql-sink-connector|task-0]    batch.size = 1000 (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,508] INFO [mysql-sink-connector|task-0]    connection.username = phuc (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,509] INFO [mysql-sink-connector|task-0]    key.converter.schemas.enable = true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,509] INFO [mysql-sink-connector|task-0]    delete.enabled = true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,509] INFO [mysql-sink-connector|task-0]    task.class = io.debezium.connector.jdbc.JdbcSinkConnectorTask (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,509] INFO [mysql-sink-connector|task-0]    name = mysql-sink-connector (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,510] INFO [mysql-sink-connector|task-0]    value.converter.schemas.enable = true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,510] INFO [mysql-sink-connector|task-0]    auto.create = false (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,510] INFO [mysql-sink-connector|task-0]    primary.key.fields = _id (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,510] INFO [mysql-sink-connector|task-0]    connection.url = jdbc:mysql://172.30.2.207:3306/demo?useSSL=false&allowPublicKeyRetrieval=true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,511] INFO [mysql-sink-connector|task-0]    transforms.unwrap.handle.duplicate.fields = skip (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,511] INFO [mysql-sink-connector|task-0]    transforms.unwrap.operation.header = true (io.debezium.connector.jdbc.JdbcSinkConnectorTask:412)
[2024-12-17 02:41:43,614] INFO [mysql-sink-connector|task-0] HHH000412: Hibernate ORM core version 6.4.8.Final (org.hibernate.Version:44)
[2024-12-17 02:41:43,681] INFO [mysql-sink-connector|task-0] HHH000026: Second-level cache disabled (org.hibernate.cache.internal.RegionFactoryInitiator:50)
[2024-12-17 02:41:43,815] INFO [mysql-sink-connector|task-0] HHH000130: Instantiating explicit connection provider: org.hibernate.c3p0.internal.C3P0ConnectionProvider (org.hibernate.engine.jdbc.connections.internal.ConnectionProviderInitiator:131)
[2024-12-17 02:41:43,818] INFO [mysql-sink-connector|task-0] HHH010002: C3P0 using driver: null at URL: jdbc:mysql://172.30.2.207:3306/demo?useSSL=false&allowPublicKeyRetrieval=true (org.hibernate.orm.connections.pooling.c3p0:124)
[2024-12-17 02:41:43,819] INFO [mysql-sink-connector|task-0] HHH10001001: Connection properties: {password=****, user=phuc} (org.hibernate.orm.connections.pooling.c3p0:125)
[2024-12-17 02:41:43,819] INFO [mysql-sink-connector|task-0] HHH10001003: Autocommit mode: false (org.hibernate.orm.connections.pooling.c3p0:128)
[2024-12-17 02:41:43,820] WARN [mysql-sink-connector|task-0] HHH10001006: No JDBC Driver class was specified by property `jakarta.persistence.jdbc.driver`, `hibernate.driver` or `javax.persistence.jdbc.driver` (org.hibernate.orm.connections.pooling.c3p0:131)
[2024-12-17 02:41:43,852] INFO [mysql-sink-connector|task-0] MLog clients using slf4j logging. (com.mchange.v2.log.MLog:212)
[2024-12-17 02:41:43,942] INFO [mysql-sink-connector|task-0] Initializing c3p0-0.9.5.5 [built 11-December-2019 22:18:33 -0800; debug? true; trace: 10] (com.mchange.v2.c3p0.C3P0Registry:212)
[2024-12-17 02:41:44,014] INFO [mysql-sink-connector|task-0] HHH10001007: JDBC isolation level: <unknown> (org.hibernate.orm.connections.pooling.c3p0:200)
[2024-12-17 02:41:44,049] INFO [mysql-sink-connector|task-0] Initializing c3p0 pool... com.mchange.v2.c3p0.PoolBackedDataSource@f6c91723 [ connectionPoolDataSource -> com.mchange.v2.c3p0.WrapperConnectionPoolDataSource@aa1246d6 [ acquireIncrement -> 32, acquireRetryAttempts -> 30, acquireRetryDelay -> 1000, autoCommitOnClose -> false, automaticTestTable -> null, breakAfterAcquireFailure -> false, checkoutTimeout -> 0, connectionCustomizerClassName -> null, connectionTesterClassName -> com.mchange.v2.c3p0.impl.DefaultConnectionTester, contextClassLoaderSource -> caller, debugUnreturnedConnectionStackTraces -> false, factoryClassLocation -> null, forceIgnoreUnresolvedTransactions -> false, forceSynchronousCheckins -> false, identityToken -> z8kfsxb71lzjtqlvoexde|58194983, idleConnectionTestPeriod -> 0, initialPoolSize -> 5, maxAdministrativeTaskTime -> 0, maxConnectionAge -> 0, maxIdleTime -> 0, maxIdleTimeExcessConnections -> 0, maxPoolSize -> 32, maxStatements -> 0, maxStatementsPerConnection -> 0, minPoolSize -> 5, nestedDataSource -> com.mchange.v2.c3p0.DriverManagerDataSource@8fc815e9 [ description -> null, driverClass -> null, factoryClassLocation -> null, forceUseNamedDriverClass -> false, identityToken -> z8kfsxb71lzjtqlvoexde|4f0ebc5e, jdbcUrl -> jdbc:mysql://172.30.2.207:3306/demo?useSSL=false&allowPublicKeyRetrieval=true, properties -> {password=******, user=******} ], preferredTestQuery -> null, privilegeSpawnedThreads -> false, propertyCycle -> 0, statementCacheNumDeferredCloseThreads -> 0, testConnectionOnCheckin -> false, testConnectionOnCheckout -> false, unreturnedConnectionTimeout -> 0, usesTraditionalReflectiveProxies -> false; userOverrides: {} ], dataSourceName -> null, extensions -> {}, factoryClassLocation -> null, identityToken -> z8kfsxb71lzjtqlvoexde|2c64225d, numHelperThreads -> 3 ] (com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource:212)
[2024-12-17 02:41:45,600] INFO [mysql-sink-connector|task-0] HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration) (org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator:58)
[2024-12-17 02:41:45,648] INFO [mysql-sink-connector|task-0] Using dialect io.debezium.connector.jdbc.dialect.mysql.MySqlDatabaseDialect (io.debezium.connector.jdbc.dialect.DatabaseDialectResolver:44)
[2024-12-17 02:41:45,686] INFO [mysql-sink-connector|task-0] Database TimeZone: SYSTEM (global), SYSTEM (system) (io.debezium.connector.jdbc.dialect.GeneralDatabaseDialect:114)
[2024-12-17 02:41:45,693] INFO [mysql-sink-connector|task-0] Database version 8.0.0 (io.debezium.connector.jdbc.JdbcChangeEventSink:69)
[2024-12-17 02:41:45,693] INFO [mysql-sink-connector|task-0] WorkerSinkTask{id=mysql-sink-connector-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:325)
[2024-12-17 02:41:45,696] INFO [mysql-sink-connector|task-0] WorkerSinkTask{id=mysql-sink-connector-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:211)
[2024-12-17 02:41:45,719] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Cluster ID: 63zujGc1TGyE2LbXVuVaSg (org.apache.kafka.clients.Metadata:365)
[2024-12-17 02:41:45,721] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Discovered group coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:937)
[2024-12-17 02:41:45,723] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:605)
[2024-12-17 02:41:45,740] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Request joining group due to: need to re-join with the given member-id: connector-consumer-mysql-sink-connector-0-1e49e8f5-cf5a-4bbb-9e6c-8e544c4f2135 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 02:41:45,741] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:605)
[2024-12-17 02:41:45,745] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-mysql-sink-connector-0-1e49e8f5-cf5a-4bbb-9e6c-8e544c4f2135', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:666)
[2024-12-17 02:41:45,756] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Finished assignment for group at generation 1: {connector-consumer-mysql-sink-connector-0-1e49e8f5-cf5a-4bbb-9e6c-8e544c4f2135=Assignment(partitions=[fullfillment.test.customers-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:664)
[2024-12-17 02:41:45,762] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-mysql-sink-connector-0-1e49e8f5-cf5a-4bbb-9e6c-8e544c4f2135', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:843)
[2024-12-17 02:41:45,763] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Notifying assignor about the new Assignment(partitions=[fullfillment.test.customers-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:324)
[2024-12-17 02:41:45,764] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Adding newly assigned partitions: fullfillment.test.customers-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:58)
[2024-12-17 02:41:45,770] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Found no committed offset for partition fullfillment.test.customers-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1508)
[2024-12-17 02:41:45,779] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Resetting offset for partition fullfillment.test.customers-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[172.30.2.207:9092 (id: 0 rack: null)], epoch=6}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2024-12-17 02:41:45,931] ERROR [mysql-sink-connector|task-0] Failed to process record: Failed to process a sink record (io.debezium.connector.jdbc.JdbcSinkConnectorTask:136)
org.apache.kafka.connect.errors.ConnectException: Failed to process a sink record
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:207)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.execute(JdbcChangeEventSink.java:152)
	at io.debezium.connector.jdbc.JdbcSinkConnectorTask.put(JdbcSinkConnectorTask.java:127)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:606)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:345)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:247)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:216)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:226)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:281)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:238)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Cannot write to table mongodb_customers with no key fields defined.
	at io.debezium.connector.jdbc.JdbcChangeEventSink.getSqlStatement(JdbcChangeEventSink.java:361)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBuffer(JdbcChangeEventSink.java:222)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:198)
	... 14 more
[2024-12-17 02:41:51,339] INFO 172.30.0.4 - - [16/Dec/2024:19:41:51 +0000] "GET /connectors/mysql-sink-connector/status HTTP/1.1" 200 178 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36" 41 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 02:41:53,483] ERROR [mysql-sink-connector|task-0] JDBC sink connector failure (io.debezium.connector.jdbc.JdbcSinkConnectorTask:119)
org.apache.kafka.connect.errors.ConnectException: Failed to process a sink record
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:207)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.execute(JdbcChangeEventSink.java:152)
	at io.debezium.connector.jdbc.JdbcSinkConnectorTask.put(JdbcSinkConnectorTask.java:127)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:606)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:345)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:247)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:216)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:226)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:281)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:238)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Cannot write to table mongodb_customers with no key fields defined.
	at io.debezium.connector.jdbc.JdbcChangeEventSink.getSqlStatement(JdbcChangeEventSink.java:361)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBuffer(JdbcChangeEventSink.java:222)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:198)
	... 14 more
[2024-12-17 02:41:53,485] ERROR [mysql-sink-connector|task-0] WorkerSinkTask{id=mysql-sink-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: JDBC sink connector failure (org.apache.kafka.connect.runtime.WorkerSinkTask:634)
org.apache.kafka.connect.errors.ConnectException: JDBC sink connector failure
	at io.debezium.connector.jdbc.JdbcSinkConnectorTask.put(JdbcSinkConnectorTask.java:120)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:606)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:345)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:247)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:216)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:226)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:281)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:238)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to process a sink record
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:207)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.execute(JdbcChangeEventSink.java:152)
	at io.debezium.connector.jdbc.JdbcSinkConnectorTask.put(JdbcSinkConnectorTask.java:127)
	... 12 more
Caused by: org.apache.kafka.connect.errors.ConnectException: Cannot write to table mongodb_customers with no key fields defined.
	at io.debezium.connector.jdbc.JdbcChangeEventSink.getSqlStatement(JdbcChangeEventSink.java:361)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBuffer(JdbcChangeEventSink.java:222)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:198)
	... 14 more
[2024-12-17 02:41:53,498] ERROR [mysql-sink-connector|task-0] WorkerSinkTask{id=mysql-sink-connector-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:234)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:636)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:345)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:247)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:216)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:226)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:281)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:238)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: JDBC sink connector failure
	at io.debezium.connector.jdbc.JdbcSinkConnectorTask.put(JdbcSinkConnectorTask.java:120)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:606)
	... 11 more
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to process a sink record
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:207)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.execute(JdbcChangeEventSink.java:152)
	at io.debezium.connector.jdbc.JdbcSinkConnectorTask.put(JdbcSinkConnectorTask.java:127)
	... 12 more
Caused by: org.apache.kafka.connect.errors.ConnectException: Cannot write to table mongodb_customers with no key fields defined.
	at io.debezium.connector.jdbc.JdbcChangeEventSink.getSqlStatement(JdbcChangeEventSink.java:361)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBuffer(JdbcChangeEventSink.java:222)
	at io.debezium.connector.jdbc.JdbcChangeEventSink.flushBufferWithRetries(JdbcChangeEventSink.java:198)
	... 14 more
[2024-12-17 02:41:53,498] INFO [mysql-sink-connector|task-0] Closing session. (io.debezium.connector.jdbc.JdbcChangeEventSink:235)
[2024-12-17 02:41:53,505] INFO [mysql-sink-connector|task-0] Closing the session factory (io.debezium.connector.jdbc.JdbcSinkConnectorTask:186)
[2024-12-17 02:41:53,511] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Revoke previously assigned partitions fullfillment.test.customers-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:80)
[2024-12-17 02:41:53,512] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Member connector-consumer-mysql-sink-connector-0-1e49e8f5-cf5a-4bbb-9e6c-8e544c4f2135 sending LeaveGroup request to coordinator 172.30.2.207:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1174)
[2024-12-17 02:41:53,520] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2024-12-17 02:41:53,520] INFO [mysql-sink-connector|task-0] [Consumer clientId=connector-consumer-mysql-sink-connector-0, groupId=connect-mysql-sink-connector] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2024-12-17 02:41:53,833] INFO [mysql-sink-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2024-12-17 02:41:53,841] INFO [mysql-sink-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:41:53,842] INFO [mysql-sink-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2024-12-17 02:41:53,842] INFO [mysql-sink-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2024-12-17 02:41:53,858] INFO [mysql-sink-connector|task-0] App info kafka.consumer for connector-consumer-mysql-sink-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2024-12-17 02:42:02,041] INFO 172.30.0.4 - - [16/Dec/2024:19:42:02 +0000] "GET /connectors/mysql-sink-connector/status HTTP/1.1" 200 2441 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36" 10 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 02:50:32,965] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:50:32,972] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 02:50:32,977] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:50:32,977] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:50:33,002] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=530, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:50:33,017] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=530, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:50:33,024] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 02:50:33,024] INFO [mysql-sink-connector|task-0] Stopping task mysql-sink-connector-0 (org.apache.kafka.connect.runtime.Worker:1048)
[2024-12-17 02:50:33,026] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 02:50:33,030] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 02:50:33,031] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 02:50:33,052] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 02:50:33,053] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 530 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', leaderUrl='http://172.30.2.207:8083/', offset=840, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[mysql-sink-connector-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:50:33,054] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 840 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:50:33,054] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:50:33,054] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:50:33,054] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:50:33,061] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=531, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:50:33,068] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=531, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:50:33,070] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 531 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', leaderUrl='http://172.30.2.207:8083/', offset=841, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:50:33,072] WARN [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1811)
[2024-12-17 02:50:33,073] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Current config state offset 840 is behind group assignment 841, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1884)
[2024-12-17 02:50:33,132] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 841 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1911)
[2024-12-17 02:50:33,141] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 841 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:50:33,142] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:52:23,639] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:371)
[2024-12-17 02:52:23,684] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Connector mysql-sink-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2024-12-17 02:52:23,688] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:52:23,692] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:52:23,704] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=532, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:52:23,718] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=532, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:52:23,719] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 532 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', leaderUrl='http://172.30.2.207:8083/', offset=842, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:52:23,720] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 842 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:52:23,723] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connector mysql-sink-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2024-12-17 02:52:23,724] INFO 172.30.2.207 - - [16/Dec/2024:19:52:23 +0000] "POST /connectors HTTP/1.1" 201 1260 "-" "curl/7.81.0" 130 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-12-17 02:52:23,726] INFO [mysql-sink-connector|worker] Creating connector mysql-sink-connector of type io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2024-12-17 02:52:23,729] INFO [mysql-sink-connector|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:52:23,741] INFO [mysql-sink-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:52:23,764] INFO [mysql-sink-connector|worker] Instantiated connector mysql-sink-connector with version 3.0.4.Final of type class io.debezium.connector.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2024-12-17 02:52:23,765] INFO [mysql-sink-connector|worker] Finished creating connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:356)
[2024-12-17 02:52:23,766] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:52:23,775] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2024-12-17 02:52:23,784] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	name = mysql-sink-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [fullfillment.test.customers]
	topics.regex = 
	transforms = [unwrap, dropFields]
	transforms.dropFields.blacklist = [__deleted]
	transforms.dropFields.exclude = []
	transforms.dropFields.include = []
	transforms.dropFields.negate = false
	transforms.dropFields.predicate = null
	transforms.dropFields.renames = []
	transforms.dropFields.replace.null.with.default = true
	transforms.dropFields.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropFields.whitelist = null
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.array.encoding = array
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.flatten.struct = false
	transforms.unwrap.flatten.struct.delimiter = _
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.connector.mongodb.transforms.ExtractNewDocumentState
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2024-12-17 02:52:23,814] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Tasks [mysql-sink-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 02:52:23,858] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Tasks [] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2024-12-17 02:52:23,859] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:52:23,860] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:52:23,864] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=533, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:52:23,869] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=533, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:52:23,869] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 533 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', leaderUrl='http://172.30.2.207:8083/', offset=846, connectorIds=[mysql-sink-connector, mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:52:23,870] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 846 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:52:23,870] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:57:23,994] INFO Successfully processed removal of connector 'mysql-sink-connector' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2024-12-17 02:57:23,997] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Connector mysql-sink-connector config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2024-12-17 02:57:24,001] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:57:24,001] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:57:24,018] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=534, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:57:24,031] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=534, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:57:24,033] INFO [mysql-sink-connector|worker] Stopping connector mysql-sink-connector (org.apache.kafka.connect.runtime.Worker:452)
[2024-12-17 02:57:24,034] INFO [mysql-sink-connector|worker] Scheduled shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2024-12-17 02:57:24,044] INFO [mysql-sink-connector|worker] Completed shutdown for WorkerConnector{id=mysql-sink-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2024-12-17 02:57:24,047] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2024-12-17 02:57:24,050] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2024-12-17 02:57:24,052] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 534 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', leaderUrl='http://172.30.2.207:8083/', offset=847, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[mysql-sink-connector], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:57:24,054] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 847 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:57:24,058] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2024-12-17 02:57:24,060] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2024-12-17 02:57:24,060] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2024-12-17 02:57:24,064] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully joined group with generation Generation{generationId=535, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2024-12-17 02:57:24,070] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Successfully synced group in generation Generation{generationId=535, memberId='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2024-12-17 02:57:24,071] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Joined group at generation 535 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-172.30.2.207:8083-32a35daa-4ae8-4e3a-846b-1d294614d0ac', leaderUrl='http://172.30.2.207:8083/', offset=848, connectorIds=[mongodb-source-connector], taskIds=[mongodb-source-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2024-12-17 02:57:24,072] WARN [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1811)
[2024-12-17 02:57:24,072] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Current config state offset 847 is behind group assignment 848, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1884)
[2024-12-17 02:57:24,093] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 848 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1911)
[2024-12-17 02:57:24,093] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Starting connectors and tasks using config offset 848 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2024-12-17 02:57:24,093] INFO [Worker clientId=connect-172.30.2.207:8083, groupId=mysql-sink-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
